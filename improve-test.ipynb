{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 97710,
     "status": "ok",
     "timestamp": 1754111534908,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "APEFy1kWOh5S",
    "outputId": "2bfe9ee6-bfb7-4ae7-ad9a-f61f2f516bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-4zclen_v\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-4zclen_v\n",
      "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (10.7.0)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.0.2)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.9.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
      "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (3.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (4.14.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20250625) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.7.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=8596976403a1a4f70817ada0978c5f2ac225c56594147553e9b669565b922d52\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-w92g9sxr/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20250625\n"
     ]
    }
   ],
   "source": [
    "!pip install --break-system-packages git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 18983,
     "status": "ok",
     "timestamp": 1754111553915,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "ZZ-jXf6mOqp0",
    "outputId": "1fe38935-f36d-4885-a3be-ed2e324709e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyannote.audio\n",
      "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio)\n",
      "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.34.1)\n",
      "Collecting lightning>=2.0.1 (from pyannote.audio)\n",
      "  Downloading lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.3.0)\n",
      "Collecting pyannote.core>=5.0.0 (from pyannote.audio)\n",
      "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyannote.database>=5.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyannote.metrics>=3.2 (from pyannote.audio)\n",
      "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
      "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio)\n",
      "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (13.9.4)\n",
      "Collecting semver>=3.0.0 (from pyannote.audio)\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.13.1)\n",
      "Collecting speechbrain>=1.0.0 (from pyannote.audio)\n",
      "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tensorboardX>=2.6 (from pyannote.audio)\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n",
      "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting torchmetrics>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torchmetrics-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (4.14.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (1.1.5)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading lightning_utilities-0.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.1)\n",
      "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.0)\n",
      "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (2.19.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
      "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.5.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.5)\n",
      "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.12.14)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (75.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.41)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
      "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.7.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.20.1)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.2.3)\n",
      "Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
      "Downloading lightning-2.5.2-py3-none-any.whl (821 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.1/821.1 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.8.0-py3-none-any.whl (981 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.0-py3-none-any.whl (29 kB)\n",
      "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
      "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
      "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt, julius\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=1c6bd62cc8e53fce0e55d877e321e150df63f65891e2e03393cddadbd64732e5\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=1cae2c26dfbc70e84c9471c42de43752ca3d99fd9970ff61178c2b3d40b381fb\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
      "Successfully built docopt julius\n",
      "Installing collected packages: primePy, docopt, tensorboardX, semver, ruamel.yaml.clib, lightning-utilities, colorlog, ruamel.yaml, pyannote.core, alembic, optuna, hyperpyyaml, torchmetrics, pytorch-metric-learning, pyannote.database, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch-audiomentations, lightning, pyannote.audio\n",
      "Successfully installed alembic-1.16.4 asteroid-filterbanks-0.4.0 colorlog-6.9.0 docopt-0.6.2 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.5.2 lightning-utilities-0.15.0 optuna-4.4.0 primePy-1.3 pyannote.audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.5.2 pytorch-metric-learning-2.8.1 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 semver-3.0.4 speechbrain-1.0.3 tensorboardX-2.6.4 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --break-system-packages pyannote.audio torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 18975,
     "status": "ok",
     "timestamp": 1754111795749,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "LHi69QHCK5RV"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1754111795773,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "m_TUajOcLI6p"
   },
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1754111795792,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "xk9ilZoQRlCr"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "HUGGING_FACE_ACCESS_TOKEN = \"hf_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1754111811028,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "QT0m-nFMLWrA"
   },
   "outputs": [],
   "source": [
    "class ImprovedTranscriptionSystem:\n",
    "    def __init__(self, model_size=\"large\"):\n",
    "        \"\"\"Initialize the transcription system with improved parameters\"\"\"\n",
    "        self.model = whisper.load_model(model_size)\n",
    "        self.diarization_pipeline = None\n",
    "        self.output_dir = Path(\"processed_output\")\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def get_audio_duration(self, audio_path: str) -> float:\n",
    "        \"\"\"Get audio duration using ffprobe\"\"\"\n",
    "        try:\n",
    "            cmd = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
    "                   \"-of\", \"default=noprint_wrappers=1:nokey=1\", audio_path]\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "            return float(result.stdout.strip())\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Could not get duration: {e}\")\n",
    "            return 0\n",
    "\n",
    "    def smart_audio_preprocessing(self, input_path: str, output_path: str) -> bool:\n",
    "        \"\"\"Improved audio preprocessing with better noise reduction\"\"\"\n",
    "        logger.info(\"Starting improved audio preprocessing...\")\n",
    "\n",
    "        # Advanced preprocessing command with better parameters for call center audio\n",
    "        ffmpeg_command = [\n",
    "            \"ffmpeg\", \"-i\", input_path,\n",
    "            \"-acodec\", \"pcm_s16le\",\n",
    "            \"-ac\", \"1\",  # Mono\n",
    "            \"-ar\", \"16000\",  # 16kHz sample rate\n",
    "            # Improved audio filters for call center quality\n",
    "            \"-af\", (\n",
    "                \"highpass=f=300,\"  # Remove low frequency noise\n",
    "                \"lowpass=f=3400,\"  # Remove high frequency noise (telephone bandwidth)\n",
    "                \"loudnorm=I=-16:TP=-1.5:LRA=11,\"  # Normalize loudness\n",
    "                \"afftdn=nr=20:nf=-25,\"  # Noise reduction\n",
    "                \"compand=0.3,1:6:-70/-60,-20/-20,0/-6:0.5:0.1\"  # Dynamic range compression\n",
    "            ),\n",
    "            \"-y\", output_path\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "            logger.info(\"✅ Advanced preprocessing successful\")\n",
    "            return True\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            logger.error(f\"❌ Advanced preprocessing failed: {e}\")\n",
    "            # Fallback to simpler preprocessing\n",
    "            return self._fallback_preprocessing(input_path, output_path)\n",
    "\n",
    "    def _fallback_preprocessing(self, input_path: str, output_path: str) -> bool:\n",
    "        \"\"\"Fallback preprocessing method\"\"\"\n",
    "        logger.info(\"Trying fallback preprocessing...\")\n",
    "        ffmpeg_command = [\n",
    "            \"ffmpeg\", \"-i\", input_path,\n",
    "            \"-acodec\", \"pcm_s16le\",\n",
    "            \"-ac\", \"1\",\n",
    "            \"-ar\", \"16000\",\n",
    "            \"-af\", \"loudnorm\",\n",
    "            \"-y\", output_path\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "            logger.info(\"✅ Fallback preprocessing successful\")\n",
    "            return True\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            logger.error(f\"❌ Fallback preprocessing failed: {e}\")\n",
    "            return False\n",
    "\n",
    "    def detect_language_and_transcribe(self, audio_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Improved transcription with automatic language detection\"\"\"\n",
    "        logger.info(\"Starting improved transcription with language detection...\")\n",
    "\n",
    "        # First, detect the language\n",
    "        detection_result = self.model.transcribe(\n",
    "            audio_path,\n",
    "            temperature=0.0,\n",
    "            no_speech_threshold=0.6,\n",
    "            condition_on_previous_text=False,\n",
    "            task=\"transcribe\"  # Don't translate yet\n",
    "        )\n",
    "\n",
    "        detected_language = detection_result.get('language', 'en')\n",
    "        logger.info(f\"Detected language: {detected_language}\")\n",
    "\n",
    "        # Custom prompt for insurance call context\n",
    "        insurance_prompt = (\n",
    "            \"This is a customer service call for life insurance. \"\n",
    "            \"Keywords: policy, premium, due date, payment, insurance, \"\n",
    "            \"sum assured, nominee, health declaration, surrender value, \"\n",
    "            \"lapse, coverage, maturity, fund value, late fee charges.\"\n",
    "        )\n",
    "\n",
    "        # Strategy 1: If English detected, transcribe directly\n",
    "        if detected_language == 'en':\n",
    "            logger.info(\"Using direct English transcription\")\n",
    "            result = self.model.transcribe(\n",
    "                audio_path,\n",
    "                language=\"en\",\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,\n",
    "                beam_size=5,\n",
    "                patience=1.0,\n",
    "                condition_on_previous_text=False,\n",
    "                no_speech_threshold=0.6,\n",
    "                compression_ratio_threshold=2.4,\n",
    "                logprob_threshold=-1.0,\n",
    "                initial_prompt=insurance_prompt,\n",
    "                word_timestamps=True,\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            # Strategy 2: For other languages, try both transcribe and translate\n",
    "            logger.info(f\"Trying both transcription and translation for {detected_language}\")\n",
    "\n",
    "            # Get original transcription\n",
    "            transcribe_result = self.model.transcribe(\n",
    "                audio_path,\n",
    "                language=detected_language,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,\n",
    "                beam_size=5,\n",
    "                patience=1.0,\n",
    "                condition_on_previous_text=False,\n",
    "                no_speech_threshold=0.6,\n",
    "                compression_ratio_threshold=2.4,\n",
    "                logprob_threshold=-1.0,\n",
    "                initial_prompt=insurance_prompt,\n",
    "                word_timestamps=True,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            # Get translation to English\n",
    "            translate_result = self.model.transcribe(\n",
    "                audio_path,\n",
    "                language=detected_language,\n",
    "                task=\"translate\",\n",
    "                temperature=0.0,\n",
    "                beam_size=5,\n",
    "                patience=1.0,\n",
    "                condition_on_previous_text=False,\n",
    "                no_speech_threshold=0.6,\n",
    "                compression_ratio_threshold=2.4,\n",
    "                logprob_threshold=-1.0,\n",
    "                initial_prompt=insurance_prompt,\n",
    "                word_timestamps=True,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            # Choose the result with better quality metrics\n",
    "            transcribe_score = self._calculate_quality_score(transcribe_result)\n",
    "            translate_score = self._calculate_quality_score(translate_result)\n",
    "\n",
    "            if translate_score > transcribe_score:\n",
    "                logger.info(\"Using translated result (better quality)\")\n",
    "                result = translate_result\n",
    "                result['used_translation'] = True\n",
    "            else:\n",
    "                logger.info(\"Using original transcription (better quality)\")\n",
    "                result = transcribe_result\n",
    "                result['used_translation'] = False\n",
    "\n",
    "        result['detected_language'] = detected_language\n",
    "        logger.info(\"✅ Transcription completed\")\n",
    "        return result\n",
    "\n",
    "    def _calculate_quality_score(self, result: Dict[str, Any]) -> float:\n",
    "        \"\"\"Calculate a quality score for transcription results\"\"\"\n",
    "        if not result.get('segments'):\n",
    "            return 0.0\n",
    "\n",
    "        segments = result['segments']\n",
    "\n",
    "        # Metrics for quality assessment\n",
    "        total_duration = sum(seg.get('end', 0) - seg.get('start', 0) for seg in segments)\n",
    "        total_words = sum(len(seg.get('text', '').split()) for seg in segments)\n",
    "\n",
    "        if total_duration == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # Words per second (should be reasonable for speech)\n",
    "        words_per_second = total_words / total_duration\n",
    "        wps_score = 1.0 if 0.5 <= words_per_second <= 4.0 else 0.5\n",
    "\n",
    "        # Check for excessive repetition\n",
    "        all_text = ' '.join(seg.get('text', '') for seg in segments).lower()\n",
    "        words = all_text.split()\n",
    "        if words:\n",
    "            word_counts = Counter(words)\n",
    "            max_word_freq = max(word_counts.values())\n",
    "            repetition_score = 1.0 - min(max_word_freq / len(words), 0.8)\n",
    "        else:\n",
    "            repetition_score = 0.0\n",
    "\n",
    "        # Average confidence (if available)\n",
    "        confidences = []\n",
    "        for seg in segments:\n",
    "            if 'words' in seg:\n",
    "                confidences.extend([w.get('probability', 0.5) for w in seg['words'] if 'probability' in w])\n",
    "\n",
    "        avg_confidence = np.mean(confidences) if confidences else 0.5\n",
    "\n",
    "        # Combined score\n",
    "        quality_score = (wps_score * 0.3 + repetition_score * 0.4 + avg_confidence * 0.3)\n",
    "        return quality_score\n",
    "\n",
    "    def enhanced_repetition_removal(self, segments: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Enhanced repetition removal with better algorithms\"\"\"\n",
    "        logger.info(\"🔍 Starting enhanced repetition removal...\")\n",
    "\n",
    "        if not segments:\n",
    "            return segments\n",
    "\n",
    "        cleaned_segments = []\n",
    "\n",
    "        # First pass: Remove obvious repetitions\n",
    "        for i, segment in enumerate(segments):\n",
    "            text = segment.get('text', '').strip()\n",
    "            if not text or len(text) < 3:\n",
    "                continue\n",
    "\n",
    "            words = text.split()\n",
    "            if len(words) < 2:\n",
    "                continue\n",
    "\n",
    "            # Skip if too many consecutive repeated words\n",
    "            max_consecutive_repeats = self._count_max_consecutive_repeats(words)\n",
    "            if max_consecutive_repeats > 2:\n",
    "                logger.debug(f\"🚫 Skipping segment with {max_consecutive_repeats} consecutive repeats: {text[:30]}...\")\n",
    "                continue\n",
    "\n",
    "            # Skip if dominated by single word\n",
    "            word_counts = Counter(word.lower().strip('.,!?') for word in words)\n",
    "            max_word_count = max(word_counts.values())\n",
    "            if max_word_count / len(words) > 0.6:\n",
    "                logger.debug(f\"🚫 Skipping word-dominated segment: {text[:30]}...\")\n",
    "                continue\n",
    "\n",
    "            cleaned_segments.append(segment)\n",
    "\n",
    "        # Second pass: Remove near-duplicates\n",
    "        final_segments = []\n",
    "        for segment in cleaned_segments:\n",
    "            is_duplicate = False\n",
    "            current_text = segment.get('text', '').lower().strip()\n",
    "            current_words = set(current_text.split())\n",
    "\n",
    "            # Check against recent segments\n",
    "            for prev_segment in final_segments[-3:]:  # Check last 3 segments\n",
    "                prev_text = prev_segment.get('text', '').lower().strip()\n",
    "                prev_words = set(prev_text.split())\n",
    "\n",
    "                if current_words and prev_words:\n",
    "                    # Calculate Jaccard similarity\n",
    "                    intersection = len(current_words.intersection(prev_words))\n",
    "                    union = len(current_words.union(prev_words))\n",
    "                    similarity = intersection / union if union > 0 else 0\n",
    "\n",
    "                    if similarity > 0.8:  # High similarity threshold\n",
    "                        logger.debug(f\"🚫 Removing near-duplicate: {current_text[:30]}...\")\n",
    "                        is_duplicate = True\n",
    "                        break\n",
    "\n",
    "            if not is_duplicate:\n",
    "                final_segments.append(segment)\n",
    "\n",
    "        removed_count = len(segments) - len(final_segments)\n",
    "        logger.info(f\"📊 Enhanced cleaning: {len(segments)} → {len(final_segments)} segments\")\n",
    "        logger.info(f\"🗑️ Removed {removed_count} repetitive segments\")\n",
    "\n",
    "        return final_segments\n",
    "\n",
    "    def _count_max_consecutive_repeats(self, words: List[str]) -> int:\n",
    "        \"\"\"Count maximum consecutive repeated words\"\"\"\n",
    "        if len(words) < 2:\n",
    "            return 0\n",
    "\n",
    "        max_consecutive = 0\n",
    "        current_consecutive = 0\n",
    "\n",
    "        for i in range(1, len(words)):\n",
    "            if words[i].lower().strip('.,!?') == words[i-1].lower().strip('.,!?'):\n",
    "                current_consecutive += 1\n",
    "                max_consecutive = max(max_consecutive, current_consecutive + 1)\n",
    "            else:\n",
    "                current_consecutive = 0\n",
    "\n",
    "        return max_consecutive\n",
    "\n",
    "    def advanced_text_cleanup(self, text: str) -> str:\n",
    "        \"\"\"Advanced text cleanup for insurance call transcriptions\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        # Insurance-specific corrections\n",
    "        corrections = {\n",
    "            'access max life': 'Axis Maxlife',\n",
    "            'axis max life': 'Axis Maxlife',\n",
    "            'max life': 'Maxlife',\n",
    "            'g pay': 'GPay',\n",
    "            'google pay': 'Google Pay',\n",
    "            'phone pay': 'PhonePe',\n",
    "            'phone pe': 'PhonePe',\n",
    "            'pay tm': 'Paytm',\n",
    "            'net banking': 'netbanking',\n",
    "            'some assured': 'sum assured',\n",
    "            'premium do': 'premium due',\n",
    "            'do date': 'due date',\n",
    "            'policy number': 'policy number',\n",
    "            'nominee': 'nominee',\n",
    "        }\n",
    "\n",
    "        # Apply corrections\n",
    "        text_lower = text.lower()\n",
    "        for wrong, correct in corrections.items():\n",
    "            text_lower = re.sub(rf'\\b{re.escape(wrong)}\\b', correct, text_lower, flags=re.IGNORECASE)\n",
    "\n",
    "        # Fix currency symbols\n",
    "        text_lower = re.sub(r'\\brs[.]?\\s*', '₹', text_lower)\n",
    "        text_lower = re.sub(r'\\brupees?\\b', '₹', text_lower)\n",
    "\n",
    "        # Clean up spacing and punctuation\n",
    "        text_lower = re.sub(r'\\s{2,}', ' ', text_lower)\n",
    "        text_lower = re.sub(r'\\s+([,.!?])', r'\\1', text_lower)\n",
    "\n",
    "        # Capitalize sentences\n",
    "        text_lower = re.sub(r'(^|[.!?]\\s+)([a-z])',\n",
    "                           lambda m: m.group(1) + m.group(2).upper(),\n",
    "                           text_lower)\n",
    "\n",
    "        return text_lower.strip()\n",
    "\n",
    "    def improved_speaker_diarization(self, audio_path: str) -> Any:\n",
    "        \"\"\"Improved speaker diarization with better parameters\"\"\"\n",
    "        logger.info(\"🔊 Starting improved speaker diarization...\")\n",
    "\n",
    "        try:\n",
    "            if self.diarization_pipeline is None:\n",
    "                self.diarization_pipeline = Pipeline.from_pretrained(\n",
    "                    \"pyannote/speaker-diarization-3.1\",\n",
    "                    use_auth_token=HUGGING_FACE_ACCESS_TOKEN\n",
    "                )\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    self.diarization_pipeline.to(torch.device(\"cuda\"))\n",
    "                    logger.info(\"✅ Using GPU for diarization\")\n",
    "\n",
    "            # Run diarization with improved parameters\n",
    "            diarization = self.diarization_pipeline(\n",
    "                audio_path,\n",
    "                min_speakers=2,  # Expect at least 2 speakers (agent + customer)\n",
    "                max_speakers=3   # Max 3 speakers (agent + customer + maybe supervisor)\n",
    "            )\n",
    "\n",
    "            logger.info(\"✅ Speaker diarization completed\")\n",
    "            return diarization\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"⚠️ Diarization failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def assign_speakers_intelligently(self, segments: List[Dict[str, Any]],\n",
    "                                    diarization: Any) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Intelligently assign speakers based on content and patterns\"\"\"\n",
    "\n",
    "        def get_dominant_speaker(start: float, end: float) -> str:\n",
    "            if not diarization:\n",
    "                return \"Speaker_Unknown\"\n",
    "\n",
    "            speakers = {}\n",
    "            for segment, _, speaker in diarization.itertracks(yield_label=True):\n",
    "                overlap = max(0, min(end, segment.end) - max(start, segment.start))\n",
    "                if overlap > 0:\n",
    "                    speakers[speaker] = speakers.get(speaker, 0) + overlap\n",
    "\n",
    "            return max(speakers, key=speakers.get) if speakers else \"Speaker_Unknown\"\n",
    "\n",
    "        # Assign speakers to segments\n",
    "        for segment in segments:\n",
    "            start = segment.get('start', 0)\n",
    "            end = segment.get('end', 0)\n",
    "            speaker = get_dominant_speaker(start, end)\n",
    "            segment['speaker'] = speaker\n",
    "\n",
    "        # Post-process to identify Agent vs Customer based on content patterns\n",
    "        agent_keywords = [\n",
    "            'axis', 'maxlife', 'insurance', 'policy number', 'due date',\n",
    "            'premium', 'payment', 'calling from', 'renewal', 'health declaration',\n",
    "            'sir', 'madam', 'mam', 'thank you for', 'can you speak'\n",
    "        ]\n",
    "\n",
    "        customer_keywords = [\n",
    "            'hello', 'yes', 'okay', 'no', 'i will', 'i have', 'i am',\n",
    "            'thank you', 'my name is'\n",
    "        ]\n",
    "\n",
    "        # Score each speaker ID for being agent vs customer\n",
    "        speaker_scores = {}\n",
    "        for segment in segments:\n",
    "            speaker = segment.get('speaker', 'Unknown')\n",
    "            text = segment.get('text', '').lower()\n",
    "\n",
    "            if speaker not in speaker_scores:\n",
    "                speaker_scores[speaker] = {'agent_score': 0, 'customer_score': 0, 'total_words': 0}\n",
    "\n",
    "            words = text.split()\n",
    "            speaker_scores[speaker]['total_words'] += len(words)\n",
    "\n",
    "            # Score based on keywords\n",
    "            for keyword in agent_keywords:\n",
    "                if keyword in text:\n",
    "                    speaker_scores[speaker]['agent_score'] += 2\n",
    "\n",
    "            for keyword in customer_keywords:\n",
    "                if keyword in text:\n",
    "                    speaker_scores[speaker]['customer_score'] += 1\n",
    "\n",
    "        # Determine which speaker is agent vs customer\n",
    "        speaker_roles = {}\n",
    "        for speaker, scores in speaker_scores.items():\n",
    "            if scores['total_words'] > 5:  # Only consider speakers with substantial content\n",
    "                agent_ratio = scores['agent_score'] / max(scores['total_words'], 1)\n",
    "                customer_ratio = scores['customer_score'] / max(scores['total_words'], 1)\n",
    "\n",
    "                if agent_ratio > customer_ratio:\n",
    "                    speaker_roles[speaker] = 'Agent'\n",
    "                else:\n",
    "                    speaker_roles[speaker] = 'Customer'\n",
    "\n",
    "        # If we have exactly 2 main speakers, ensure one is Agent and one is Customer\n",
    "        main_speakers = [s for s, scores in speaker_scores.items()\n",
    "                        if scores['total_words'] > 10]\n",
    "\n",
    "        if len(main_speakers) == 2:\n",
    "            speakers_by_agent_score = sorted(main_speakers,\n",
    "                                           key=lambda s: speaker_scores[s]['agent_score'],\n",
    "                                           reverse=True)\n",
    "            speaker_roles[speakers_by_agent_score[0]] = 'Agent'\n",
    "            speaker_roles[speakers_by_agent_score[1]] = 'Customer'\n",
    "\n",
    "        # Apply role assignments\n",
    "        for segment in segments:\n",
    "            original_speaker = segment.get('speaker', 'Unknown')\n",
    "            segment['speaker'] = speaker_roles.get(original_speaker, original_speaker)\n",
    "\n",
    "        return segments\n",
    "\n",
    "    def merge_consecutive_segments(self, segments: List[Dict[str, Any]],\n",
    "                                 max_gap: float = 2.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Merge consecutive segments from the same speaker\"\"\"\n",
    "        if not segments:\n",
    "            return segments\n",
    "\n",
    "        merged = []\n",
    "        current_group = [segments[0]]\n",
    "\n",
    "        for segment in segments[1:]:\n",
    "            last_segment = current_group[-1]\n",
    "\n",
    "            # Check if same speaker and close in time\n",
    "            same_speaker = segment.get('speaker') == last_segment.get('speaker')\n",
    "            time_gap = segment.get('start', 0) - last_segment.get('end', 0)\n",
    "            close_in_time = time_gap <= max_gap\n",
    "\n",
    "            if same_speaker and close_in_time:\n",
    "                current_group.append(segment)\n",
    "            else:\n",
    "                # Merge current group\n",
    "                if current_group:\n",
    "                    merged_segment = self._merge_segment_group(current_group)\n",
    "                    merged.append(merged_segment)\n",
    "                current_group = [segment]\n",
    "\n",
    "        # Don't forget the last group\n",
    "        if current_group:\n",
    "            merged_segment = self._merge_segment_group(current_group)\n",
    "            merged.append(merged_segment)\n",
    "\n",
    "        return merged\n",
    "\n",
    "    def _merge_segment_group(self, segments: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Merge a group of segments into one\"\"\"\n",
    "        if not segments:\n",
    "            return {}\n",
    "\n",
    "        if len(segments) == 1:\n",
    "            return segments[0].copy()\n",
    "\n",
    "        merged = segments[0].copy()\n",
    "        texts = []\n",
    "\n",
    "        for segment in segments:\n",
    "            text = segment.get('text', '').strip()\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "\n",
    "        merged['text'] = ' '.join(texts)\n",
    "        merged['start'] = segments[0].get('start', 0)\n",
    "        merged['end'] = segments[-1].get('end', 0)\n",
    "\n",
    "        return merged\n",
    "\n",
    "    def process_audio_file(self, audio_file_path: Path) -> Dict[str, Any]:\n",
    "        \"\"\"Process a single audio file with improved pipeline\"\"\"\n",
    "        logger.info(f\"\\n📁 Processing file: {audio_file_path.name}\")\n",
    "\n",
    "        # Prepare output paths\n",
    "        clean_audio_path = self.output_dir / f\"{audio_file_path.stem}_clean.wav\"\n",
    "        json_output_path = self.output_dir / f\"{audio_file_path.stem}_transcription.json\"\n",
    "\n",
    "        # Step 1: Audio preprocessing\n",
    "        if not self.smart_audio_preprocessing(str(audio_file_path), str(clean_audio_path)):\n",
    "            logger.error(\"❌ Preprocessing failed, skipping file.\")\n",
    "            return {}\n",
    "\n",
    "        try:\n",
    "            # Step 2: Improved transcription\n",
    "            whisper_result = self.detect_language_and_transcribe(str(clean_audio_path))\n",
    "\n",
    "            # Step 3: Enhanced repetition removal\n",
    "            cleaned_segments = self.enhanced_repetition_removal(whisper_result.get(\"segments\", []))\n",
    "\n",
    "            # Step 4: Text cleanup\n",
    "            for segment in cleaned_segments:\n",
    "                original_text = segment.get('text', '')\n",
    "                cleaned_text = self.advanced_text_cleanup(original_text)\n",
    "                segment['text'] = cleaned_text\n",
    "\n",
    "            # Step 5: Speaker diarization\n",
    "            diarization = self.improved_speaker_diarization(str(clean_audio_path))\n",
    "\n",
    "            # Step 6: Intelligent speaker assignment\n",
    "            segments_with_speakers = self.assign_speakers_intelligently(cleaned_segments, diarization)\n",
    "\n",
    "            # Step 7: Merge consecutive segments\n",
    "            final_segments = self.merge_consecutive_segments(segments_with_speakers)\n",
    "\n",
    "            # Filter out very short segments\n",
    "            final_segments = [seg for seg in final_segments\n",
    "                            if len(seg.get('text', '').strip()) > 5]\n",
    "\n",
    "            # Prepare output data\n",
    "            output_data = {\n",
    "                'metadata': {\n",
    "                    'audio_file': str(audio_file_path.name),\n",
    "                    'detected_language': whisper_result.get('detected_language', 'unknown'),\n",
    "                    'used_translation': whisper_result.get('used_translation', False),\n",
    "                    'total_duration': whisper_result.get('duration', 0),\n",
    "                    'total_speakers': len(set(seg.get('speaker', 'Unknown') for seg in final_segments)),\n",
    "                    'total_segments': len(final_segments),\n",
    "                    'processing_successful': True,\n",
    "                    'quality_score': self._calculate_quality_score(whisper_result)\n",
    "                },\n",
    "                'dialogue': final_segments,\n",
    "                'raw_whisper_result': whisper_result\n",
    "            }\n",
    "\n",
    "            # Save results\n",
    "            with open(json_output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "            logger.info(f\"✅ Successfully processed: {json_output_path.name}\")\n",
    "            logger.info(f\"📊 Final segments: {len(final_segments)}\")\n",
    "\n",
    "            return output_data\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Processing failed for {audio_file_path.name}: {e}\")\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874,
     "referenced_widgets": [
      "17fe4d73cbf24b3c8e396d2ae7ec9021",
      "1fb06687df854155b11305a318e869b3",
      "570206c87c8f47c0a625a6b79a92a064",
      "26d3e8adca174230be7cedcd5bc2b131",
      "9db7b785c92445e78d1fac7bf6b8e67b",
      "bddfb9a822ee4c4fb9171355af0e0ee7",
      "ac445a74d0cf4d23bb228c4e6af351ac",
      "fa352dc403b348aa9ba2cbedc001e0b2",
      "58a0e9b2204947088fe63ef42d8b978e",
      "c9aa5dffa5e64bd4834f723885e63c60",
      "dffdc0aa503b46feae2e58bef19d95bc",
      "fe1fe7fd52a646ce8c97fb26be8a16b3",
      "657e524d8e9d4a549f56fdf055e6a74a",
      "11840e9bedd346d28dd3cf0e541d5d62",
      "7d6f48c261e64b82b09b5e3f7cb7bfc9",
      "4d76e87ef72b4912bb3155ae886afa5d",
      "b4cf326e45f244459cfa700bdf35eef9",
      "01bcb6fef8e041508986e9c61259cef1",
      "70f9983289e745e0be667ac6cc3425bc",
      "89eb7dae802b43b2b42df1846c9cb5d5",
      "f36329c6d81f490093a79f51604f3502",
      "7b7440ee94b64b89af2f389dbe62846a",
      "9b1c96545a6f436da1f43f1021cdfe3b",
      "639d15d6dd204ba88e815b08769cbd6f",
      "ba7dbca5650843a98f7931d941738f83",
      "8a727e8119b549ecaa4b487610801832",
      "cce8a0e791f9437b9ff0121c515e1319",
      "03b83a5ab84d4185a64ee19466165625",
      "603f2286743e475fbe3626cc2a079ef9",
      "4e249082f9464f69aa3ffacc34e14b35",
      "1c0438de27b14e82b89411d4a7edf6aa",
      "b9726cb92c684fd6b5359b146b0d88e8",
      "3959561be60441378b7faec6f4717828",
      "1ba712b4b23042e09920029578ac9578",
      "92b6ca8ce6df4dcf840816745c6d5954",
      "e9ea5a1fb76a4d45b5ed51305b58a079",
      "b58964be27a94496801a0eee14b3174a",
      "00ad50457a4c43fa89dd0c4d38c5ddd4",
      "7ba280ed73974642b7d1626c6e9bec2e",
      "201b40d116f342c89fa71d39b45e123f",
      "127ba8b415ff4a9ab2b41f08aa169139",
      "fcdf93ff81e84d44b1110772becd4b76",
      "e7ea310b75324cfc9c98f4e96ff998a2",
      "28ce2a9beb56412998201b335ad4e3de",
      "c2fa4825b645412b907d7546c6b23151",
      "cbcfb46eaf334ad6a26c5a135add8a8e",
      "39a5fae1dd354a7d96aac2ec56e39633",
      "5dcc0657b7174269a0414cbcc02fe2ea",
      "e23a4bd3274a4407a79e4e0051e650b9",
      "ddfa5edfe72e41228fe06fee872b0f7b",
      "1ce4cbb05ec04c08aad199d5f5adcf5f",
      "5ddf9738fa9e4d018835e06b8798a283",
      "29bd179ef73e41d78f61972b3979c57b",
      "97d9e43febd74c1daffe710eb6efccec",
      "9302dab6b5ef4ffcb57756128a1026c1"
     ]
    },
    "executionInfo": {
     "elapsed": 1297222,
     "status": "ok",
     "timestamp": 1754113115172,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "KC-uoyvILZBE",
    "outputId": "d2708775-6d8d-46c6-c1d6-de08bf7e9fbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [01:02<00:00, 49.5MiB/s]\n",
      "ERROR:__main__:❌ Advanced preprocessing failed: Command '['ffmpeg', '-i', 'training_data/call2.wav', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', '-af', 'highpass=f=300,lowpass=f=3400,loudnorm=I=-16:TP=-1.5:LRA=11,afftdn=nr=20:nf=-25,compand=0.3,1:6:-70/-60,-20/-20,0/-6:0.5:0.1', '-y', 'processed_output/call2_clean.wav']' returned non-zero exit status 1.\n",
      "100%|██████████| 19076/19076 [03:01<00:00, 105.14frames/s]\n",
      "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:182: UserWarning: Word-level timestamps on translations may not be reliable.\n",
      "  warnings.warn(\"Word-level timestamps on translations may not be reliable.\")\n",
      "100%|██████████| 19076/19076 [01:13<00:00, 260.71frames/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fe4d73cbf24b3c8e396d2ae7ec9021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/469 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1fe7fd52a646ce8c97fb26be8a16b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1c96545a6f436da1f43f1021cdfe3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba712b4b23042e09920029578ac9578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/26.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fa4825b645412b907d7546c6b23151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/221 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "ERROR:__main__:❌ Advanced preprocessing failed: Command '['ffmpeg', '-i', 'training_data/call3.wav', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', '-af', 'highpass=f=300,lowpass=f=3400,loudnorm=I=-16:TP=-1.5:LRA=11,afftdn=nr=20:nf=-25,compand=0.3,1:6:-70/-60,-20/-20,0/-6:0.5:0.1', '-y', 'processed_output/call3_clean.wav']' returned non-zero exit status 1.\n",
      "100%|██████████| 14072/14072 [00:58<00:00, 238.77frames/s]\n",
      "ERROR:__main__:❌ Advanced preprocessing failed: Command '['ffmpeg', '-i', 'training_data/call5.wav', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', '-af', 'highpass=f=300,lowpass=f=3400,loudnorm=I=-16:TP=-1.5:LRA=11,afftdn=nr=20:nf=-25,compand=0.3,1:6:-70/-60,-20/-20,0/-6:0.5:0.1', '-y', 'processed_output/call5_clean.wav']' returned non-zero exit status 1.\n",
      "100%|██████████| 16970/16970 [02:30<00:00, 112.58frames/s]\n",
      "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:182: UserWarning: Word-level timestamps on translations may not be reliable.\n",
      "  warnings.warn(\"Word-level timestamps on translations may not be reliable.\")\n",
      " 96%|█████████▋| 16338/16970 [00:46<00:01, 348.74frames/s]\n",
      "ERROR:__main__:❌ Advanced preprocessing failed: Command '['ffmpeg', '-i', 'training_data/call1.wav', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', '-af', 'highpass=f=300,lowpass=f=3400,loudnorm=I=-16:TP=-1.5:LRA=11,afftdn=nr=20:nf=-25,compand=0.3,1:6:-70/-60,-20/-20,0/-6:0.5:0.1', '-y', 'processed_output/call1_clean.wav']' returned non-zero exit status 1.\n",
      "100%|██████████| 10692/10692 [01:13<00:00, 145.50frames/s]\n",
      "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:182: UserWarning: Word-level timestamps on translations may not be reliable.\n",
      "  warnings.warn(\"Word-level timestamps on translations may not be reliable.\")\n",
      "100%|██████████| 10692/10692 [00:39<00:00, 268.61frames/s]\n",
      "ERROR:__main__:❌ Advanced preprocessing failed: Command '['ffmpeg', '-i', 'training_data/call4.wav', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', '-af', 'highpass=f=300,lowpass=f=3400,loudnorm=I=-16:TP=-1.5:LRA=11,afftdn=nr=20:nf=-25,compand=0.3,1:6:-70/-60,-20/-20,0/-6:0.5:0.1', '-y', 'processed_output/call4_clean.wav']' returned non-zero exit status 1.\n",
      "100%|██████████| 16095/16095 [01:52<00:00, 142.45frames/s]\n",
      "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:182: UserWarning: Word-level timestamps on translations may not be reliable.\n",
      "  warnings.warn(\"Word-level timestamps on translations may not be reliable.\")\n",
      "100%|██████████| 16095/16095 [01:00<00:00, 264.05frames/s]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main processing function\"\"\"\n",
    "    # Initialize the system\n",
    "    system = ImprovedTranscriptionSystem()\n",
    "\n",
    "    # Process all audio files\n",
    "    input_dir = Path(\"training_data\")\n",
    "    audio_files = list(input_dir.glob(\"*.wav\"))\n",
    "\n",
    "    if not audio_files:\n",
    "        logger.error(\"❌ No .wav files found in 'training_data/' folder.\")\n",
    "        return\n",
    "\n",
    "    logger.info(f\"🚀 Found {len(audio_files)} files to process...\")\n",
    "\n",
    "    # Process each file\n",
    "    all_results = []\n",
    "    for audio_file in audio_files:\n",
    "        result = system.process_audio_file(audio_file)\n",
    "        if result:\n",
    "            all_results.append(result)\n",
    "\n",
    "    # Generate training manifest\n",
    "    manifest_path = system.output_dir / \"training_manifest.jsonl\"\n",
    "    with open(manifest_path, 'w', encoding='utf-8') as f:\n",
    "        for result in all_results:\n",
    "            if result.get('dialogue'):\n",
    "                # Create conversation text\n",
    "                conversation_text = \"\\n\".join([\n",
    "                    f\"{seg.get('speaker', 'Unknown')}: {seg.get('text', '')}\"\n",
    "                    for seg in result['dialogue']\n",
    "                ])\n",
    "\n",
    "                manifest_entry = {\n",
    "                    \"audio_filepath\": str(system.output_dir / f\"{Path(result['metadata']['audio_file']).stem}_clean.wav\"),\n",
    "                    \"text\": conversation_text,\n",
    "                    \"language\": result['metadata'].get('detected_language', 'en'),\n",
    "                    \"task\": \"transcribe\" if not result['metadata'].get('used_translation', False) else \"translate\"\n",
    "                }\n",
    "                f.write(json.dumps(manifest_entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    logger.info(f\"\\n📄 Training manifest saved to: {manifest_path}\")\n",
    "    logger.info(f\"✅ Successfully processed {len(all_results)} out of {len(audio_files)} files\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6rLH4xYT1R8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mboMcwCWT1Uo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkA5J5FsT1XL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1376,
     "status": "ok",
     "timestamp": 1754113508011,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "B07v93kSCaWa",
    "outputId": "d0b8e22e-6a36-4429-cbff-f92c09df6b3f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/processed_output-claude.zip'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Zip the folder into processed_outputs.zip\n",
    "shutil.make_archive('processed_output-claude', 'zip', 'processed_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1754113508038,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "zxKt44x-CaWc",
    "outputId": "f8aaf00c-6759-4d76-d53d-00b5dd65c6f0"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_91d2cd9b-877c-4d13-b478-5d251d2409ad\", \"processed_output-claude.zip\", 19251252)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download the zipped folder\n",
    "files.download('processed_output-claude.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "938ySwg2T_2E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNqN+0xmz2P7DQScPBUSsfv",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00ad50457a4c43fa89dd0c4d38c5ddd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01bcb6fef8e041508986e9c61259cef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "03b83a5ab84d4185a64ee19466165625": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11840e9bedd346d28dd3cf0e541d5d62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70f9983289e745e0be667ac6cc3425bc",
      "max": 5905440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89eb7dae802b43b2b42df1846c9cb5d5",
      "value": 5905440
     }
    },
    "127ba8b415ff4a9ab2b41f08aa169139": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17fe4d73cbf24b3c8e396d2ae7ec9021": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1fb06687df854155b11305a318e869b3",
       "IPY_MODEL_570206c87c8f47c0a625a6b79a92a064",
       "IPY_MODEL_26d3e8adca174230be7cedcd5bc2b131"
      ],
      "layout": "IPY_MODEL_9db7b785c92445e78d1fac7bf6b8e67b"
     }
    },
    "1ba712b4b23042e09920029578ac9578": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92b6ca8ce6df4dcf840816745c6d5954",
       "IPY_MODEL_e9ea5a1fb76a4d45b5ed51305b58a079",
       "IPY_MODEL_b58964be27a94496801a0eee14b3174a"
      ],
      "layout": "IPY_MODEL_00ad50457a4c43fa89dd0c4d38c5ddd4"
     }
    },
    "1c0438de27b14e82b89411d4a7edf6aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ce4cbb05ec04c08aad199d5f5adcf5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fb06687df854155b11305a318e869b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bddfb9a822ee4c4fb9171355af0e0ee7",
      "placeholder": "​",
      "style": "IPY_MODEL_ac445a74d0cf4d23bb228c4e6af351ac",
      "value": "config.yaml: 100%"
     }
    },
    "201b40d116f342c89fa71d39b45e123f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26d3e8adca174230be7cedcd5bc2b131": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9aa5dffa5e64bd4834f723885e63c60",
      "placeholder": "​",
      "style": "IPY_MODEL_dffdc0aa503b46feae2e58bef19d95bc",
      "value": " 469/469 [00:00&lt;00:00, 43.5kB/s]"
     }
    },
    "28ce2a9beb56412998201b335ad4e3de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29bd179ef73e41d78f61972b3979c57b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3959561be60441378b7faec6f4717828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39a5fae1dd354a7d96aac2ec56e39633": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ddf9738fa9e4d018835e06b8798a283",
      "max": 221,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_29bd179ef73e41d78f61972b3979c57b",
      "value": 221
     }
    },
    "4d76e87ef72b4912bb3155ae886afa5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e249082f9464f69aa3ffacc34e14b35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "570206c87c8f47c0a625a6b79a92a064": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa352dc403b348aa9ba2cbedc001e0b2",
      "max": 469,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_58a0e9b2204947088fe63ef42d8b978e",
      "value": 469
     }
    },
    "58a0e9b2204947088fe63ef42d8b978e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5dcc0657b7174269a0414cbcc02fe2ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97d9e43febd74c1daffe710eb6efccec",
      "placeholder": "​",
      "style": "IPY_MODEL_9302dab6b5ef4ffcb57756128a1026c1",
      "value": " 221/221 [00:00&lt;00:00, 23.3kB/s]"
     }
    },
    "5ddf9738fa9e4d018835e06b8798a283": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "603f2286743e475fbe3626cc2a079ef9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "639d15d6dd204ba88e815b08769cbd6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03b83a5ab84d4185a64ee19466165625",
      "placeholder": "​",
      "style": "IPY_MODEL_603f2286743e475fbe3626cc2a079ef9",
      "value": "config.yaml: 100%"
     }
    },
    "657e524d8e9d4a549f56fdf055e6a74a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4cf326e45f244459cfa700bdf35eef9",
      "placeholder": "​",
      "style": "IPY_MODEL_01bcb6fef8e041508986e9c61259cef1",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "70f9983289e745e0be667ac6cc3425bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b7440ee94b64b89af2f389dbe62846a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ba280ed73974642b7d1626c6e9bec2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d6f48c261e64b82b09b5e3f7cb7bfc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f36329c6d81f490093a79f51604f3502",
      "placeholder": "​",
      "style": "IPY_MODEL_7b7440ee94b64b89af2f389dbe62846a",
      "value": " 5.91M/5.91M [00:00&lt;00:00, 9.18MB/s]"
     }
    },
    "89eb7dae802b43b2b42df1846c9cb5d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a727e8119b549ecaa4b487610801832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9726cb92c684fd6b5359b146b0d88e8",
      "placeholder": "​",
      "style": "IPY_MODEL_3959561be60441378b7faec6f4717828",
      "value": " 399/399 [00:00&lt;00:00, 34.5kB/s]"
     }
    },
    "92b6ca8ce6df4dcf840816745c6d5954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ba280ed73974642b7d1626c6e9bec2e",
      "placeholder": "​",
      "style": "IPY_MODEL_201b40d116f342c89fa71d39b45e123f",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "9302dab6b5ef4ffcb57756128a1026c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97d9e43febd74c1daffe710eb6efccec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b1c96545a6f436da1f43f1021cdfe3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_639d15d6dd204ba88e815b08769cbd6f",
       "IPY_MODEL_ba7dbca5650843a98f7931d941738f83",
       "IPY_MODEL_8a727e8119b549ecaa4b487610801832"
      ],
      "layout": "IPY_MODEL_cce8a0e791f9437b9ff0121c515e1319"
     }
    },
    "9db7b785c92445e78d1fac7bf6b8e67b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac445a74d0cf4d23bb228c4e6af351ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4cf326e45f244459cfa700bdf35eef9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b58964be27a94496801a0eee14b3174a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7ea310b75324cfc9c98f4e96ff998a2",
      "placeholder": "​",
      "style": "IPY_MODEL_28ce2a9beb56412998201b335ad4e3de",
      "value": " 26.6M/26.6M [00:00&lt;00:00, 41.7MB/s]"
     }
    },
    "b9726cb92c684fd6b5359b146b0d88e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba7dbca5650843a98f7931d941738f83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e249082f9464f69aa3ffacc34e14b35",
      "max": 399,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c0438de27b14e82b89411d4a7edf6aa",
      "value": 399
     }
    },
    "bddfb9a822ee4c4fb9171355af0e0ee7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2fa4825b645412b907d7546c6b23151": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbcfb46eaf334ad6a26c5a135add8a8e",
       "IPY_MODEL_39a5fae1dd354a7d96aac2ec56e39633",
       "IPY_MODEL_5dcc0657b7174269a0414cbcc02fe2ea"
      ],
      "layout": "IPY_MODEL_e23a4bd3274a4407a79e4e0051e650b9"
     }
    },
    "c9aa5dffa5e64bd4834f723885e63c60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbcfb46eaf334ad6a26c5a135add8a8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddfa5edfe72e41228fe06fee872b0f7b",
      "placeholder": "​",
      "style": "IPY_MODEL_1ce4cbb05ec04c08aad199d5f5adcf5f",
      "value": "config.yaml: 100%"
     }
    },
    "cce8a0e791f9437b9ff0121c515e1319": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddfa5edfe72e41228fe06fee872b0f7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dffdc0aa503b46feae2e58bef19d95bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e23a4bd3274a4407a79e4e0051e650b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7ea310b75324cfc9c98f4e96ff998a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9ea5a1fb76a4d45b5ed51305b58a079": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_127ba8b415ff4a9ab2b41f08aa169139",
      "max": 26645418,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fcdf93ff81e84d44b1110772becd4b76",
      "value": 26645418
     }
    },
    "f36329c6d81f490093a79f51604f3502": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa352dc403b348aa9ba2cbedc001e0b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcdf93ff81e84d44b1110772becd4b76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe1fe7fd52a646ce8c97fb26be8a16b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_657e524d8e9d4a549f56fdf055e6a74a",
       "IPY_MODEL_11840e9bedd346d28dd3cf0e541d5d62",
       "IPY_MODEL_7d6f48c261e64b82b09b5e3f7cb7bfc9"
      ],
      "layout": "IPY_MODEL_4d76e87ef72b4912bb3155ae886afa5d"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
