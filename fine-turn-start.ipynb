{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 101725,
     "status": "ok",
     "timestamp": 1754023519591,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "APEFy1kWOh5S",
    "outputId": "05a8469e-a0ff-47d9-8e3d-5aec8f70a180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-f22m3p_p\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-f22m3p_p\n",
      "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (10.7.0)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.0.2)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.9.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
      "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (3.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (4.14.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20250625) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.7.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=c1671b178ee0b48b1db79c2527288b2e8c3befc82d315902bd6d60a7fc772e8d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vdwb3e_j/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20250625\n"
     ]
    }
   ],
   "source": [
    "!pip install --break-system-packages git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 19907,
     "status": "ok",
     "timestamp": 1754023539457,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "ZZ-jXf6mOqp0",
    "outputId": "540a8a2a-6fb1-45b9-f1d8-f031191e85f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyannote.audio\n",
      "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio)\n",
      "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.34.3)\n",
      "Collecting lightning>=2.0.1 (from pyannote.audio)\n",
      "  Downloading lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.3.0)\n",
      "Collecting pyannote.core>=5.0.0 (from pyannote.audio)\n",
      "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyannote.database>=5.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyannote.metrics>=3.2 (from pyannote.audio)\n",
      "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
      "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio)\n",
      "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (13.9.4)\n",
      "Collecting semver>=3.0.0 (from pyannote.audio)\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.13.1)\n",
      "Collecting speechbrain>=1.0.0 (from pyannote.audio)\n",
      "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tensorboardX>=2.6 (from pyannote.audio)\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n",
      "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting torchmetrics>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torchmetrics-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (4.14.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (1.1.5)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading lightning_utilities-0.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.16.1)\n",
      "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.1)\n",
      "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.0)\n",
      "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (2.19.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
      "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.5.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.5)\n",
      "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.12.15)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (75.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.42)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
      "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.7.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.20.1)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.2.3)\n",
      "Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
      "Downloading lightning-2.5.2-py3-none-any.whl (821 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.1/821.1 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.8.0-py3-none-any.whl (981 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.0-py3-none-any.whl (29 kB)\n",
      "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
      "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
      "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt, julius\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=94c4a6183052b18ff16be75a80c4093c8b1adeecd697ddef36bc93a6a2d05daf\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=9d4a6363d66fccf7f62ed236ef495240d9c8df8e5d4fceebe1f3c8818dadfba2\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
      "Successfully built docopt julius\n",
      "Installing collected packages: primePy, docopt, tensorboardX, semver, ruamel.yaml.clib, lightning-utilities, colorlog, ruamel.yaml, pyannote.core, alembic, optuna, hyperpyyaml, torchmetrics, pytorch-metric-learning, pyannote.database, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch-audiomentations, lightning, pyannote.audio\n",
      "Successfully installed alembic-1.16.4 asteroid-filterbanks-0.4.0 colorlog-6.9.0 docopt-0.6.2 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.5.2 lightning-utilities-0.15.0 optuna-4.4.0 primePy-1.3 pyannote.audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.5.2 pytorch-metric-learning-2.8.1 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 semver-3.0.4 speechbrain-1.0.3 tensorboardX-2.6.4 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --break-system-packages pyannote.audio torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 25756,
     "status": "ok",
     "timestamp": 1754023565221,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "18p3Psr_Or2M"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1754023565258,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "xk9ilZoQRlCr"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# INPUT_AUDIO_PATH = \"call6.wav\"\n",
    "# CLEAN_AUDIO_PATH = \"cleaned_audio_for_asr_and_diarization.wav\"\n",
    "HUGGING_FACE_ACCESS_TOKEN = \"hf_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 66315,
     "status": "ok",
     "timestamp": 1754023631584,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "bqm2KjivRfeD",
    "outputId": "8f9383c6-44cd-4b2e-a9f2-f70fc09209c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [00:33<00:00, 91.0MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1754023631691,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "N4-pUEoiRfeD",
    "outputId": "a9f5c689-3f65-4629-94cf-2c71de085170"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51866, 1280)\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1754023631692,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "9XecuZI1O5xs"
   },
   "outputs": [],
   "source": [
    "def get_audio_duration(audio_path):\n",
    "    \"\"\"Get audio duration using ffprobe\"\"\"\n",
    "    try:\n",
    "        cmd = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
    "               \"-of\", \"default=noprint_wrappers=1:nokey=1\", audio_path]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "        return float(result.stdout.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Could not get duration: {e}\")\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1754023631843,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "chymACVjO50S"
   },
   "outputs": [],
   "source": [
    "def audio_preprocessing_v1(input_path, output_path):\n",
    "    \"\"\"Advanced audio preprocessing with better parameters\"\"\"\n",
    "    print(\"--- Trying Advanced Audio Preprocessing ---\")\n",
    "\n",
    "    # Improved ffmpeg command - less aggressive filtering to preserve speech\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ac\", \"1\",  # Mono\n",
    "        \"-ar\", \"16000\",  # 16kHz sample rate\n",
    "        \"-af\", \"loudnorm=I=-23:TP=-2:LRA=7,highpass=f=80,lowpass=f=8000,afftdn=nr=10\",\n",
    "        \"-y\", output_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "        print(\"Advanced preprocessing successful\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Advanced preprocessing failed: {e.returncode}\")\n",
    "        return False\n",
    "\n",
    "def audio_preprocessing_v2(input_path, output_path):\n",
    "    \"\"\"Simplified but effective preprocessing\"\"\"\n",
    "    print(\"--- Trying Simplified Audio Preprocessing ---\")\n",
    "\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ac\", \"1\",\n",
    "        \"-ar\", \"16000\",\n",
    "        \"-af\", \"loudnorm=I=-23:TP=-2,highpass=f=100\",\n",
    "        \"-y\", output_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "        print(\"Simplified preprocessing successful\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Simplified preprocessing failed: {e.returncode}\")\n",
    "        return False\n",
    "\n",
    "def audio_preprocessing_v3(input_path, output_path):\n",
    "    \"\"\"Basic but reliable preprocessing\"\"\"\n",
    "    print(\"--- Trying Basic Audio Preprocessing ---\")\n",
    "\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ac\", \"1\",\n",
    "        \"-ar\", \"16000\",\n",
    "        \"-af\", \"loudnorm\",\n",
    "        \"-y\", output_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "        print(\"Basic preprocessing successful\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Basic preprocessing failed: {e.returncode}\")\n",
    "        return False\n",
    "\n",
    "def audio_preprocessing_v4(input_path, output_path):\n",
    "    \"\"\"Minimal processing - just format conversion\"\"\"\n",
    "    print(\"--- Trying Minimal Audio Processing ---\")\n",
    "\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ac\", \"1\",\n",
    "        \"-ar\", \"16000\",\n",
    "        \"-y\", output_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "        print(\"Minimal processing successful\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Minimal processing failed: {e.returncode}\")\n",
    "        return False\n",
    "\n",
    "def smart_audio_preprocessing(input_path, output_path):\n",
    "    \"\"\"Try different preprocessing methods in order of preference\"\"\"\n",
    "    original_duration = get_audio_duration(input_path)\n",
    "    print(f\"Original audio duration: {original_duration:.2f} seconds\")\n",
    "\n",
    "    methods = [\n",
    "        audio_preprocessing_v1,\n",
    "        audio_preprocessing_v2,\n",
    "        audio_preprocessing_v3,\n",
    "        audio_preprocessing_v4\n",
    "    ]\n",
    "\n",
    "    for i, method in enumerate(methods, 1):\n",
    "        if method(input_path, output_path):\n",
    "            if os.path.exists(output_path):\n",
    "                processed_duration = get_audio_duration(output_path)\n",
    "                print(f\"Processed audio duration: {processed_duration:.2f} seconds\")\n",
    "\n",
    "                if abs(original_duration - processed_duration) < 1.0:\n",
    "                    print(f\"✅ Audio preprocessing successful with method {i}\")\n",
    "                    return True\n",
    "                else:\n",
    "                    print(f\"⚠️  Duration mismatch with method {i}, trying next...\")\n",
    "                    continue\n",
    "\n",
    "    print(\"❌ All preprocessing methods failed!\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1754023631849,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "gq_lrCJMF9Fm"
   },
   "outputs": [],
   "source": [
    "def post_process_text(text):\n",
    "    \"\"\"Clean up transcribed text from Whisper output for call center insurance context.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # === 1. Remove excessive immediate repetitions ===\n",
    "    words = text.split()\n",
    "    cleaned_words = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        current_word = words[i].lower()\n",
    "        repetition_count = 1\n",
    "        j = i + 1\n",
    "        while j < len(words) and words[j].lower() == current_word:\n",
    "            repetition_count += 1\n",
    "            j += 1\n",
    "\n",
    "        keep_count = min(repetition_count, 2) if repetition_count <= 3 else 1\n",
    "        for _ in range(keep_count):\n",
    "            cleaned_words.append(words[i])\n",
    "        i += repetition_count\n",
    "\n",
    "    text = ' '.join(cleaned_words)\n",
    "\n",
    "    # === 2. Remove filler sounds (non-verbal, repetitive) ===\n",
    "    filler_sounds = [\"uh\", \"um\", \"mm\", \"hmm\", \"ah\", \"oh\", \"huh\", \"ha ha\"]\n",
    "    soft_fillers = [\"okay okay\", \"yes yes\", \"yes yes yes\", \"i mean\", \"you know\", \"like like\", \"ok ok\"]\n",
    "\n",
    "    for filler in filler_sounds + soft_fillers:\n",
    "        text = re.sub(rf'\\b{re.escape(filler)}\\b', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # === 3. Insurance domain term normalization ===\n",
    "    corrections = {\n",
    "        'access max life': 'Axis Max Life',\n",
    "        'axis max life': 'Axis Max Life',\n",
    "        'g pay': 'GPay',\n",
    "        'google pay': 'Google Pay',\n",
    "        'phone pay': 'PhonePe',\n",
    "        'phone pe': 'PhonePe',\n",
    "        'pay tm': 'Paytm',\n",
    "        'net banking': 'netbanking',\n",
    "        'some assured': 'sum assured',\n",
    "        'premium do': 'premium due',\n",
    "        'do date': 'due date',\n",
    "        'okay sir': 'Okay sir',\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for wrong, correct in corrections.items():\n",
    "        text_lower = text_lower.replace(wrong, correct)\n",
    "\n",
    "    # === 3.5 Replace 'Rs.', 'Rs' → '₹' with optional space cleanup ===\n",
    "    text_lower = re.sub(r'\\brs[.]?\\s*', '₹', text_lower)\n",
    "\n",
    "    # === 4. Punctuation cleanup ===\n",
    "    text_lower = re.sub(r'\\s{2,}', ' ', text_lower)          # Extra spaces\n",
    "    text_lower = re.sub(r'[,]{2,}', ',', text_lower)         # Repeated commas\n",
    "    text_lower = re.sub(r'\\s+,', ',', text_lower)            # Space before comma\n",
    "    text_lower = re.sub(r'\\s+\\.', '.', text_lower)           # Space before period\n",
    "    text_lower = re.sub(r'\\s+[!?]', lambda m: m.group(0).strip(), text_lower)\n",
    "\n",
    "    # === 5. Capitalize sentences ===\n",
    "    text_lower = re.sub(r'(^|[.!?]\\s+)([a-z])',\n",
    "                        lambda m: m.group(1) + m.group(2).upper(),\n",
    "                        text_lower)\n",
    "\n",
    "    return text_lower.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1754023640480,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "vy-G7YeEU0TU"
   },
   "outputs": [],
   "source": [
    "def enhanced_whisper_transcription(audio_path):\n",
    "    \"\"\"\n",
    "    Enhanced Whisper transcription with optimal anti-repetition parameters\n",
    "    \"\"\"\n",
    "    print(\"--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\")\n",
    "\n",
    "    # prompt = (\n",
    "    #     \"Axis Maxlife Insurance, Policy number, fund value, Due date,\"\n",
    "    #     \"Sum Assured, Policy Status, Late Fee, Google Pay, GPay, PhonePe, Paytm, netbanking,\"\n",
    "    # )\n",
    "\n",
    "    prompt = (\n",
    "        \"This is a customer support call for Axis Maxlife Insurance. \"\n",
    "        \"We will discuss policy numbers, due date, fund value, sum assured, late fee, \"\n",
    "        \"and payment methods such as Google Pay, PhonePe, Paytm and net banking.\"\n",
    "    )\n",
    "\n",
    "    # Single optimal strategy - no need for multiple attempts\n",
    "    result = model.transcribe(\n",
    "        audio_path,\n",
    "        language=\"ta\",\n",
    "        task=\"translate\",\n",
    "        temperature=0.0,\n",
    "        beam_size=5,\n",
    "        patience=1.2,\n",
    "        condition_on_previous_text=False,\n",
    "        no_speech_threshold=0.8,\n",
    "        compression_ratio_threshold=2.0,\n",
    "        logprob_threshold=-0.35,\n",
    "        word_timestamps=False,\n",
    "        initial_prompt=prompt,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(\"✅ Whisper transcription completed with optimal parameters\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_repetition_score(segments):\n",
    "    \"\"\"\n",
    "    Calculate a repetition score for transcription segments\n",
    "    Lower score = less repetition = better\n",
    "    \"\"\"\n",
    "    if not segments:\n",
    "        return 0.0\n",
    "\n",
    "    total_repetition = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for segment in segments:\n",
    "        text = segment.get('text', '').strip().lower()\n",
    "        words = text.split()\n",
    "\n",
    "        if len(words) < 2:\n",
    "            continue\n",
    "\n",
    "        total_words += len(words)\n",
    "\n",
    "        # Count immediate word repetitions\n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i] == words[i + 1]:\n",
    "                total_repetition += 1\n",
    "\n",
    "        # Count phrase repetitions within segment\n",
    "        for phrase_len in range(2, min(len(words)//2 + 1, 6)):\n",
    "            for start in range(len(words) - phrase_len * 2 + 1):\n",
    "                phrase1 = ' '.join(words[start:start + phrase_len])\n",
    "                phrase2 = ' '.join(words[start + phrase_len:start + phrase_len * 2])\n",
    "                if phrase1 == phrase2:\n",
    "                    total_repetition += phrase_len * 2  # Heavy penalty\n",
    "\n",
    "    return total_repetition / max(total_words, 1)\n",
    "\n",
    "def detect_and_remove_repetitions(segments, max_repetition_ratio=0.3):\n",
    "    \"\"\"\n",
    "    AGGRESSIVE post-processing function to detect and remove repetitive segments\n",
    "    \"\"\"\n",
    "    print(\"🔍 Starting aggressive repetition detection...\")\n",
    "    cleaned_segments = []\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        text = segment['text'].strip()\n",
    "        words = text.split()\n",
    "\n",
    "        # Skip very short segments\n",
    "        if len(words) < 2:\n",
    "            continue\n",
    "\n",
    "        # AGGRESSIVE: Check for excessive word repetition\n",
    "        is_repetitive = False\n",
    "\n",
    "        # Count word frequencies\n",
    "        word_counts = {}\n",
    "        for word in words:\n",
    "            word_lower = word.lower().strip('.,!?')\n",
    "            word_counts[word_lower] = word_counts.get(word_lower, 0) + 1\n",
    "\n",
    "        # Check if any single word dominates the segment\n",
    "        max_word_count = max(word_counts.values()) if word_counts else 0\n",
    "        word_dominance = max_word_count / len(words) if words else 0\n",
    "\n",
    "        if word_dominance > 0.4:  # If any word is >40% of the segment\n",
    "            print(f\"🚫 Rejecting word-dominated segment: {text[:50]}... (dominance: {word_dominance:.2f})\")\n",
    "            continue\n",
    "\n",
    "        # Check for immediate repetitions (same word repeated consecutively)\n",
    "        consecutive_repeats = 0\n",
    "        max_consecutive = 0\n",
    "\n",
    "        for j in range(1, len(words)):\n",
    "            if words[j].lower().strip('.,!?') == words[j-1].lower().strip('.,!?'):\n",
    "                consecutive_repeats += 1\n",
    "                max_consecutive = max(max_consecutive, consecutive_repeats + 1)\n",
    "            else:\n",
    "                consecutive_repeats = 0\n",
    "\n",
    "        if max_consecutive > 3:  # More than 3 consecutive identical words\n",
    "            print(f\"🚫 Rejecting consecutive repeat segment: {text[:50]}... (max consecutive: {max_consecutive})\")\n",
    "            continue\n",
    "\n",
    "        # Check for pattern repetitions within segment\n",
    "        for phrase_len in range(2, min(len(words)//3 + 1, 8)):\n",
    "            for start in range(len(words) - phrase_len * 2 + 1):\n",
    "                phrase1 = ' '.join(words[start:start + phrase_len]).lower()\n",
    "                phrase2 = ' '.join(words[start + phrase_len:start + phrase_len * 2]).lower()\n",
    "\n",
    "                if phrase1 == phrase2:\n",
    "                    repetition_coverage = (phrase_len * 2) / len(words)\n",
    "                    if repetition_coverage > max_repetition_ratio:\n",
    "                        print(f\"🚫 Rejecting pattern repeat segment: {text[:50]}... (coverage: {repetition_coverage:.2f})\")\n",
    "                        is_repetitive = True\n",
    "                        break\n",
    "            if is_repetitive:\n",
    "                break\n",
    "\n",
    "        if is_repetitive:\n",
    "            continue\n",
    "\n",
    "        # Check for similarity with recent segments (avoid near-duplicates)\n",
    "        is_near_duplicate = False\n",
    "        for prev_segment in cleaned_segments[-5:]:  # Check last 5 segments\n",
    "            prev_words = prev_segment['text'].lower().split()\n",
    "            current_words = [w.lower() for w in words]\n",
    "\n",
    "            if prev_words and current_words:\n",
    "                # Calculate Jaccard similarity\n",
    "                prev_set = set(prev_words)\n",
    "                current_set = set(current_words)\n",
    "                intersection = len(prev_set.intersection(current_set))\n",
    "                union = len(prev_set.union(current_set))\n",
    "\n",
    "                similarity = intersection / union if union > 0 else 0\n",
    "\n",
    "                if similarity > 0.7 and abs(len(prev_words) - len(current_words)) < 5:\n",
    "                    print(f\"🚫 Rejecting near-duplicate: {text[:30]}... (similarity: {similarity:.2f})\")\n",
    "                    is_near_duplicate = True\n",
    "                    break\n",
    "\n",
    "        if is_near_duplicate:\n",
    "            continue\n",
    "\n",
    "        # If we reach here, the segment passed all checks\n",
    "        cleaned_segments.append(segment)\n",
    "\n",
    "    removed_count = len(segments) - len(cleaned_segments)\n",
    "    print(f\"📊 Aggressive cleaning: {len(segments)} → {len(cleaned_segments)} segments\")\n",
    "    print(f\"🗑️  Removed {removed_count} repetitive/problematic segments\")\n",
    "\n",
    "    return cleaned_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7873,
     "referenced_widgets": [
      "9759269eda364a97a64309c2c3bff868",
      "b409b271982b4fa7bc6e089af2b75d66",
      "71852b4d92584aa3870f4925c460bd00",
      "d5c324f33e4343d79dc7726ea1fe1cae",
      "07baadb518404839992da1a956f4bfc8",
      "1f753c9b11764a0a9adc5a53c1cdf884",
      "cbf7495aa8324669bec443f5af958d82",
      "23cad67056e641879b583e516628cc0c",
      "9993a6677a604715bdfe6a7a3af5cd92",
      "14d2864a531144249ef3300b2685147f",
      "940eb8fcffd844c6a8bef5cf98e87db9",
      "fa4398ce9bf84f7e930016de78459c7d",
      "d35e44a54065449db42f3771de599757",
      "cf1b1d1b173843f7bdf35d453c50e2d9",
      "f37f79208e7942ccbc9fbc1d16297b52",
      "d23813e47d0643289da0fbaac85ff383",
      "06b5560bf7ab4135a00cf49dca78429a",
      "44591331230b4eebbe2384ab738270d9",
      "615b74baff724f47b19d9ef2fd7089bc",
      "a1b412674d97411ba0e67e4efb0c4e26",
      "6f8d7b23ce644bd7b8be58b9265c12f6",
      "679b72fc9492496ab3edd8dcdb761749",
      "f37c05f9ac7c4a04a73ef440ac6cd1f6",
      "d502a0186a5c42de9afd8131a285f380",
      "72ea5bd9d9f34865a0484f85efdac580",
      "3670d3fd18304c0c958c31742ecf4319",
      "a6c324000060496dbdc4b2b7364f4757",
      "ffe051de7ed24380a20655b490fb79bc",
      "b83d2df7f3844a119ee1c0e518009797",
      "f342e4e47d5d4967b76683967926176c",
      "9108cbfd291f4b7a96e8281bc8e3cf43",
      "8099d7b687b140d0949de1e0093fea21",
      "c8a3216dfc8646ecbdd5a7c90a00d741",
      "a2596709245d47d9a1ee3b69442cbb04",
      "4dc83867c4cc4a38b5dbf9f543d9d52b",
      "038a567ee6da468cb476e609e5b118c8",
      "15e2ba8682124e3fbead9ad63f3e2cc0",
      "0229f60382f9489ba73b74b86d724302",
      "b0e09acc1a364d99acf645240b050526",
      "79b01027fb994047bb073d9434b34492",
      "5b3e4302807242ebb4e46a39cf075301",
      "7224382f32a6420295346bd84036a09d",
      "2d1bd7910644445595eca8f77b80d6e5",
      "570dee48526048a38233eb6a1da33056",
      "15f2a795d5374aedb2cd2a9075d627aa",
      "4771c3ecd0ef4d2d83d399e589694b64",
      "305e5e8498b04343b2e973ae2f9f0b06",
      "02b51f9993904929b0b6c6b9b7717a8b",
      "b3eecc7e6ab44753b816bad4d94c7cd7",
      "3103a0effb4a4e44b5daa1f40141ca01",
      "e2d42f1cabce4439bab80d3c384c18e1",
      "de06f05884ac481a8f46469a0c3983bc",
      "27a69e09d5be4c51826eb366f4ba1a0f",
      "34be10db43914491a4b6af68ab456f90",
      "d46500676a8c44098908fd1f0b0bfd3f"
     ]
    },
    "executionInfo": {
     "elapsed": 504651,
     "status": "ok",
     "timestamp": 1754024149459,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "wB3OJ0-WU6kA",
    "outputId": "1a9539d6-54b4-450b-8a70-f7415f19d93d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Found 5 files to process...\n",
      "\n",
      "📁 Processing file: call5.wav\n",
      "Original audio duration: 169.70 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 169.68 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\n",
      "[00:00.000 --> 00:04.000]  Hello, Good morning ma'am.\n",
      "[00:04.000 --> 00:05.000]  Yes ma'am.\n",
      "[00:05.000 --> 00:11.000]  I am calling from Axis Maxlife. I am from Sir.\n",
      "[00:11.000 --> 00:12.000]  Okay.\n",
      "[00:12.000 --> 00:13.000]  Hello.\n",
      "[00:13.000 --> 00:19.000]  Actually, I have received the payment yesterday ma'am. 12,574.65.\n",
      "[00:19.000 --> 00:20.000]  Okay.\n",
      "[00:20.000 --> 00:29.000]  Okay. The health declaration form is pending. Did you submit it online ma'am?\n",
      "[00:29.000 --> 00:35.000]  No, I haven't done the health declaration yet. I have already paid for it.\n",
      "[00:35.000 --> 00:38.000]  Okay, so the form hasn't been opened yet?\n",
      "[00:38.000 --> 00:39.000]  Not yet.\n",
      "[00:39.000 --> 00:46.000]  Okay, not yet. I will answer all the questions that you have asked. I am filling out the ASILM form and submitting it.\n",
      "[00:46.000 --> 00:52.000]  Okay, so sir, are you a salaried or self-employed?\n",
      "[00:52.000 --> 00:54.000]  I am a salaried.\n",
      "[00:54.000 --> 01:01.000]  Salary? Ok. Date of birth is 3-8-1973.\n",
      "[01:01.000 --> 01:05.000]  Ok. So, do you usually confirm?\n",
      "[01:05.000 --> 01:06.000]  Yes.\n",
      "[01:06.000 --> 01:08.000]  Monthly?\n",
      "[01:08.000 --> 01:12.000]  Normally, we change it.\n",
      "[01:12.000 --> 01:14.000]  What do you change?\n",
      "[01:14.000 --> 01:17.000]  Health and strong.\n",
      "[01:17.000 --> 01:18.000]  Sorry?\n",
      "[01:18.000 --> 01:22.000]  Health and strong.\n",
      "[01:22.000 --> 01:27.000]  Anamma, you have not been updated on this side. Please update on the other side.\n",
      "[01:27.000 --> 01:28.000]  Ok.\n",
      "[01:28.000 --> 01:31.000]  I have not been updated on the other side.\n",
      "[01:31.000 --> 01:33.000]  What have you changed?\n",
      "[01:33.000 --> 01:35.000]  I have not been updated on the website.\n",
      "[01:35.000 --> 01:36.000]  Have you not been updated on the website?\n",
      "[01:36.000 --> 01:37.000]  Yes.\n",
      "[01:37.000 --> 01:38.000]  Have you not been updated on the website?\n",
      "[01:38.000 --> 01:40.000]  I have not been updated on the website.\n",
      "[01:40.000 --> 01:43.000]  Ok, fine. What is your name?\n",
      "[01:43.000 --> 01:45.000]  Prasanna Nancy.\n",
      "[01:45.000 --> 01:46.000]  Prasanna Nancy.\n",
      "[01:46.000 --> 01:47.000]  Prasanna Nancy.\n",
      "[01:47.000 --> 01:54.000]  Prashanna, Nancy and Armstrong.\n",
      "[01:54.000 --> 02:11.000]  Okay ma'am. Sir's husband, I mean if he doesn't have a wife, can he say his father's name?\n",
      "[02:11.000 --> 02:14.000]  I don't know the age of the patient.\n",
      "[02:14.000 --> 02:18.000]  You don't know? Okay, fine.\n",
      "[02:18.000 --> 02:21.000]  So, Sir, previously you were suffering from COVID-19, right?\n",
      "[02:21.000 --> 02:23.000]  Did you get any treatment for COVID-19?\n",
      "[02:23.000 --> 02:24.000]  No, no.\n",
      "[02:24.000 --> 02:26.000]  Did you get any good health care?\n",
      "[02:26.000 --> 02:27.000]  Yes, yes.\n",
      "[02:27.000 --> 02:30.000]  Did you get any surgery for the past six months?\n",
      "[02:30.000 --> 02:31.000]  No, no.\n",
      "[02:31.000 --> 02:34.000]  Did you get any medicine for the alpha-chol consumption?\n",
      "[02:34.000 --> 02:35.000]  No, no.\n",
      "[02:35.000 --> 02:36.000]  Fine.\n",
      "[02:36.000 --> 02:38.000]  So, I will update you later. Thank you.\n",
      "[02:38.000 --> 02:39.000]  Thank you.\n",
      "[02:39.000 --> 02:41.000]  Thank you very much for your time.\n",
      "✅ Whisper transcription completed with optimal parameters\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting word-dominated segment: Yes ma'am.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Not yet.... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: Health and strong.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Have you not been updated on t... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: I have not been updated on the... (similarity: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Prasanna Nancy.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Prasanna Nancy.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Prasanna Nancy.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: No, no.... (dominance: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Yes, yes.... (dominance: 1.00)\n",
      "🚫 Rejecting word-dominated segment: No, no.... (dominance: 1.00)\n",
      "🚫 Rejecting word-dominated segment: No, no.... (dominance: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Thank you.... (dominance: 0.50)\n",
      "📊 Aggressive cleaning: 53 → 31 segments\n",
      "🗑️  Removed 22 repetitive/problematic segments\n",
      "🔊 Performing Speaker Diarization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9759269eda364a97a64309c2c3bff868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/469 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4398ce9bf84f7e930016de78459c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37c05f9ac7c4a04a73ef440ac6cd1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2596709245d47d9a1ee3b69442cbb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/26.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f2a795d5374aedb2cd2a9075d627aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/221 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved: call5_transcription.json\n",
      "\n",
      "📁 Processing file: call2.wav\n",
      "Original audio duration: 190.76 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 190.74 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\n",
      "[00:00.000 --> 00:10.000]  Hello! Greetings! My name is Aathi. We are calling from Licensure. This is an email call. You have taken a policy from Axis Maxlife Insurance. Can you speak for 2 minutes?\n",
      "[00:10.000 --> 00:18.000]  Yes, Madam. Quick call. I can't get it. If we cancel the policy, will it be refunded?\n",
      "[00:18.000 --> 00:23.000]  Okay. I will inform you about the details of your policy in a short time.\n",
      "[00:23.000 --> 00:27.000]  Okay.\n",
      "[00:27.000 --> 00:29.000]  Okay. Can you speak in Himalayan?\n",
      "[00:29.000 --> 00:31.000]  Yes.\n",
      "[00:31.000 --> 00:33.000]  Okay. Can you tell me the reason why you did not commit the crime?\n",
      "[00:33.000 --> 00:35.000]  I did not have a job.\n",
      "[00:35.000 --> 00:37.000]  I did not have a job.\n",
      "[00:37.000 --> 00:39.000]  Okay.\n",
      "[00:39.000 --> 00:41.000]  Okay. I understand the situation.\n",
      "[00:41.000 --> 00:43.000]  You have already made a payment for a year.\n",
      "[00:43.000 --> 00:45.000]  When you surrender after making the first payment,\n",
      "[00:45.000 --> 00:47.000]  do you have any attempts?\n",
      "[00:47.000 --> 00:49.000]  Because for the surrender value to be generated,\n",
      "[00:49.000 --> 00:51.000]  you should have made the payment for at least 3 years.\n",
      "[00:51.000 --> 00:53.000]  Usually, if you surrender after making the payment for at least 3 years,\n",
      "[00:53.000 --> 00:55.000]  usually, if you surrender for at least 3 years,\n",
      "[00:55.000 --> 00:57.000]  They will give you a surrender value of some amount.\n",
      "[00:57.000 --> 01:01.000]  But when you surrender after first year payment, there won't be any attempts.\n",
      "[01:01.000 --> 01:04.000]  You can at least take some time to continue.\n",
      "[01:04.000 --> 01:08.000]  How much will it cost if I do this now?\n",
      "[01:08.000 --> 01:14.000]  That's it. When you surrender after first year payment, there won't be any attempts.\n",
      "[01:14.000 --> 01:17.000]  You are saying that the amount will go like that.\n",
      "[01:17.000 --> 01:24.000]  Yes. Because if you pay for at least 3 years and surrender, then only the cash surrender value will be generated.\n",
      "[01:24.000 --> 01:28.000]  So, when you surrender, they will give you the surrender amount accordingly.\n",
      "[01:28.000 --> 01:32.000]  When you surrender with the first payment, will there be any other benefits?\n",
      "[01:32.000 --> 01:37.000]  Can you please continue with the timer for a while?\n",
      "[01:37.000 --> 01:39.000]  Yes, I will continue.\n",
      "[01:39.000 --> 01:42.000]  Okay, please tell me what you are thinking.\n",
      "[01:42.000 --> 01:45.000]  There are lapses in the policy status and there are holes in the summaries.\n",
      "[01:45.000 --> 01:47.000]  There will be no benefit in the lapses.\n",
      "[01:47.000 --> 01:51.000]  In case, there is a sudden policy change, there will be no benefit for us.\n",
      "[01:51.000 --> 01:59.000]  If the delay is too high according to the lay payment charges, you will have to pay the payment soon.\n",
      "[01:59.000 --> 02:04.000]  Your policy number is 149607129.\n",
      "[02:04.000 --> 02:08.000]  Next is Smart Wealth Advantage Growth Per Price Insta Income Fixed Return Policy.\n",
      "[02:08.000 --> 02:13.000]  You have to pay Rs.66,537 to cross Avanadu 102024.\n",
      "[02:43.000 --> 02:45.000]  Okay, I will call you back.\n",
      "[02:45.000 --> 02:50.000]  Okay ma'am. In case you need any special services, you can contact the branch.\n",
      "[02:50.000 --> 02:55.000]  I will submit the health declaration form. I will arrange for a call back next week.\n",
      "[02:55.000 --> 02:58.000]  Just inform me what you need. Okay?\n",
      "[02:58.000 --> 02:59.000]  Okay ma'am.\n",
      "[02:59.000 --> 03:01.000]  Any other questions?\n",
      "[03:01.000 --> 03:02.000]  No, ma'am.\n",
      "[03:02.000 --> 03:05.000]  Do you want to update anything via alternate mobile?\n",
      "[03:05.000 --> 03:06.000]  No, ma'am.\n",
      "[03:06.000 --> 03:10.000]  Okay ma'am. I will try to get access to you. Thank you.\n",
      "✅ Whisper transcription completed with optimal parameters\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting near-duplicate: I did not have a job.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: That's it. When you surrender ... (similarity: 0.80)\n",
      "🚫 Rejecting word-dominated segment: Okay ma'am.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: No, ma'am.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: No, ma'am.... (dominance: 0.50)\n",
      "📊 Aggressive cleaning: 47 → 39 segments\n",
      "🗑️  Removed 8 repetitive/problematic segments\n",
      "🔊 Performing Speaker Diarization...\n",
      "✅ Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved: call2_transcription.json\n",
      "\n",
      "📁 Processing file: call4.wav\n",
      "Original audio duration: 160.96 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 160.93 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\n",
      "[00:00.000 --> 00:02.000]  Hello!\n",
      "[00:02.000 --> 00:06.000]  Hello! My name is Axis Maxlife Insurance.\n",
      "[00:06.000 --> 00:08.000]  Hello!\n",
      "[00:08.000 --> 00:10.000]  My name is Salwa Kumar.\n",
      "[00:10.000 --> 00:12.000]  Hello!\n",
      "[00:12.000 --> 00:14.000]  I would like to ask you about the policy for Axis Maxlife Insurance.\n",
      "[00:14.000 --> 00:16.000]  Hello!\n",
      "[00:16.000 --> 00:18.000]  The policy for Axis Maxlife Insurance is,\n",
      "[00:18.000 --> 00:20.000]  The policy for Axis Maxlife Insurance is,\n",
      "[00:20.000 --> 00:22.000]  The policy for Axis Maxlife Insurance is,\n",
      "[00:22.000 --> 00:24.000]  The policy for Axis Maxlife Insurance is,\n",
      "[00:24.000 --> 00:27.000]  It is due on 6th June 2024.\n",
      "[00:27.000 --> 00:29.000]  The amount is Rs.1,200,000.\n",
      "[00:29.000 --> 00:33.000]  17 years have passed and now 2 years are due.\n",
      "[00:33.000 --> 00:34.000]  Yes.\n",
      "[00:34.000 --> 00:37.000]  When are you going to pay for this?\n",
      "[00:37.000 --> 00:40.000]  We will see if we can pay.\n",
      "[00:40.000 --> 00:42.000]  We have to finish it by the end of the year.\n",
      "[00:42.000 --> 00:47.000]  We will see if we can finish it by the end of the year.\n",
      "[00:47.000 --> 00:50.000]  We will see.\n",
      "[00:50.000 --> 00:54.000]  The plan is that you have to pay for the entire 5 years, right?\n",
      "[00:54.000 --> 00:55.000]  Yes.\n",
      "[00:55.000 --> 00:57.000]  So, you have already paid for 2 years.\n",
      "[00:57.000 --> 00:58.000]  Yes.\n",
      "[00:58.000 --> 00:59.000]  Now you have 2 years of life.\n",
      "[00:59.000 --> 01:01.000]  So, you have paid for these 2 years of life, right?\n",
      "[01:01.000 --> 01:02.000]  Yes.\n",
      "[01:02.000 --> 01:05.000]  So, next year you will have only 1 year of life.\n",
      "[01:05.000 --> 01:06.000]  Yes.\n",
      "[01:06.000 --> 01:09.000]  So, after that you will have 5 years of life.\n",
      "[01:09.000 --> 01:15.000]  So, if you look at the amount you have already paid so far, it will be Rs.1,200,000.\n",
      "[01:15.000 --> 01:16.000]  Yes.\n",
      "[01:16.000 --> 01:19.000]  So, if you look at your present fund value,\n",
      "[01:19.000 --> 01:25.000]  2 lakhs, 12000 rupees and 33300 rupees. Seriously, we are in a very high growth.\n",
      "[01:25.000 --> 01:26.000]  Yes, yes, yes.\n",
      "[01:26.000 --> 01:29.000]  So, if you don't pay now, you can keep it. That's what we want, sir.\n",
      "[01:29.000 --> 01:33.000]  But, if you pay now, it will be around 1 lakhs.\n",
      "[01:33.000 --> 01:37.000]  You will get a return of around 1 lakhs, without interest.\n",
      "[01:37.000 --> 01:38.000]  Yes, yes.\n",
      "[01:38.000 --> 01:40.000]  So, if you pay now, you can keep the remaining amount.\n",
      "[01:40.000 --> 01:44.000]  You can add interest to the company and give it to the community.\n",
      "[01:44.000 --> 01:45.000]  Yes, yes, yes.\n",
      "[01:45.000 --> 01:52.000]  If you want to add a discount, you will have to add a discounted fund.\n",
      "[01:52.000 --> 01:59.000]  If you add a discounted fund, you will not get that much returns and you will not have risk average.\n",
      "[01:59.000 --> 02:01.000]  Ok.\n",
      "[02:01.000 --> 02:03.000]  When will you show it?\n",
      "[02:03.000 --> 02:07.000]  I will talk to the VP and let you know.\n",
      "[02:07.000 --> 02:09.000]  Ok.\n",
      "[02:09.000 --> 02:12.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:12.000 --> 02:13.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:13.000 --> 02:14.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:14.000 --> 02:15.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:15.000 --> 02:16.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:16.000 --> 02:17.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:17.000 --> 02:18.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:18.000 --> 02:19.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:19.000 --> 02:20.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:20.000 --> 02:21.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:21.000 --> 02:22.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:22.000 --> 02:23.000]  Sir, I am calling to inform you that the health declaration is not complete.\n",
      "[02:23.000 --> 02:24.000]  Thank you sir.\n",
      "[02:24.000 --> 02:25.000]  Thank you sir.\n",
      "[02:25.000 --> 02:26.000]  Thank you sir.\n",
      "[02:26.000 --> 02:27.000]  Thank you sir.\n",
      "[02:27.000 --> 02:28.000]  Thank you sir.\n",
      "[02:28.000 --> 02:29.000]  Thank you sir.\n",
      "[02:29.000 --> 02:30.000]  Thank you sir.\n",
      "[02:30.000 --> 02:31.000]  Thank you sir.\n",
      "[02:31.000 --> 02:32.000]  Thank you sir.\n",
      "[02:32.000 --> 02:33.000]  Thank you sir.\n",
      "[02:33.000 --> 02:34.000]  Thank you sir.\n",
      "[02:34.000 --> 02:35.000]  Thank you sir.\n",
      "[02:35.000 --> 02:36.000]  Thank you sir.\n",
      "[02:36.000 --> 02:37.000]  Thank you sir.\n",
      "[02:37.000 --> 02:38.000]  Thank you sir.\n",
      "[02:38.000 --> 02:39.000]  Thank you sir.\n",
      "[02:39.000 --> 02:40.000]  Thank you sir.\n",
      "[02:40.000 --> 02:41.000]  Thank you sir.\n",
      "[02:41.000 --> 02:42.000]  Thank you sir.\n",
      "[02:42.000 --> 02:43.000]  Thank you sir.\n",
      "[02:43.000 --> 02:44.000]  Thank you sir.\n",
      "[02:44.000 --> 02:45.000]  Thank you sir.\n",
      "[02:45.000 --> 02:46.000]  Thank you sir.\n",
      "[02:46.000 --> 02:47.000]  Thank you sir.\n",
      "[02:47.000 --> 02:48.000]  Thank you sir.\n",
      "[02:48.000 --> 02:49.000]  Thank you sir.\n",
      "[02:49.000 --> 02:50.000]  Thank you sir.\n",
      "[02:50.000 --> 02:51.000]  Thank you sir.\n",
      "✅ Whisper transcription completed with optimal parameters\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting near-duplicate: The policy for Axis Maxlife In... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: The policy for Axis Maxlife In... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: The policy for Axis Maxlife In... (similarity: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Yes, yes, yes.... (dominance: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Yes, yes.... (dominance: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Yes, yes, yes.... (dominance: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am calling to inform yo... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you sir.... (similarity: 1.00)\n",
      "📊 Aggressive cleaning: 88 → 32 segments\n",
      "🗑️  Removed 56 repetitive/problematic segments\n",
      "🔊 Performing Speaker Diarization...\n",
      "✅ Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved: call4_transcription.json\n",
      "\n",
      "📁 Processing file: call1.wav\n",
      "Original audio duration: 106.92 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 106.89 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\n",
      "[00:00.000 --> 00:09.000]  Hello sir, I am Jai Prakash from Axis Maxlife. I am calling from Govindhara.\n",
      "[00:09.000 --> 00:14.000]  We have a renewal call for policy DVR. Shall we talk about the policy details?\n",
      "[00:44.000 --> 00:46.000]  It has been paid up.\n",
      "[00:46.000 --> 00:52.000]  Rs.1,14,713.47\n",
      "[00:54.000 --> 00:56.000]  The policy has been paid up.\n",
      "[00:56.000 --> 00:57.000]  It is not active.\n",
      "[00:57.000 --> 00:58.000]  It is not safe.\n",
      "[00:58.000 --> 00:59.000]  It is not safe.\n",
      "[00:59.000 --> 01:00.000]  It is not safe.\n",
      "[01:00.000 --> 01:01.000]  It is not safe.\n",
      "[01:01.000 --> 01:02.000]  It is not safe.\n",
      "[01:02.000 --> 01:03.000]  It is not safe.\n",
      "[01:03.000 --> 01:04.000]  It is not safe.\n",
      "[01:04.000 --> 01:05.000]  It is not safe.\n",
      "[01:05.000 --> 01:06.000]  It is not safe.\n",
      "[01:06.000 --> 01:07.000]  It is not safe.\n",
      "[01:07.000 --> 01:08.000]  It is not safe.\n",
      "[01:08.000 --> 01:09.000]  It is not safe.\n",
      "[01:09.000 --> 01:10.000]  It is not safe.\n",
      "[01:10.000 --> 01:11.000]  It is not safe.\n",
      "[01:11.000 --> 01:18.000]  It will take about 1 month.\n",
      "[01:18.000 --> 01:23.000]  You will have to pay the amount before that.\n",
      "[01:23.000 --> 01:28.000]  After some time, the rate will increase.\n",
      "[01:28.000 --> 01:33.000]  You will have to pay the amount before that.\n",
      "[01:33.000 --> 01:38.000]  You will have to pay the amount before that.\n",
      "[01:38.000 --> 01:40.000]  Thank you, sir.\n",
      "[01:40.000 --> 01:42.000]  Thank you, sir.\n",
      "[01:42.000 --> 01:44.000]  Thank you, sir.\n",
      "[01:44.000 --> 01:46.000]  Thank you, sir.\n",
      "✅ Whisper transcription completed with optimal parameters\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: It is not safe.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: You will have to pay the amoun... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: You will have to pay the amoun... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you, sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you, sir.... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Thank you, sir.... (similarity: 1.00)\n",
      "📊 Aggressive cleaning: 29 → 10 segments\n",
      "🗑️  Removed 19 repetitive/problematic segments\n",
      "🔊 Performing Speaker Diarization...\n",
      "✅ Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved: call1_transcription.json\n",
      "\n",
      "📁 Processing file: call3.wav\n",
      "Original audio duration: 140.72 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 140.69 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\n",
      "[00:00.000 --> 00:02.000]  Hello!\n",
      "[00:02.000 --> 00:05.000]  Hello! I am Chandra from Axis Maxlife Insurance.\n",
      "[00:05.000 --> 00:07.000]  What is this?\n",
      "[00:07.000 --> 00:09.000]  Axis Maxlife Insurance.\n",
      "[00:09.000 --> 00:11.000]  Yes, tell me.\n",
      "[00:11.000 --> 00:15.000]  Are you free to talk about Axis Maxlife Insurance policy for a minute?\n",
      "[00:15.000 --> 00:18.000]  Yes, I will.\n",
      "[00:18.000 --> 00:21.000]  One minute. I will set the date.\n",
      "[00:21.000 --> 00:25.000]  Russell B. Madan is speaking.\n",
      "[00:25.000 --> 00:27.000]  Yes.\n",
      "[00:27.000 --> 00:41.000]  The policy number is 142115666 and the total amount is Rs.3,522,10,898.\n",
      "[00:41.000 --> 00:44.000]  You have a one-year and two-year due.\n",
      "[00:44.000 --> 00:46.000]  When are you going to pay for this?\n",
      "[00:49.000 --> 00:51.000]  I will try to pay soon.\n",
      "[00:51.000 --> 00:53.000]  What is the reason for delay?\n",
      "[00:53.000 --> 01:02.000]  Yes, it is there. I told him that I will build it. He told me that he will build it soon and he will build it.\n",
      "[01:02.000 --> 01:04.000]  Have you already informed him?\n",
      "[01:04.000 --> 01:05.000]  Yes.\n",
      "[01:05.000 --> 01:07.000]  Do you have your phone number?\n",
      "[01:07.000 --> 01:17.000]  No, they called me. I told him that I will build it. He told me that he will build it.\n",
      "[01:17.000 --> 01:19.000]  When are you going to build it?\n",
      "[01:19.000 --> 01:26.000]  If the policy is in lapse, then you will not have risk coverage.\n",
      "[01:26.000 --> 01:28.000]  So, you have to add the lump sum at the end.\n",
      "[01:28.000 --> 01:30.000]  4 years guarantee addition and maturity.\n",
      "[01:30.000 --> 01:33.000]  This benefit will be lost to you.\n",
      "[01:33.000 --> 01:36.000]  Plus, the rate fee charges will be added on a daily basis.\n",
      "[01:36.000 --> 01:38.000]  If the rate fee charges have already been added,\n",
      "[01:38.000 --> 01:41.000]  that 8,628 rupees has been added.\n",
      "[01:41.000 --> 01:43.000]  Now, if you make a delay,\n",
      "[01:43.000 --> 01:46.000]  the rate fee charges will be added more.\n",
      "[01:46.000 --> 01:50.000]  So, what year are you pending?\n",
      "[01:50.000 --> 01:55.000]  I am pending the same year.\n",
      "[01:55.000 --> 02:00.000]  Really?\n",
      "[02:00.000 --> 02:02.000]  Yes.\n",
      "[02:02.000 --> 02:07.000]  Yes, try to complete it within 2 months.\n",
      "[02:07.000 --> 02:11.000]  The health declaration form is also pending.\n",
      "[02:11.000 --> 02:15.000]  So, we have to pay you back as soon as we get the bulk of the electric charge, is that okay?\n",
      "[02:15.000 --> 02:17.000]  Yes, sir.\n",
      "[02:17.000 --> 02:19.000]  Thank you very much.\n",
      "[02:19.000 --> 02:21.000]  Thank you.\n",
      "✅ Whisper transcription completed with optimal parameters\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting word-dominated segment: Yes, sir.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Thank you.... (dominance: 0.50)\n",
      "📊 Aggressive cleaning: 40 → 33 segments\n",
      "🗑️  Removed 7 repetitive/problematic segments\n",
      "🔊 Performing Speaker Diarization...\n",
      "✅ Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved: call3_transcription.json\n",
      "\n",
      "📄 Training manifest saved to: processed_output/training_manifest.jsonl\n",
      "✅ All files processed.\n"
     ]
    }
   ],
   "source": [
    "# Directory paths\n",
    "INPUT_DIR = Path(\"training_data\")\n",
    "OUTPUT_DIR = Path(\"processed_output\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Manifest for Whisper fine-tuning\n",
    "manifest_path = OUTPUT_DIR / \"training_manifest.jsonl\"\n",
    "manifest_entries = []\n",
    "\n",
    "def process_single_file(audio_file_path):\n",
    "    print(f\"\\n📁 Processing file: {audio_file_path.name}\")\n",
    "    clean_audio_path = OUTPUT_DIR / f\"{audio_file_path.stem}_clean.wav\"\n",
    "    json_output_path = OUTPUT_DIR / f\"{audio_file_path.stem}_transcription.json\"\n",
    "\n",
    "    if not smart_audio_preprocessing(str(audio_file_path), str(clean_audio_path)):\n",
    "        print(\"❌ Preprocessing failed, skipping file.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        whisper_result = enhanced_whisper_transcription(str(clean_audio_path))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Whisper transcription failed: {e}\")\n",
    "        return\n",
    "\n",
    "    cleaned_segments = detect_and_remove_repetitions(whisper_result[\"segments\"])\n",
    "\n",
    "    processed_segments = []\n",
    "    for segment in cleaned_segments:\n",
    "        cleaned = post_process_text(segment['text'])\n",
    "        if cleaned.strip() and len(cleaned.strip()) > 5:\n",
    "            new_segment = segment.copy()\n",
    "            new_segment['text'] = cleaned\n",
    "            processed_segments.append(new_segment)\n",
    "\n",
    "    whisper_result[\"segments\"] = processed_segments\n",
    "\n",
    "    print(\"🔊 Performing Speaker Diarization...\")\n",
    "    try:\n",
    "        pipeline = Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-diarization-3.1\",\n",
    "            use_auth_token=HUGGING_FACE_ACCESS_TOKEN\n",
    "        )\n",
    "        if torch.cuda.is_available():\n",
    "            pipeline.to(torch.device(\"cuda\"))\n",
    "            print(\"✅ Using GPU\")\n",
    "        diarization = pipeline(str(clean_audio_path))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Diarization failed: {e}\")\n",
    "        diarization = None\n",
    "\n",
    "    def get_dominant_speaker(start, end, diarization_result):\n",
    "        if not diarization_result:\n",
    "            return \"Speaker_Unknown\"\n",
    "        speakers = {}\n",
    "        for segment, _, speaker in diarization_result.itertracks(yield_label=True):\n",
    "            overlap = max(0, min(end, segment.end) - max(start, segment.start))\n",
    "            if overlap > 0:\n",
    "                speakers[speaker] = speakers.get(speaker, 0) + overlap\n",
    "        return max(speakers, key=speakers.get) if speakers else \"Speaker_Unknown\"\n",
    "\n",
    "    dialogue = []\n",
    "    current_speaker, current_texts, current_start, current_end = None, [], 0, 0\n",
    "    for seg in processed_segments:\n",
    "        start, end, text = seg['start'], seg['end'], seg['text'].strip()\n",
    "        speaker = get_dominant_speaker(start, end, diarization)\n",
    "        if (speaker == current_speaker and current_speaker and (start - current_end) < 3.0):\n",
    "            current_texts.append(text)\n",
    "            current_end = end\n",
    "        else:\n",
    "            if current_speaker and current_texts:\n",
    "                combined = ' '.join(current_texts)\n",
    "                if len(combined.strip()) > 10:\n",
    "                    dialogue.append({\n",
    "                        'speaker': current_speaker,\n",
    "                        'text': combined,\n",
    "                        'start_time': current_start,\n",
    "                        'end_time': current_end\n",
    "                    })\n",
    "            current_speaker, current_texts, current_start, current_end = speaker, [text], start, end\n",
    "\n",
    "    if current_speaker and current_texts:\n",
    "        combined = ' '.join(current_texts)\n",
    "        if len(combined.strip()) > 10:\n",
    "            dialogue.append({\n",
    "                'speaker': current_speaker,\n",
    "                'text': combined,\n",
    "                'start_time': current_start,\n",
    "                'end_time': current_end\n",
    "            })\n",
    "\n",
    "    # Save JSON per file\n",
    "    output_data = {\n",
    "        'metadata': {\n",
    "            'audio_file': str(audio_file_path.name),\n",
    "            'total_duration': whisper_result.get('duration', 0),\n",
    "            'total_speakers': len(set(d['speaker'] for d in dialogue)),\n",
    "            'total_segments': len(dialogue),\n",
    "            'model_used': 'whisper-large',\n",
    "            'processing_successful': True,\n",
    "            'anti_repetition_applied': True\n",
    "        },\n",
    "        'dialogue': dialogue,\n",
    "        'raw_transcription': whisper_result\n",
    "    }\n",
    "\n",
    "    with open(json_output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"✅ Output saved: {json_output_path.name}\")\n",
    "\n",
    "    # Generate final conversation string\n",
    "    full_text = \"\\n\".join([f\"{d['speaker']}: {d['text']}\" for d in dialogue])\n",
    "\n",
    "    # Add to manifest entry\n",
    "    manifest_entries.append({\n",
    "        \"audio_filepath\": str(clean_audio_path),\n",
    "        \"text\": full_text,\n",
    "        \"language\": \"ta\",\n",
    "        \"task\": \"translate\"\n",
    "    })\n",
    "\n",
    "def main():\n",
    "    audio_files = list(INPUT_DIR.glob(\"*.wav\"))\n",
    "    if not audio_files:\n",
    "        print(\"❌ No .wav files found in 'training_data/' folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"🚀 Found {len(audio_files)} files to process...\")\n",
    "    for audio_file in audio_files:\n",
    "        process_single_file(audio_file)\n",
    "\n",
    "    # Save consolidated JSONL manifest\n",
    "    with open(manifest_path, 'w', encoding='utf-8') as f:\n",
    "        for entry in manifest_entries:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"\\n📄 Training manifest saved to: {manifest_path}\")\n",
    "    print(\"✅ All files processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1408,
     "status": "ok",
     "timestamp": 1754024356130,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "Q6afRkkpnZ2W",
    "outputId": "c89a777e-349c-44ae-ef51-bdc22e40b7e8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/processed_output1-5.zip'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Zip the folder into processed_outputs.zip\n",
    "shutil.make_archive('processed_output1-5', 'zip', 'processed_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1754024356786,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "OREdJIxgncHI",
    "outputId": "8b74b457-a76a-4693-e7d8-eea967315d3f"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_b08bc8ad-a950-420f-a540-c118481ad5c8\", \"processed_output1-5.zip\", 19367965)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download the zipped folder\n",
    "files.download('processed_output1-5.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGOh_sgMALiK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDXUN_jUALk4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THuLmMgFALoV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "si_qcA-CALp9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElWSLQtWALst"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mmZN82yALvq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 798081,
     "status": "ok",
     "timestamp": 1754025237983,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "-HiGuJJyALxl",
    "outputId": "9602213c-e5a7-4299-aacd-a9cd2e0e1c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Found 5 files to process...\n",
      "\n",
      "📁 Processing file: call6.wav\n",
      "Original audio duration: 172.48 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 172.45 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\n",
      "[00:00.000 --> 00:06.000]  Good afternoon ma'am. I am calling from Axis Maxlife for renewal.\n",
      "[00:06.000 --> 00:09.000]  I am calling for renewal.\n",
      "[00:09.000 --> 00:12.000]  Hello.\n",
      "[00:12.000 --> 00:15.000]  Hello.\n",
      "[00:15.000 --> 00:18.000]  Hello.\n",
      "[00:18.000 --> 00:20.000]  Hello.\n",
      "[00:20.000 --> 00:22.000]  Hello ma'am. Good afternoon.\n",
      "[00:22.000 --> 00:23.000]  Yes, tell me ma'am.\n",
      "[00:23.000 --> 00:28.000]  I am calling from Axis Maxlife. Do you know who is Ms. Maheshwari Vinodkumar?\n",
      "[00:28.000 --> 00:32.000]  It's my madam.\n",
      "[00:32.000 --> 00:36.000]  There is a policy in her name. We have called her to talk about it.\n",
      "[00:36.000 --> 00:43.000]  You spoke to her once the other day. She even told my staff about it.\n",
      "[00:43.000 --> 00:47.000]  What have you updated, madam?\n",
      "[00:47.000 --> 00:53.000]  One minute. One minute, madam. I will talk to my staff.\n",
      "[00:53.000 --> 00:58.000]  Yes, but till last month they have said that they will be paying for it.\n",
      "[01:23.000 --> 01:25.000]  Hello ma'am\n",
      "[01:25.000 --> 01:30.000]  Ma'am, they are saying that they will pay you on Monday\n",
      "[01:30.000 --> 01:37.000]  Monday? Okay ma'am, they have already said that they will pay you, that's why we are calling you\n",
      "[01:37.000 --> 01:41.000]  Okay ma'am, they are saying that they will pay you on Monday\n",
      "[01:41.000 --> 01:43.000]  Will they pay you on Monday for sure ma'am?\n",
      "[01:43.000 --> 01:45.000]  Yes ma'am\n",
      "[01:45.000 --> 01:49.000]  Okay, will they do it in the branch or online?\n",
      "[01:49.000 --> 01:51.000]  Online only ma'am\n",
      "[01:51.000 --> 01:58.000]  Your apology will be active only if you submit the health declaration form once you make the payment.\n",
      "[01:58.000 --> 02:00.000]  Okay ma'am.\n",
      "[02:00.000 --> 02:02.000]  Okay ma'am.\n",
      "[02:02.000 --> 02:06.000]  Do you have any alternative phone number or email id?\n",
      "[02:06.000 --> 02:12.000]  I don't have any number. Do you have this number?\n",
      "[02:12.000 --> 02:22.000]  This is the number ma'am. It's 999-400-90809.\n",
      "[02:22.000 --> 02:27.000]  Yes, that's the number ma'am. You can take that too.\n",
      "[02:27.000 --> 02:31.000]  Okay ma'am, fine. Thank you ma'am for giving me time.\n",
      "[02:31.000 --> 02:33.000]  Okay ma'am.\n",
      "[02:33.000 --> 02:48.000]  I will disconnect the call from the customer's side.\n",
      "[02:48.000 --> 02:52.000]  I will disconnect the call from the customer's side.\n",
      "✅ Whisper transcription completed with optimal parameters\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting word-dominated segment: Hello ma'am... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: Okay ma'am, they are saying th... (similarity: 0.91)\n",
      "🚫 Rejecting word-dominated segment: Yes ma'am... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Okay ma'am.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Okay ma'am.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Okay ma'am.... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: I will disconnect the call fro... (similarity: 1.00)\n",
      "📊 Aggressive cleaning: 34 → 23 segments\n",
      "🗑️  Removed 11 repetitive/problematic segments\n",
      "🔊 Performing Speaker Diarization...\n",
      "✅ Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved: call6_transcription.json\n",
      "\n",
      "📁 Processing file: call9.wav\n",
      "Original audio duration: 326.84 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 326.81 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\n",
      "[00:00.000 --> 00:07.000]  Hello. Good morning sir. My name is Anand. I am a customer support for Axis Maxlife Insurance.\n",
      "[00:07.000 --> 00:09.000]  I am from Maths Science Institute.\n",
      "[00:09.000 --> 00:11.000]  Hello.\n",
      "[00:11.000 --> 00:13.000]  Yes.\n",
      "[00:13.000 --> 00:15.000]  This is Mr. Kannan Thyagaraj.\n",
      "[00:15.000 --> 00:17.000]  Yes Madam.\n",
      "[00:17.000 --> 00:19.000]  Sir, do you have a policy?\n",
      "[00:19.000 --> 00:21.000]  I have called for policy renewal.\n",
      "[00:21.000 --> 00:23.000]  Can I talk to you for 2 minutes?\n",
      "[00:23.000 --> 00:25.000]  What is the procedure to close the policy?\n",
      "[00:27.000 --> 00:29.000]  Actually, if you want to close it,\n",
      "[00:29.000 --> 00:31.000]  for your surrender,\n",
      "[00:31.000 --> 00:33.000]  you have to take a bond paper.\n",
      "[00:33.000 --> 00:35.000]  Do you have a bond paper?\n",
      "[00:35.000 --> 00:39.600]  If you submit it in the branch, they will surrender it.\n",
      "[00:39.600 --> 00:50.000]  But if you surrender, the amount will not be refunded because the policy is in lapse.\n",
      "[00:50.000 --> 00:55.800]  As it is in lapse, the amount will not be refunded.\n",
      "[00:55.800 --> 01:00.800]  If you pay minimum 2-3 years, the amount will be refunded.\n",
      "[01:00.800 --> 01:03.800]  The amount I have paid is enough for now.\n",
      "[01:03.800 --> 01:07.800]  The amount you have paid will not be refunded to you, sir.\n",
      "[01:07.800 --> 01:10.800]  Okay, madam. No problem at all. Thank you very much, madam.\n",
      "[01:10.800 --> 01:15.800]  Okay. What is the reason for closing the shop?\n",
      "[01:15.800 --> 01:18.800]  My support is good, madam. There is no problem.\n",
      "[01:18.800 --> 01:23.800]  I can only pay for my business. I can't pay for my company's business.\n",
      "[01:23.800 --> 01:26.800]  I have informed all of them.\n",
      "[01:26.800 --> 01:31.800]  I am talking about renewals. I don't have any remedy for that.\n",
      "[01:31.800 --> 01:35.800]  Can you tell me what issues you are facing?\n",
      "[01:35.800 --> 01:40.800]  When I started, they gave me auto debit option.\n",
      "[01:40.800 --> 01:44.800]  I didn't have any problem with that.\n",
      "[01:44.800 --> 01:48.800]  Now I am paying for the house.\n",
      "[01:48.800 --> 01:51.800]  I am paying for the time I am paying.\n",
      "[01:51.800 --> 01:55.800]  I am asking them to give me auto debit option.\n",
      "[01:55.800 --> 01:57.800]  Auto Debit Auction\n",
      "[01:57.800 --> 02:00.800]  Auto Debit Auction will be cancelled\n",
      "[02:00.800 --> 02:02.800]  Yes, it will be cancelled\n",
      "[02:02.800 --> 02:04.800]  Auto Debit Auction will be cancelled\n",
      "[02:04.800 --> 02:06.800]  I have to pay the money\n",
      "[02:06.800 --> 02:09.800]  Ok Sir, actually we are the Renewal Department\n",
      "[02:09.800 --> 02:12.800]  In case if you go to any branch\n",
      "[02:12.800 --> 02:16.800]  You can directly inform them\n",
      "[02:16.800 --> 02:18.800]  Auto Debit Auction will be closed\n",
      "[02:18.800 --> 02:21.800]  Now you are in insufficient balance\n",
      "[02:21.800 --> 02:23.800]  Is that correct?\n",
      "[02:23.800 --> 02:26.800]  Yes ma'am. I have a sufficient balance and insufficient balance.\n",
      "[02:26.800 --> 02:28.800]  Ok, ok. You have sufficient balance.\n",
      "[02:28.800 --> 02:31.800]  I am unable to do any other transaction. I am facing unnecessary issues.\n",
      "[02:31.800 --> 02:39.800]  Ok, ok sir. Actually, if you have the amount of Rs.32,000, they will take your amount in auto debit.\n",
      "[02:39.800 --> 02:43.800]  Otherwise, you will not have any problem. I will show you the insufficient balance.\n",
      "[02:43.800 --> 02:48.800]  Ok, ok. If I have the amount, I have bought the housing loan for the transaction in that bank.\n",
      "[02:48.800 --> 02:50.800]  I have bought it in that account.\n",
      "[02:50.800 --> 02:54.800]  If the transaction is done correctly, I will not face any problem.\n",
      "[02:54.800 --> 02:58.800]  I will maintain the amount according to the account.\n",
      "[02:58.800 --> 02:59.800]  Okay.\n",
      "[02:59.800 --> 03:04.800]  You will get the benefit if you pay the amount.\n",
      "[03:04.800 --> 03:05.800]  That's why I am telling you.\n",
      "[03:05.800 --> 03:13.800]  Once you go to the branch, cancel the order.\n",
      "[03:13.800 --> 03:19.800]  After canceling, you can refund to them.\n",
      "[03:19.800 --> 03:27.800]  If you want to cancel the auto debit option, you have to pay this payment first and then cancel it.\n",
      "[03:27.800 --> 03:37.800]  No sir, once you come to the branch and tell them that you can only pay when you can,\n",
      "[03:37.800 --> 03:43.800]  they will tell you and then they will tell you to close such accounts.\n",
      "[03:43.800 --> 03:49.800]  Because they are asking you to pay for late payment only because you have added late payment charges.\n",
      "[03:49.800 --> 03:55.800]  If you tell them without telling them, we will pay for late payment.\n",
      "[03:55.800 --> 03:57.800]  If we tell them, we are going to put it in the account and we are going to pay for it.\n",
      "[03:57.800 --> 03:58.800]  Yes sir.\n",
      "[03:58.800 --> 04:00.800]  How long will it take for them to take it and give it to you?\n",
      "[04:00.800 --> 04:01.800]  How long will it take?\n",
      "[04:01.800 --> 04:02.800]  I understand sir.\n",
      "[04:02.800 --> 04:04.800]  Sorry sir.\n",
      "[04:04.800 --> 04:09.800]  Those who don't even give that small option will not help me in future.\n",
      "[04:09.800 --> 04:10.800]  I understand sir.\n",
      "[04:10.800 --> 04:15.400]  I understand sir. But the amount is coming to everyone. There is no problem with that.\n",
      "[04:15.400 --> 04:17.400]  The benefits will come correctly.\n",
      "[04:17.400 --> 04:19.400]  Because you can go and ask for it.\n",
      "[04:19.400 --> 04:21.400]  You pay the amount.\n",
      "[04:21.400 --> 04:23.400]  You can ask in the branch. I will do it.\n",
      "[04:23.400 --> 04:28.400]  Okay sir. If you don't have a late payment charge, you can also pay online.\n",
      "[04:28.400 --> 04:32.400]  We have waived off the late payment charge from our side.\n",
      "[04:32.400 --> 04:34.400]  Online payment is not done at all.\n",
      "[04:34.400 --> 04:37.400]  I can do anything only if I take the auto debit option.\n",
      "[04:37.400 --> 04:38.400]  Okay sir.\n",
      "[04:38.400 --> 04:43.400]  You can tell them that you are ready to pay. I will pay. If they don't take it back, what will we do?\n",
      "[04:43.400 --> 04:47.400]  No, sir. They will definitely do it. You can contact them online.\n",
      "[04:47.400 --> 04:49.400]  Okay, ma'am. I will contact them in the branch.\n",
      "[04:49.400 --> 04:51.400]  Okay. Check in the branch and update, sir.\n",
      "[04:51.400 --> 04:52.400]  Okay, ma'am.\n",
      "[04:52.400 --> 04:54.400]  Do you have a mobile number?\n",
      "[04:54.400 --> 04:58.400]  Yes, I have a mobile number, ma'am. I have given my email address.\n",
      "[04:58.400 --> 05:02.400]  Okay, sir. Thank you for giving us the time, sir.\n",
      "[05:02.400 --> 05:03.400]  Thanks, ma'am.\n",
      "[05:03.400 --> 05:04.400]  Okay.\n",
      "[05:04.400 --> 05:05.400]  Okay.\n",
      "[05:08.400 --> 05:12.400]  Sir, I am trying to disconnect the call.\n",
      "[05:12.400 --> 05:14.400]  Sir, I am trying to disconnect the call.\n",
      "[05:14.400 --> 05:16.400]  Sir, I am trying to disconnect the call.\n",
      "[05:16.400 --> 05:18.400]  Sir, I am trying to disconnect the call.\n",
      "[05:18.400 --> 05:20.400]  Sir, I am trying to disconnect the call.\n",
      "[05:20.400 --> 05:22.400]  Sir, I am trying to disconnect the call.\n",
      "[05:22.400 --> 05:24.400]  Sir, I am trying to disconnect the call.\n",
      "[05:24.400 --> 05:26.400]  Sir, I am trying to disconnect the call.\n",
      "[05:26.400 --> 05:28.400]  Sir, I am trying to disconnect the call.\n",
      "[05:28.400 --> 05:30.400]  Sir, I am trying to disconnect the call.\n",
      "[05:30.400 --> 05:32.400]  Sir, I am trying to disconnect the call.\n",
      "[05:32.400 --> 05:34.400]  Sir, I am trying to disconnect the call.\n",
      "[05:34.400 --> 05:36.400]  Sir, I am trying to disconnect the call.\n",
      "✅ Whisper transcription completed with optimal parameters\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting word-dominated segment: Yes Madam.... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: Auto Debit Auction will be can... (similarity: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Yes sir.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Sorry sir.... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: I understand sir.... (similarity: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Okay sir.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Okay, ma'am.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Thanks, ma'am.... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Sir, I am trying to disconnect... (similarity: 1.00)\n",
      "📊 Aggressive cleaning: 104 → 79 segments\n",
      "🗑️  Removed 25 repetitive/problematic segments\n",
      "🔊 Performing Speaker Diarization...\n",
      "✅ Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved: call9_transcription.json\n",
      "\n",
      "📁 Processing file: call10.wav\n",
      "Original audio duration: 439.42 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 439.39 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\n",
      "[00:00.000 --> 00:07.000]  Good afternoon, sir. I am K. R. Singh. We are talking about Axis Maxlife Insurance.\n",
      "[00:07.000 --> 00:09.000]  Yes, tell me.\n",
      "[00:09.000 --> 00:11.000]  Do you know Ms. Mala's name?\n",
      "[00:11.000 --> 00:14.000]  I am the one who took the policy.\n",
      "[00:14.000 --> 00:20.000]  Okay, okay, sir. Actually, we have a policy in our name. We have called the policy for anyone.\n",
      "[00:20.000 --> 00:23.000]  We will talk to you for 2 minutes, sir.\n",
      "[00:23.000 --> 00:24.000]  Yes, tell me.\n",
      "[00:24.000 --> 00:25.000]  Thank you, sir.\n",
      "[00:25.000 --> 00:35.000]  Policy number is 333-744-8419. Plan name is Life Co-Fair Partner Super Plan. You have stayed for 3 years.\n",
      "[00:35.000 --> 00:37.000]  You will be rewired for 3 years.\n",
      "[00:37.000 --> 00:39.000]  Yes, completely.\n",
      "[00:39.000 --> 00:44.000]  Due date is 24th, 3rd month, 2023.\n",
      "[00:44.000 --> 00:50.000]  And due amount is Rs.175,426.21.\n",
      "[00:50.000 --> 00:54.000]  Because of the renewal, the policy status is now paid up.\n",
      "[00:54.000 --> 00:58.000]  So because of the pay up, the amount is reduced day by day.\n",
      "[00:58.000 --> 01:03.000]  The current value is Rs.158,111.\n",
      "[01:03.000 --> 01:06.000]  That amount has been reduced for you.\n",
      "[01:06.000 --> 01:08.000]  And the rate payment charge has been added to you.\n",
      "[01:08.000 --> 01:12.000]  Sir, can we know why you have to renew for the current request?\n",
      "[01:12.000 --> 01:16.000]  I don't know.\n",
      "[01:16.000 --> 01:18.000]  Okay, okay sir.\n",
      "[01:18.000 --> 01:27.000]  Even if you don't understand the situation, if you don't take a trade-off, even if there is an uncertainty in the trade-off, they will not give you the full amount.\n",
      "[01:27.000 --> 01:43.000]  The sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum of the sum\n",
      "[01:43.000 --> 01:49.000]  Your minimum amount is Rs.175,446.\n",
      "[01:53.000 --> 01:57.000]  Can you confirm that you can pay in any amount?\n",
      "[01:58.000 --> 02:02.000]  I will try. I will tell you later.\n",
      "[02:03.000 --> 02:06.000]  Ok. I will touch the details and let you know.\n",
      "[02:13.000 --> 02:31.000]  Hello. Sir, actually you have four policies. Three policies are side up and one policy is discontinued.\n",
      "[02:31.000 --> 02:33.000]  It comes under three policies.\n",
      "[02:35.000 --> 02:37.000]  This policy is for you.\n",
      "[02:37.000 --> 02:39.000]  This policy is for you.\n",
      "[02:39.000 --> 02:41.000]  Okay, sir. 30 seconds.\n",
      "[04:01.000 --> 04:16.000]  One second sir, actually due to some technical issue, we are not able to check you.\n",
      "[04:16.000 --> 04:20.000]  Ok, we will take care of it. Next week, we will see.\n",
      "[04:20.000 --> 04:25.000]  Sir, actually you are not here. Thank you sir for the line number first of all.\n",
      "[04:25.000 --> 04:30.000]  You have been paying for 5 years.\n",
      "[04:30.000 --> 04:33.000]  So your policy is still active.\n",
      "[04:33.000 --> 04:34.000]  I don't understand sir.\n",
      "[04:34.000 --> 04:35.000]  What policy?\n",
      "[04:35.000 --> 04:41.000]  Actually you came and said that you have a discontinued policy.\n",
      "[04:46.000 --> 04:48.000]  Discontinued policy. I told you.\n",
      "[04:48.000 --> 04:55.000]  Yes, this is a discontinued policy. If you look at the total amount, the payment amount is 5 years.\n",
      "[04:55.000 --> 05:00.000]  So, you have been paying for 5 years, right?\n",
      "[05:00.000 --> 05:04.000]  Yes, I have been paying for 1 year.\n",
      "[05:04.000 --> 05:07.000]  Sir, you have been paying for 5 years, right?\n",
      "[05:07.000 --> 05:08.000]  Yes.\n",
      "[05:08.000 --> 05:10.000]  What is the name of the policy?\n",
      "[05:10.000 --> 05:22.000]  The name of the policy is 4 0 3 5 2 0 1 2 5. The name of the plan is Fault Track Plan.\n",
      "[05:22.000 --> 05:28.000]  You have taken a unique policy. Fault Track Plan.\n",
      "[05:28.000 --> 05:33.000]  Fault Track Plan. Yes, that is it.\n",
      "[05:33.000 --> 05:35.000]  Yes, that's it.\n",
      "[05:35.000 --> 05:41.000]  Let's see if there is a policy called wealth plus.\n",
      "[05:41.000 --> 05:43.000]  One minute sir.\n",
      "[05:43.000 --> 05:47.000]  Let's see if there is a policy called wealth plus.\n",
      "[05:47.000 --> 05:51.000]  Let's see if there is a policy called wealth plus.\n",
      "[05:51.000 --> 05:56.000]  Sir, actually it's not in your name.\n",
      "[05:56.000 --> 06:00.000]  Yes, I did the policy.\n",
      "[06:00.000 --> 06:16.000]  The policy number is in the name of the person who has come to you.\n",
      "[06:16.000 --> 06:29.000]  Actually, they have a life assured wealth plan.\n",
      "[06:29.000 --> 06:36.000]  After that, there is a plan called Savings Advantage Limited Pay Long Term Plan.\n",
      "[06:36.000 --> 06:39.000]  That too is in paid up.\n",
      "[06:39.000 --> 06:44.000]  Another one is Savings Advantage Limited Pay Short Term Plan.\n",
      "[06:44.000 --> 06:47.000]  Long term plan and short term plan.\n",
      "[06:47.000 --> 06:50.000]  After that, there is Life Perfect Partner Super Plan.\n",
      "[06:50.000 --> 06:53.000]  Another one is Monthly Income Advantage Plan.\n",
      "[06:53.000 --> 06:58.000]  monthly income advantage plan. So what policies do you have?\n",
      "[06:58.000 --> 07:03.000]  You have surrendered the monthly income advantage plan.\n",
      "[07:03.000 --> 07:08.000]  Ok. Hello.\n",
      "[07:08.000 --> 07:13.000]  Can you hear me?\n",
      "[07:13.000 --> 07:18.000]  Can you hear me?\n",
      "✅ Whisper transcription completed with optimal parameters\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting near-duplicate: Yes, tell me.... (similarity: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Yes, completely.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Okay, okay sir.... (dominance: 0.67)\n",
      "🚫 Rejecting near-duplicate: This policy is for you.... (similarity: 1.00)\n",
      "🚫 Rejecting word-dominated segment: What policy?... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: Sir, you have been paying for ... (similarity: 0.80)\n",
      "🚫 Rejecting near-duplicate: Let's see if there is a policy... (similarity: 1.00)\n",
      "🚫 Rejecting near-duplicate: Let's see if there is a policy... (similarity: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Ok. Hello.... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: Can you hear me?... (similarity: 1.00)\n",
      "📊 Aggressive cleaning: 70 → 59 segments\n",
      "🗑️  Removed 11 repetitive/problematic segments\n",
      "🔊 Performing Speaker Diarization...\n",
      "✅ Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved: call10_transcription.json\n",
      "\n",
      "📁 Processing file: call7.wav\n",
      "Original audio duration: 263.77 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 263.74 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\n",
      "[00:00.000 --> 00:07.000]  Good afternoon, sir. I am Nithya Goswami. I am a customer support call for Axis Maxlife Insurance.\n",
      "[00:07.000 --> 00:09.000]  Hello.\n",
      "[00:09.000 --> 00:11.000]  Hello.\n",
      "[00:11.000 --> 00:13.000]  Hello.\n",
      "[00:13.000 --> 00:15.000]  Sir, this is Mr. Sengar Vaidyanathan.\n",
      "[00:15.000 --> 00:17.000]  Yes.\n",
      "[00:17.000 --> 00:22.000]  Sir, you have taken a policy and have called for policy renewal. Can I talk to you for one minute, sir?\n",
      "[00:22.000 --> 00:23.000]  Yes.\n",
      "[00:23.000 --> 00:25.000]  Can you hear me?\n",
      "[00:25.000 --> 00:27.000]  Yes, I can hear you.\n",
      "[00:27.000 --> 00:32.000]  Have you taken a policy? We have called for a policy renewal. Can I talk to you for 2 minutes?\n",
      "[00:32.000 --> 00:37.000]  I have been getting money from the staff.\n",
      "[00:37.000 --> 00:39.000]  I don't understand sir.\n",
      "[00:39.000 --> 00:41.000]  I have taken that policy.\n",
      "[00:41.000 --> 00:42.000]  Ok\n",
      "[00:42.000 --> 00:45.000]  In the meantime, I have a medical issue.\n",
      "[00:45.000 --> 00:50.000]  I have taken a policy for my health, but it didn't work out.\n",
      "[00:50.000 --> 00:54.000]  Actually, it is a life insurance.\n",
      "[00:54.000 --> 00:58.000]  I did not get life insurance. Both of them told me and did it for me.\n",
      "[00:58.000 --> 01:03.000]  I applied for health insurance separately and for life insurance separately.\n",
      "[01:03.000 --> 01:09.000]  Do you know which branch you applied for health insurance?\n",
      "[01:09.000 --> 01:14.000]  I applied for it in the same office.\n",
      "[01:14.000 --> 01:18.000]  Do you have the policy number with you?\n",
      "[01:18.000 --> 01:33.000]  I don't have a claim on the policy. So, I have to pay the deposit and deposit the money.\n",
      "[01:33.000 --> 01:39.000]  If you see in this policy, this is a life insurance policy.\n",
      "[01:39.000 --> 01:42.000]  You have paid the policy for only one year.\n",
      "[01:42.000 --> 01:45.000]  Your policy is in lapse now.\n",
      "[01:45.000 --> 01:48.000]  As it is in lapse, your amount will not be refunded.\n",
      "[01:48.000 --> 01:51.000]  Because the benefits have not yet been added to you.\n",
      "[01:51.000 --> 01:53.000]  It is in zero benefits only.\n",
      "[01:53.000 --> 01:56.000]  The amount you have paid will not be refunded to you.\n",
      "[01:56.000 --> 02:00.000]  Because it is in lapse, the total amount has not yet been generated.\n",
      "[02:00.000 --> 02:05.000]  Only if you pay at least 2-3 years, you will be able to enter the surrender amount.\n",
      "[02:05.000 --> 02:09.000]  So, you can't do anything about it?\n",
      "[02:09.000 --> 02:13.000]  If you close it now, you won't be able to enter the surrender amount.\n",
      "[02:13.000 --> 02:18.000]  So, you can't do anything about it?\n",
      "[02:18.000 --> 02:22.000]  No, sir. Actually, you will be able to benefit from it.\n",
      "[02:22.000 --> 02:24.000]  So, you will be able to benefit from it.\n",
      "[02:24.000 --> 02:28.000]  Why is your health not improving?\n",
      "[02:28.000 --> 02:35.000]  You are going to give your life insurance. Tell me, what do you think about your health insurance?\n",
      "[02:35.000 --> 02:41.000]  You are saying that you are covering your life insurance. How do you cover it? What do you think I should cover? Tell me.\n",
      "[02:41.000 --> 02:43.000]  Sorry, sir.\n",
      "[02:48.000 --> 02:55.000]  Sorry, sir. Actually, we are updating your health insurance after checking. Can you tell us?\n",
      "[02:55.000 --> 02:59.000]  If you have the policy, can you please touch the details and tell us the details?\n",
      "[03:01.000 --> 03:03.000]  Do you remember the policy number?\n",
      "[03:04.000 --> 03:05.000]  No, I don't.\n",
      "[03:06.000 --> 03:10.000]  Okay, sir. But if you continue this, you will get income.\n",
      "[03:11.000 --> 03:17.000]  Now, you have paid in the first year. Your benefits are zero because it is in the lapse.\n",
      "[03:18.000 --> 03:23.000]  Once you have activated it, you will not get income from the first year.\n",
      "[03:23.000 --> 03:27.000]  That amount will be added to you. First year, second year, third year.\n",
      "[03:27.000 --> 03:30.000]  The income of three years will be added to you.\n",
      "[03:30.000 --> 03:33.000]  After activating the policy.\n",
      "[03:33.000 --> 03:35.000]  After activating the policy.\n",
      "[03:35.000 --> 03:37.000]  Sir, who is the sub-inspector?\n",
      "[03:37.000 --> 03:40.000]  You can ask him in the branch. You can ask him in the branch.\n",
      "[03:40.000 --> 03:42.000]  He will update you.\n",
      "[03:42.000 --> 03:46.000]  He will come and update you.\n",
      "[03:46.000 --> 03:47.000]  Ok.\n",
      "[03:47.000 --> 03:50.000]  Ok. You can ask him and then update.\n",
      "[03:50.000 --> 03:52.000]  Ok.\n",
      "[03:52.000 --> 03:56.000]  Okay sir. Do you want to update your mobile number and email?\n",
      "[03:56.000 --> 03:58.000]  No, I don't want to.\n",
      "[03:58.000 --> 04:01.000]  Okay sir. When can I call you?\n",
      "[04:01.000 --> 04:04.000]  I'll call you later.\n",
      "[04:04.000 --> 04:07.000]  Okay sir.\n",
      "[04:07.000 --> 04:11.000]  If you want to talk to anyone, I'll talk to them.\n",
      "[04:11.000 --> 04:17.000]  Actually, you can talk to the branch. They'll give you the details.\n",
      "[04:17.000 --> 04:18.000]  Okay.\n",
      "[04:18.000 --> 04:20.000]  Okay sir.\n",
      "[04:20.000 --> 04:21.000]  Thank you, sir.\n",
      "[04:21.000 --> 04:23.000]  Thank you, sir.\n",
      "✅ Whisper transcription completed with optimal parameters\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting near-duplicate: So, you can't do anything abou... (similarity: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Sorry, sir.... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: After activating the policy.... (similarity: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Okay sir.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Okay sir.... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: Thank you, sir.... (similarity: 1.00)\n",
      "📊 Aggressive cleaning: 71 → 56 segments\n",
      "🗑️  Removed 15 repetitive/problematic segments\n",
      "🔊 Performing Speaker Diarization...\n",
      "✅ Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved: call7_transcription.json\n",
      "\n",
      "📁 Processing file: call8.wav\n",
      "Original audio duration: 176.00 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 175.97 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Whisper Transcription (Optimal Single Strategy) ---\n",
      "[00:00.000 --> 00:10.000]  We will discuss policy numbers, due date, fund value, sum assured, late fee, and payment methods such as Google Pay, PhonePe, Paytm and net banking.\n",
      "[00:10.000 --> 00:19.000]  We will discuss policy numbers, due date, fund value, sum assured, late fee, and payment methods such as Google Paytm and net banking.\n",
      "[00:19.000 --> 00:22.500]  10,37,29,10,69,20 ma'am\n",
      "[00:22.500 --> 00:26.000]  Policy Divided 10,29,6,2,5,23 Divided\n",
      "[00:26.000 --> 00:27.000]  Ok\n",
      "[00:27.000 --> 00:30.000]  So, the amount to be paid is 1.35 lakhs\n",
      "[00:30.000 --> 00:32.000]  and Rs.431.97\n",
      "[00:32.000 --> 00:35.000]  The policy to be paid is in lapse ma'am\n",
      "[00:35.000 --> 00:37.000]  Is there any other reason to pay it?\n",
      "[00:37.000 --> 00:40.000]  There is no other reason to pay it\n",
      "[00:40.000 --> 00:42.000]  It is in loss\n",
      "[00:42.000 --> 00:46.000]  Last time when I asked, there were only two options.\n",
      "[00:46.000 --> 00:50.000]  But now I have to pay for all of them.\n",
      "[00:50.000 --> 00:53.000]  Yes, you are already fully diva.\n",
      "[00:53.000 --> 00:55.000]  So, you have to pay for all of them.\n",
      "[00:55.000 --> 00:57.000]  But there is no policy.\n",
      "[00:57.000 --> 00:59.000]  I have to pay for all of them.\n",
      "[00:59.000 --> 01:00.000]  Yes.\n",
      "[01:00.000 --> 01:03.000]  If you pay for all of them, the policy will be active.\n",
      "[01:03.000 --> 01:06.000]  If the policy is active, you will get all the benefits.\n",
      "[01:06.000 --> 01:10.000]  So, I have to pay for all of them after 10 years.\n",
      "[01:10.000 --> 01:12.000]  Yes\n",
      "[01:12.000 --> 01:14.000]  There is no policy\n",
      "[01:14.000 --> 01:16.000]  Okay ma'am\n",
      "[01:16.000 --> 01:18.000]  So if you pay the policy\n",
      "[01:18.000 --> 01:20.000]  You will be paid 25 years\n",
      "[01:20.000 --> 01:22.000]  And you will be paid 15 years\n",
      "[01:22.000 --> 01:24.000]  After 15 years you will be paid 10 years\n",
      "[01:24.000 --> 01:26.000]  You will be paid monthly income\n",
      "[01:26.000 --> 01:28.000]  So you will be paid monthly income\n",
      "[01:28.000 --> 01:30.000]  After that you will be paid material time and material amount\n",
      "[01:30.000 --> 01:32.000]  So material amount is\n",
      "[01:32.000 --> 01:34.000]  You will get bonus\n",
      "[01:34.000 --> 01:36.000]  If the bonus is added\n",
      "[01:36.000 --> 01:38.000]  The company will give you a bonus\n",
      "[01:38.000 --> 01:45.000]  So, you will get monthly amount and in the end, you will get the maturity amount of the policy.\n",
      "[01:45.000 --> 01:49.000]  Plus, if something happens in the centre, you will get a debt benefit coverage.\n",
      "[01:49.000 --> 01:50.000]  Okay.\n",
      "[01:50.000 --> 01:52.000]  There will be a lot of benefits.\n",
      "[01:52.000 --> 01:55.000]  Okay, sir. I will try.\n",
      "[01:55.000 --> 01:59.000]  You will have to try. I will call you at the end.\n",
      "[01:59.000 --> 02:00.000]  Okay, sir.\n",
      "[02:00.000 --> 02:03.000]  So, how much will you get?\n",
      "[02:03.000 --> 02:08.000]  This week\n",
      "[02:08.000 --> 02:09.000]  Are you paying this week?\n",
      "[02:09.000 --> 02:11.000]  Yes\n",
      "[02:11.000 --> 02:14.000]  Can you confirm the date this week?\n",
      "[02:14.000 --> 02:18.000]  Yes, I can confirm the date\n",
      "[02:18.000 --> 02:23.000]  Ok, you call me at the end of the week and if I ask you to pay\n",
      "[02:23.000 --> 02:28.000]  So until you pay, you have to fill the form and then the policy will be activated\n",
      "[02:28.000 --> 02:29.000]  Ok\n",
      "[02:29.000 --> 02:32.000]  Are you paying online or in branch?\n",
      "[02:32.000 --> 02:38.000]  If you want to go to the branch, UTS is already booked. Can I cancel online from UTS?\n",
      "[02:38.000 --> 02:43.000]  No, you can visit the branch and cancel. If you want to cancel online, there is a website login point.\n",
      "[02:43.000 --> 02:49.000]  So, you can cancel it. But it will take 3 months. So, you can visit the branch and cancel.\n",
      "[02:49.000 --> 02:52.000]  Thank you.\n",
      "✅ Whisper transcription completed with optimal parameters\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting near-duplicate: We will discuss policy numbers... (similarity: 0.92)\n",
      "🚫 Rejecting word-dominated segment: 10,37,29,10,69,20 ma'am... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Policy Divided 10,29,6,2,5,23 Divided... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: and Rs.431.97... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: I have to pay for all of them.... (similarity: 0.80)\n",
      "🚫 Rejecting word-dominated segment: Okay ma'am... (dominance: 0.50)\n",
      "🚫 Rejecting near-duplicate: So you will be paid monthly in... (similarity: 0.86)\n",
      "🚫 Rejecting word-dominated segment: Okay, sir.... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: This week... (dominance: 0.50)\n",
      "🚫 Rejecting word-dominated segment: Thank you.... (dominance: 0.50)\n",
      "📊 Aggressive cleaning: 56 → 40 segments\n",
      "🗑️  Removed 16 repetitive/problematic segments\n",
      "🔊 Performing Speaker Diarization...\n",
      "✅ Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved: call8_transcription.json\n",
      "\n",
      "📄 Training manifest saved to: processed_output_1/training_manifest.jsonl\n",
      "✅ All files processed.\n"
     ]
    }
   ],
   "source": [
    "# Directory paths\n",
    "INPUT_DIR = Path(\"training_data_1\")\n",
    "OUTPUT_DIR = Path(\"processed_output_1\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Manifest for Whisper fine-tuning\n",
    "manifest_path = OUTPUT_DIR / \"training_manifest.jsonl\"\n",
    "manifest_entries = []\n",
    "\n",
    "def process_single_file(audio_file_path):\n",
    "    print(f\"\\n📁 Processing file: {audio_file_path.name}\")\n",
    "    clean_audio_path = OUTPUT_DIR / f\"{audio_file_path.stem}_clean.wav\"\n",
    "    json_output_path = OUTPUT_DIR / f\"{audio_file_path.stem}_transcription.json\"\n",
    "\n",
    "    if not smart_audio_preprocessing(str(audio_file_path), str(clean_audio_path)):\n",
    "        print(\"❌ Preprocessing failed, skipping file.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        whisper_result = enhanced_whisper_transcription(str(clean_audio_path))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Whisper transcription failed: {e}\")\n",
    "        return\n",
    "\n",
    "    cleaned_segments = detect_and_remove_repetitions(whisper_result[\"segments\"])\n",
    "\n",
    "    processed_segments = []\n",
    "    for segment in cleaned_segments:\n",
    "        cleaned = post_process_text(segment['text'])\n",
    "        if cleaned.strip() and len(cleaned.strip()) > 5:\n",
    "            new_segment = segment.copy()\n",
    "            new_segment['text'] = cleaned\n",
    "            processed_segments.append(new_segment)\n",
    "\n",
    "    whisper_result[\"segments\"] = processed_segments\n",
    "\n",
    "    print(\"🔊 Performing Speaker Diarization...\")\n",
    "    try:\n",
    "        pipeline = Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-diarization-3.1\",\n",
    "            use_auth_token=HUGGING_FACE_ACCESS_TOKEN\n",
    "        )\n",
    "        if torch.cuda.is_available():\n",
    "            pipeline.to(torch.device(\"cuda\"))\n",
    "            print(\"✅ Using GPU\")\n",
    "        diarization = pipeline(str(clean_audio_path))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Diarization failed: {e}\")\n",
    "        diarization = None\n",
    "\n",
    "    def get_dominant_speaker(start, end, diarization_result):\n",
    "        if not diarization_result:\n",
    "            return \"Speaker_Unknown\"\n",
    "        speakers = {}\n",
    "        for segment, _, speaker in diarization_result.itertracks(yield_label=True):\n",
    "            overlap = max(0, min(end, segment.end) - max(start, segment.start))\n",
    "            if overlap > 0:\n",
    "                speakers[speaker] = speakers.get(speaker, 0) + overlap\n",
    "        return max(speakers, key=speakers.get) if speakers else \"Speaker_Unknown\"\n",
    "\n",
    "    dialogue = []\n",
    "    current_speaker, current_texts, current_start, current_end = None, [], 0, 0\n",
    "    for seg in processed_segments:\n",
    "        start, end, text = seg['start'], seg['end'], seg['text'].strip()\n",
    "        speaker = get_dominant_speaker(start, end, diarization)\n",
    "        if (speaker == current_speaker and current_speaker and (start - current_end) < 3.0):\n",
    "            current_texts.append(text)\n",
    "            current_end = end\n",
    "        else:\n",
    "            if current_speaker and current_texts:\n",
    "                combined = ' '.join(current_texts)\n",
    "                if len(combined.strip()) > 10:\n",
    "                    dialogue.append({\n",
    "                        'speaker': current_speaker,\n",
    "                        'text': combined,\n",
    "                        'start_time': current_start,\n",
    "                        'end_time': current_end\n",
    "                    })\n",
    "            current_speaker, current_texts, current_start, current_end = speaker, [text], start, end\n",
    "\n",
    "    if current_speaker and current_texts:\n",
    "        combined = ' '.join(current_texts)\n",
    "        if len(combined.strip()) > 10:\n",
    "            dialogue.append({\n",
    "                'speaker': current_speaker,\n",
    "                'text': combined,\n",
    "                'start_time': current_start,\n",
    "                'end_time': current_end\n",
    "            })\n",
    "\n",
    "    # Save JSON per file\n",
    "    output_data = {\n",
    "        'metadata': {\n",
    "            'audio_file': str(audio_file_path.name),\n",
    "            'total_duration': whisper_result.get('duration', 0),\n",
    "            'total_speakers': len(set(d['speaker'] for d in dialogue)),\n",
    "            'total_segments': len(dialogue),\n",
    "            'model_used': 'whisper-large',\n",
    "            'processing_successful': True,\n",
    "            'anti_repetition_applied': True\n",
    "        },\n",
    "        'dialogue': dialogue,\n",
    "        'raw_transcription': whisper_result\n",
    "    }\n",
    "\n",
    "    with open(json_output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"✅ Output saved: {json_output_path.name}\")\n",
    "\n",
    "    # Generate final conversation string\n",
    "    full_text = \"\\n\".join([f\"{d['speaker']}: {d['text']}\" for d in dialogue])\n",
    "\n",
    "    # Add to manifest entry\n",
    "    manifest_entries.append({\n",
    "        \"audio_filepath\": str(clean_audio_path),\n",
    "        \"text\": full_text,\n",
    "        \"language\": \"ta\",\n",
    "        \"task\": \"translate\"\n",
    "    })\n",
    "\n",
    "def main():\n",
    "    audio_files = list(INPUT_DIR.glob(\"*.wav\"))\n",
    "    if not audio_files:\n",
    "        print(\"❌ No .wav files found in 'training_data/' folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"🚀 Found {len(audio_files)} files to process...\")\n",
    "    for audio_file in audio_files:\n",
    "        process_single_file(audio_file)\n",
    "\n",
    "    # Save consolidated JSONL manifest\n",
    "    with open(manifest_path, 'w', encoding='utf-8') as f:\n",
    "        for entry in manifest_entries:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"\\n📄 Training manifest saved to: {manifest_path}\")\n",
    "    print(\"✅ All files processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfG7H8oHAO68"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y67nTRefCXMw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da-yqtQZCXPa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2424,
     "status": "ok",
     "timestamp": 1754025261160,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "B07v93kSCaWa",
    "outputId": "0e0abe19-b6e8-42bf-df66-f1fe3d3041e5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/processed_output6-10.zip'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Zip the folder into processed_outputs.zip\n",
    "shutil.make_archive('processed_output6-10', 'zip', 'processed_output_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1754025261191,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "zxKt44x-CaWc",
    "outputId": "f373bb31-15dc-47f1-9a90-6cb1d5e1a15a"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_35ca1f66-3865-419e-8b2f-2958fcdac2b5\", \"processed_output6-10.zip\", 33060416)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download the zipped folder\n",
    "files.download('processed_output6-10.zip')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/S4ap4mcvNNvccklql4rN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0229f60382f9489ba73b74b86d724302": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02b51f9993904929b0b6c6b9b7717a8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34be10db43914491a4b6af68ab456f90",
      "placeholder": "​",
      "style": "IPY_MODEL_d46500676a8c44098908fd1f0b0bfd3f",
      "value": " 221/221 [00:00&lt;00:00, 11.4kB/s]"
     }
    },
    "038a567ee6da468cb476e609e5b118c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b3e4302807242ebb4e46a39cf075301",
      "max": 26645418,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7224382f32a6420295346bd84036a09d",
      "value": 26645418
     }
    },
    "06b5560bf7ab4135a00cf49dca78429a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07baadb518404839992da1a956f4bfc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14d2864a531144249ef3300b2685147f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15e2ba8682124e3fbead9ad63f3e2cc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d1bd7910644445595eca8f77b80d6e5",
      "placeholder": "​",
      "style": "IPY_MODEL_570dee48526048a38233eb6a1da33056",
      "value": " 26.6M/26.6M [00:00&lt;00:00, 38.3MB/s]"
     }
    },
    "15f2a795d5374aedb2cd2a9075d627aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4771c3ecd0ef4d2d83d399e589694b64",
       "IPY_MODEL_305e5e8498b04343b2e973ae2f9f0b06",
       "IPY_MODEL_02b51f9993904929b0b6c6b9b7717a8b"
      ],
      "layout": "IPY_MODEL_b3eecc7e6ab44753b816bad4d94c7cd7"
     }
    },
    "1f753c9b11764a0a9adc5a53c1cdf884": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23cad67056e641879b583e516628cc0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27a69e09d5be4c51826eb366f4ba1a0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2d1bd7910644445595eca8f77b80d6e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "305e5e8498b04343b2e973ae2f9f0b06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de06f05884ac481a8f46469a0c3983bc",
      "max": 221,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_27a69e09d5be4c51826eb366f4ba1a0f",
      "value": 221
     }
    },
    "3103a0effb4a4e44b5daa1f40141ca01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34be10db43914491a4b6af68ab456f90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3670d3fd18304c0c958c31742ecf4319": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8099d7b687b140d0949de1e0093fea21",
      "placeholder": "​",
      "style": "IPY_MODEL_c8a3216dfc8646ecbdd5a7c90a00d741",
      "value": " 399/399 [00:00&lt;00:00, 25.8kB/s]"
     }
    },
    "44591331230b4eebbe2384ab738270d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4771c3ecd0ef4d2d83d399e589694b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3103a0effb4a4e44b5daa1f40141ca01",
      "placeholder": "​",
      "style": "IPY_MODEL_e2d42f1cabce4439bab80d3c384c18e1",
      "value": "config.yaml: 100%"
     }
    },
    "4dc83867c4cc4a38b5dbf9f543d9d52b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0e09acc1a364d99acf645240b050526",
      "placeholder": "​",
      "style": "IPY_MODEL_79b01027fb994047bb073d9434b34492",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "570dee48526048a38233eb6a1da33056": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b3e4302807242ebb4e46a39cf075301": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "615b74baff724f47b19d9ef2fd7089bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "679b72fc9492496ab3edd8dcdb761749": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f8d7b23ce644bd7b8be58b9265c12f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71852b4d92584aa3870f4925c460bd00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23cad67056e641879b583e516628cc0c",
      "max": 469,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9993a6677a604715bdfe6a7a3af5cd92",
      "value": 469
     }
    },
    "7224382f32a6420295346bd84036a09d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "72ea5bd9d9f34865a0484f85efdac580": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f342e4e47d5d4967b76683967926176c",
      "max": 399,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9108cbfd291f4b7a96e8281bc8e3cf43",
      "value": 399
     }
    },
    "79b01027fb994047bb073d9434b34492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8099d7b687b140d0949de1e0093fea21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9108cbfd291f4b7a96e8281bc8e3cf43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "940eb8fcffd844c6a8bef5cf98e87db9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9759269eda364a97a64309c2c3bff868": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b409b271982b4fa7bc6e089af2b75d66",
       "IPY_MODEL_71852b4d92584aa3870f4925c460bd00",
       "IPY_MODEL_d5c324f33e4343d79dc7726ea1fe1cae"
      ],
      "layout": "IPY_MODEL_07baadb518404839992da1a956f4bfc8"
     }
    },
    "9993a6677a604715bdfe6a7a3af5cd92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1b412674d97411ba0e67e4efb0c4e26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a2596709245d47d9a1ee3b69442cbb04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4dc83867c4cc4a38b5dbf9f543d9d52b",
       "IPY_MODEL_038a567ee6da468cb476e609e5b118c8",
       "IPY_MODEL_15e2ba8682124e3fbead9ad63f3e2cc0"
      ],
      "layout": "IPY_MODEL_0229f60382f9489ba73b74b86d724302"
     }
    },
    "a6c324000060496dbdc4b2b7364f4757": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0e09acc1a364d99acf645240b050526": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3eecc7e6ab44753b816bad4d94c7cd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b409b271982b4fa7bc6e089af2b75d66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f753c9b11764a0a9adc5a53c1cdf884",
      "placeholder": "​",
      "style": "IPY_MODEL_cbf7495aa8324669bec443f5af958d82",
      "value": "config.yaml: 100%"
     }
    },
    "b83d2df7f3844a119ee1c0e518009797": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8a3216dfc8646ecbdd5a7c90a00d741": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbf7495aa8324669bec443f5af958d82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf1b1d1b173843f7bdf35d453c50e2d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_615b74baff724f47b19d9ef2fd7089bc",
      "max": 5905440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a1b412674d97411ba0e67e4efb0c4e26",
      "value": 5905440
     }
    },
    "d23813e47d0643289da0fbaac85ff383": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d35e44a54065449db42f3771de599757": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06b5560bf7ab4135a00cf49dca78429a",
      "placeholder": "​",
      "style": "IPY_MODEL_44591331230b4eebbe2384ab738270d9",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "d46500676a8c44098908fd1f0b0bfd3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d502a0186a5c42de9afd8131a285f380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffe051de7ed24380a20655b490fb79bc",
      "placeholder": "​",
      "style": "IPY_MODEL_b83d2df7f3844a119ee1c0e518009797",
      "value": "config.yaml: 100%"
     }
    },
    "d5c324f33e4343d79dc7726ea1fe1cae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14d2864a531144249ef3300b2685147f",
      "placeholder": "​",
      "style": "IPY_MODEL_940eb8fcffd844c6a8bef5cf98e87db9",
      "value": " 469/469 [00:00&lt;00:00, 33.4kB/s]"
     }
    },
    "de06f05884ac481a8f46469a0c3983bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2d42f1cabce4439bab80d3c384c18e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f342e4e47d5d4967b76683967926176c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f37c05f9ac7c4a04a73ef440ac6cd1f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d502a0186a5c42de9afd8131a285f380",
       "IPY_MODEL_72ea5bd9d9f34865a0484f85efdac580",
       "IPY_MODEL_3670d3fd18304c0c958c31742ecf4319"
      ],
      "layout": "IPY_MODEL_a6c324000060496dbdc4b2b7364f4757"
     }
    },
    "f37f79208e7942ccbc9fbc1d16297b52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f8d7b23ce644bd7b8be58b9265c12f6",
      "placeholder": "​",
      "style": "IPY_MODEL_679b72fc9492496ab3edd8dcdb761749",
      "value": " 5.91M/5.91M [00:00&lt;00:00, 8.82MB/s]"
     }
    },
    "fa4398ce9bf84f7e930016de78459c7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d35e44a54065449db42f3771de599757",
       "IPY_MODEL_cf1b1d1b173843f7bdf35d453c50e2d9",
       "IPY_MODEL_f37f79208e7942ccbc9fbc1d16297b52"
      ],
      "layout": "IPY_MODEL_d23813e47d0643289da0fbaac85ff383"
     }
    },
    "ffe051de7ed24380a20655b490fb79bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
