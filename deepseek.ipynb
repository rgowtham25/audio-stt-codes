{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 97918,
     "status": "ok",
     "timestamp": 1753938676589,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "APEFy1kWOh5S",
    "outputId": "c51fcf90-98cd-41f3-d684-5dc987f5177f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-53qkjzae\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-53qkjzae\n",
      "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (10.7.0)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.0.2)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.9.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
      "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (3.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (4.14.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20250625)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20250625) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.7.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=fca0b1476f55cf7bc26dbd02c9c74afc866af64ae7848f50d6f4fa357566b958\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9ydza4dx/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20250625\n"
     ]
    }
   ],
   "source": [
    "!pip install --break-system-packages git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 18584,
     "status": "ok",
     "timestamp": 1753938695178,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "ZZ-jXf6mOqp0",
    "outputId": "6a61df5f-ec31-4b8e-fde9-ae1616b54b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyannote.audio\n",
      "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio)\n",
      "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.34.1)\n",
      "Collecting lightning>=2.0.1 (from pyannote.audio)\n",
      "  Downloading lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.3.0)\n",
      "Collecting pyannote.core>=5.0.0 (from pyannote.audio)\n",
      "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyannote.database>=5.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyannote.metrics>=3.2 (from pyannote.audio)\n",
      "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
      "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio)\n",
      "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (13.9.4)\n",
      "Collecting semver>=3.0.0 (from pyannote.audio)\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.13.1)\n",
      "Collecting speechbrain>=1.0.0 (from pyannote.audio)\n",
      "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tensorboardX>=2.6 (from pyannote.audio)\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n",
      "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting torchmetrics>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torchmetrics-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (4.14.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (1.1.5)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading lightning_utilities-0.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.1)\n",
      "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.0)\n",
      "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (2.19.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
      "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.5.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.5)\n",
      "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.12.14)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (75.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.41)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
      "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.7.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.20.1)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.2.3)\n",
      "Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
      "Downloading lightning-2.5.2-py3-none-any.whl (821 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.1/821.1 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.8.0-py3-none-any.whl (981 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.0-py3-none-any.whl (29 kB)\n",
      "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
      "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
      "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt, julius\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=65313bfc4188c99538b19b8b261b1b3c36afcbe67be885acec96977504c01c96\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=38da2dc943c794c85fe9a8c4b4f61684b163554f0bbae2a3f52f69dac96a185d\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
      "Successfully built docopt julius\n",
      "Installing collected packages: primePy, docopt, tensorboardX, semver, ruamel.yaml.clib, lightning-utilities, colorlog, ruamel.yaml, pyannote.core, alembic, optuna, hyperpyyaml, torchmetrics, pytorch-metric-learning, pyannote.database, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch-audiomentations, lightning, pyannote.audio\n",
      "Successfully installed alembic-1.16.4 asteroid-filterbanks-0.4.0 colorlog-6.9.0 docopt-0.6.2 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.5.2 lightning-utilities-0.15.0 optuna-4.4.0 primePy-1.3 pyannote.audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.5.2 pytorch-metric-learning-2.8.1 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 semver-3.0.4 speechbrain-1.0.3 tensorboardX-2.6.4 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --break-system-packages pyannote.audio torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 22828,
     "status": "ok",
     "timestamp": 1753938718023,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "18p3Psr_Or2M"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from typing import Optional, List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1753938718052,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "xk9ilZoQRlCr"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_AUDIO_PATH = \"call4.wav\"\n",
    "CLEAN_AUDIO_PATH = \"cleaned_audio_for_asr_and_diarization.wav\"\n",
    "HUGGING_FACE_ACCESS_TOKEN = \"hf_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 346679,
     "status": "ok",
     "timestamp": 1753939064730,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "0nQwvvqxy-ym",
    "outputId": "f04d95a3-7f2e-4ba2-ad1a-cbab6c0ed64f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [05:14<00:00, 9.83MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model globally\n",
    "model = whisper.load_model(\"large-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1753939064768,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "yzGwmrX3y_Nq",
    "outputId": "d77f173d-6588-4945-d55f-05e586911c34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51866, 1280)\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1753939064769,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "D-zTCy1Uy_8G"
   },
   "outputs": [],
   "source": [
    "def get_audio_duration(audio_path: str) -> float:\n",
    "    \"\"\"Get audio duration using ffprobe\"\"\"\n",
    "    try:\n",
    "        cmd = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
    "               \"-of\", \"default=noprint_wrappers=1:nokey=1\", audio_path]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "        return float(result.stdout.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Could not get duration: {e}\")\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1753939064784,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "mO30A97izBes"
   },
   "outputs": [],
   "source": [
    "def analyze_audio_quality(audio_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Detect if audio is from call center environment\"\"\"\n",
    "    try:\n",
    "        cmd = [\"ffmpeg\", \"-i\", audio_path, \"-af\", \"volumedetect\", \"-f\", \"null\", \"-\"]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "        is_callcenter = False\n",
    "        if \"mean_volume\" in result.stderr:\n",
    "            mean_vol = float(re.search(r\"mean_volume: ([\\d.-]+) dB\", result.stderr).group(1))\n",
    "            if mean_vol < -25:\n",
    "                is_callcenter = True\n",
    "\n",
    "        return {\n",
    "            \"is_callcenter\": is_callcenter,\n",
    "            \"duration\": get_audio_duration(audio_path)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Audio analysis failed: {e}\")\n",
    "        return {\"is_callcenter\": False, \"duration\": 0}\n",
    "\n",
    "def callcenter_specific_cleaning(input_path: str, output_path: str) -> bool:\n",
    "    \"\"\"Specialized cleaning for BPO call center audio\"\"\"\n",
    "    print(\"--- Applying Call Center Specific Cleaning ---\")\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ac\", \"1\",\n",
    "        \"-ar\", \"16000\",\n",
    "        \"-af\", \"highpass=300,lowpass=3500,afftdn=nr=25:nf=-30,adeclick,adeclip\",\n",
    "        \"-y\", output_path\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(ffmpeg_command, check=True)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Call center cleaning failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def clean_audio_preprocessing(input_path: str, output_path: str) -> bool:\n",
    "    \"\"\"Optimized preprocessing for clean 1:1 calls\"\"\"\n",
    "    print(\"--- Applying Clean Audio Processing ---\")\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ac\", \"1\",\n",
    "        \"-ar\", \"16000\",\n",
    "        \"-af\", \"loudnorm=I=-23:TP=-2,highpass=100\",\n",
    "        \"-y\", output_path\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(ffmpeg_command, check=True)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Clean audio processing failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def smart_audio_preprocessing(input_path: str, output_path: str) -> bool:\n",
    "    \"\"\"Automatically selects the best preprocessing approach\"\"\"\n",
    "    audio_info = analyze_audio_quality(input_path)\n",
    "    print(f\"Audio Duration: {audio_info['duration']:.2f}s | Call Center: {audio_info['is_callcenter']}\")\n",
    "\n",
    "    if audio_info['is_callcenter']:\n",
    "        return callcenter_specific_cleaning(input_path, output_path)\n",
    "    else:\n",
    "        return clean_audio_preprocessing(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1753939064789,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "Rm0OXU3XzHHR"
   },
   "outputs": [],
   "source": [
    "def enhanced_whisper_transcription(audio_path: str, is_callcenter: bool = False) -> Dict:\n",
    "    \"\"\"Optimized Whisper transcription based on audio type\"\"\"\n",
    "    print(\"--- Starting Enhanced Transcription ---\")\n",
    "\n",
    "    insurance_prompt = (\n",
    "        \"This is a customer support call for Axis Maxlife Insurance. \"\n",
    "        \"Discussion includes policy numbers, due dates, fund values, \"\n",
    "        \"sum assured amounts, and payment methods like Google Pay, PhonePe.\"\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"language\": \"ta\",\n",
    "        \"task\": \"translate\",\n",
    "        \"temperature\": 0.0,\n",
    "        \"beam_size\": 5,\n",
    "        \"condition_on_previous_text\": False,\n",
    "        \"word_timestamps\": True,\n",
    "        \"initial_prompt\": insurance_prompt,\n",
    "        \"verbose\": True\n",
    "    }\n",
    "\n",
    "    if is_callcenter:\n",
    "        params.update({\n",
    "            \"vad_filter\": True,\n",
    "            \"no_speech_threshold\": 0.4,\n",
    "            \"compression_ratio_threshold\": 2.4,\n",
    "            \"logprob_threshold\": -0.4\n",
    "        })\n",
    "\n",
    "    result = model.transcribe(audio_path, **params)\n",
    "    print(\"✅ Transcription completed\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1753939064844,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "k781JNNTzI3A"
   },
   "outputs": [],
   "source": [
    "def enhanced_post_process_text(text: str) -> str:\n",
    "    \"\"\"Advanced text cleaning with insurance-specific corrections\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Remove excessive filler words and repetitions\n",
    "    text = re.sub(r'\\b(\\w+)(?:\\s+\\1\\b)+', r'\\1', text)\n",
    "    text = re.sub(r'\\b(?:yes|okay|sir)\\b\\s*(?:yes|okay|sir\\b\\s*)+', 'yes sir', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 2. Insurance term normalization\n",
    "    corrections = {\n",
    "        r'\\bmax\\s*life\\b': 'Max Life',\n",
    "        r'\\bmaxlife\\b': 'Max Life',\n",
    "        r'\\baxis\\s*max\\s*life\\b': 'Axis Max Life',\n",
    "        r'\\b(\\d{3})\\s*(\\d{3})\\s*(\\d{3})\\b': r'\\1\\2\\3',  # Policy numbers\n",
    "        r'\\b(\\d{2})-(\\d{2})-(\\d{4})\\b': r'\\1/\\2/\\3',    # Dates\n",
    "        r'\\b(\\d+),(\\d+)\\b': r'\\1,\\2',                   # Numbers\n",
    "        r'\\bdiscontinue\\s*fund\\b': 'discontinued fund',\n",
    "        r'\\bplaning\\b': 'planning',\n",
    "        r'\\bgets\\b': 'will get',\n",
    "        r'\\bhaa\\b': 'yes',\n",
    "        r'\\bhmm\\b': 'I understand',\n",
    "        r'\\b(rs|rs\\.)\\s*': '₹',\n",
    "        r'\\b(\\d+)\\s*(lakhs|lakh)\\b': r'₹\\1,00,000'\n",
    "    }\n",
    "\n",
    "    for pattern, replacement in corrections.items():\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 3. Capitalization and punctuation\n",
    "    text = re.sub(r'\\bi\\b', 'I', text)\n",
    "    text = re.sub(r'\\bsir\\b', 'Sir', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'(\\w)(\\?|\\.|\\,)', r'\\1 \\2', text)\n",
    "    text = re.sub(r'\\s+([.,?!])', r'\\1', text)\n",
    "\n",
    "    # 4. Sentence capitalization\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    sentences = [s[0].upper() + s[1:] if s else s for s in sentences]\n",
    "    text = ' '.join(sentences)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1753939064851,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "iYUSXzyfzLSe"
   },
   "outputs": [],
   "source": [
    "def improve_transcription_alignment(segments: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Enhance segments to match insurance conversation patterns\"\"\"\n",
    "    improved_segments = []\n",
    "    current_speaker = None\n",
    "\n",
    "    for segment in segments:\n",
    "        text = segment['text'].strip()\n",
    "\n",
    "        # Identify speaker changes based on content\n",
    "        if not current_speaker:\n",
    "            if re.search(r'(calling from|policy number|due date)', text, re.IGNORECASE):\n",
    "                current_speaker = \"AGENT\"\n",
    "            else:\n",
    "                current_speaker = \"CUSTOMER\"\n",
    "\n",
    "        # Merge short segments with same speaker\n",
    "        if len(text.split()) < 5 and improved_segments and improved_segments[-1]['speaker'] == current_speaker:\n",
    "            improved_segments[-1]['text'] += \" \" + text\n",
    "            improved_segments[-1]['end'] = segment['end']\n",
    "        else:\n",
    "            improved_segments.append({\n",
    "                'speaker': current_speaker,\n",
    "                'text': text,\n",
    "                'start': segment['start'],\n",
    "                'end': segment['end']\n",
    "            })\n",
    "\n",
    "        # Toggle speaker for next segment\n",
    "        current_speaker = \"AGENT\" if current_speaker == \"CUSTOMER\" else \"CUSTOMER\"\n",
    "\n",
    "    return improved_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1753939338079,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "kmYFStMkzNlv"
   },
   "outputs": [],
   "source": [
    "def detect_and_remove_repetitions(segments: List[Dict], is_callcenter: bool) -> List[Dict]:\n",
    "    \"\"\"Adaptive repetition removal based on audio type\"\"\"\n",
    "    print(\"🔍 Starting Repetition Detection\")\n",
    "\n",
    "    thresholds = {\n",
    "        \"word_dominance\": 0.4 if is_callcenter else 0.5,\n",
    "        \"max_consecutive\": 3 if is_callcenter else 4,\n",
    "        \"similarity\": 0.7 if is_callcenter else 0.75\n",
    "    }\n",
    "\n",
    "    cleaned_segments = []\n",
    "\n",
    "    for segment in segments:\n",
    "        text = segment['text'].strip()\n",
    "        words = [w.lower().strip('.,!?') for w in text.split()]\n",
    "\n",
    "        if len(words) < 2:\n",
    "            continue\n",
    "\n",
    "        # Check word dominance\n",
    "        word_counts = {}\n",
    "        for word in words:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "        max_count = max(word_counts.values(), default=0)\n",
    "        if max_count / len(words) > thresholds[\"word_dominance\"]:\n",
    "            continue\n",
    "\n",
    "        # Check consecutive repeats\n",
    "        consecutive = 0\n",
    "        for i in range(1, len(words)):\n",
    "            consecutive = consecutive + 1 if words[i] == words[i-1] else 0\n",
    "            if consecutive > thresholds[\"max_consecutive\"]:\n",
    "                break\n",
    "        if consecutive > thresholds[\"max_consecutive\"]:\n",
    "            continue\n",
    "\n",
    "        cleaned_segments.append(segment)\n",
    "\n",
    "    print(f\"📊 Removed {len(segments) - len(cleaned_segments)} repetitive segments\")\n",
    "    return cleaned_segments\n",
    "\n",
    "def format_final_output(dialogue: List[Dict]) -> str:\n",
    "    \"\"\"Generate properly formatted conversation output\"\"\"\n",
    "    output = []\n",
    "    for entry in dialogue:\n",
    "        speaker = entry['speaker']  # Keep original AGENT/CUSTOMER labels\n",
    "        timestamp = f\"[{entry['start']:.1f}s-{entry['end']:.1f}s]\"\n",
    "        text = enhanced_post_process_text(entry['text'])\n",
    "        output.append(f\"{speaker} {timestamp}:\\n  {text}\")\n",
    "    return '\\n\\n'.join(output)\n",
    "\n",
    "def process_insurance_call(whisper_segments: List[Dict], is_callcenter: bool) -> tuple:\n",
    "    \"\"\"Enhanced processing pipeline for insurance calls\"\"\"\n",
    "    # 1. Remove repetitions\n",
    "    cleaned_segments = detect_and_remove_repetitions(whisper_segments, is_callcenter)\n",
    "\n",
    "    # 2. Improve speaker alignment\n",
    "    aligned_segments = improve_transcription_alignment(cleaned_segments)\n",
    "\n",
    "    # 3. Apply advanced post-processing\n",
    "    for segment in aligned_segments:\n",
    "        segment['text'] = enhanced_post_process_text(segment['text'])\n",
    "\n",
    "    # 4. Generate final formatted output\n",
    "    final_output = format_final_output(aligned_segments)\n",
    "\n",
    "    return final_output, aligned_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d9dfd214214f4cdb8bf838a354c2e5ff",
      "79b461cdcba7432aa963c9f62a7cdefd",
      "a01c5b85b5054be5ba4ffe22b78947ba",
      "37f610385b754a618770b65e4a0d10ff",
      "09d9d7c4407b49ec85e85dd063c80302",
      "69e20f68cae44cc79287aff68c852a58",
      "12164907e405497489144f0021538d96",
      "2387e52bf66b4153b807f28e3e18fe6b",
      "a14e23e5648842279e486b23b2d1cb78",
      "84dd00cd23bc42c7bcf6ef1cd9656a56",
      "94cdf9ccb43e4e61aa4f1723728d6350",
      "c093ec380fd24c66b6186cca0819f238",
      "90da1e31152041d18bfb61a85b8ef32c",
      "2f3dd8e2653744639ade8c17e8b2a94a",
      "56b6cc3e2516452694c9a2f90aba0fe7",
      "81a67928599a412d949ee42821e0a875",
      "ebd036f741e04fd8b67fe08879977b45",
      "f62b1fc1337b48398f5a8477822b4325",
      "b7565254234740cda17c9a10c541c967",
      "fe19ede88dcd4d658c8f1f18c554ef44",
      "1223099c48ec46e2943a21866889235c",
      "63b8615f3c794ce78380e732bda45d91",
      "6d965de5fa2f4bad82c240ff27fe8d68",
      "4fe9c25a5ab34e97b1f975147387fa85",
      "375b3c3b0502442d9f5a9997ae5ee312",
      "df4cd56fc19143a29247ce545b5c5de9",
      "5e5b1b08064f484c8824debc170f5032",
      "6c0459d2ebf34af8b4217c2934d00f8a",
      "9eb5f3455ce442828f4b054142d5b1a0",
      "fa1dd595f2884e199c7776203209fd91",
      "3f857544f37944ddb6ef363b558a10e6",
      "e3c04cc66be54bf1bde7ef3accc8d245",
      "628601caf77c48d1a107ce84bba158b5",
      "0884a4d12f804c649be52be6de718431",
      "e458f14273a1483a9cbc46c10c1e9ba4",
      "43b8bd36ff9a4bcabcef6574cfb0ed4a",
      "d937dbcf08364007801d9dba92289fcf",
      "04c02505e6b34118a94c8ed337c56493",
      "9aac8260067f45d68f1d964677b3041f",
      "3292aaea97eb4f1dbd4aec140bc690fa",
      "91b64d87487844f9941c6ba44ac14d58",
      "afafe0ffb1414b789e4286a8dc88e134",
      "ee26b2d5a17241d4a229f0b3419585be",
      "2be0c61df6284750ababaf5b30edac22",
      "0b5604f5a6f442949379d647282e5657",
      "bedacf9466974cdca355e639a3720f82",
      "9a4af23043224c05b97d68918217a583",
      "4c17d509334b44d3a44db86d1d8634bd",
      "69542258bdb349c0aad188c9c34c61f8",
      "579a17c3fcb34df3a90c4f160123d789",
      "d4c01906f6f3433e80327cd8aa2f92ec",
      "5b1e85638da54f55872bc66d62608fb8",
      "3469bb28154c405bbe0d3bf0016343c6",
      "369f0deee2aa4d3f9b725135e04b9cf4",
      "b0374de50c1e4875899a9bb83f84514e"
     ]
    },
    "executionInfo": {
     "elapsed": 92677,
     "status": "ok",
     "timestamp": 1753939434571,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "kt4mFmdx4nx8",
    "outputId": "3deb708e-553c-409b-ff17-2f3d71b23dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Starting Enhanced Audio Processing Pipeline\n",
      "============================================================\n",
      "Audio Duration: 160.96s | Call Center: False\n",
      "--- Applying Clean Audio Processing ---\n",
      "--- Starting Enhanced Transcription ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:182: UserWarning: Word-level timestamps on translations may not be reliable.\n",
      "  warnings.warn(\"Word-level timestamps on translations may not be reliable.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:00.820]  Hello!\n",
      "[00:02.060 --> 00:04.720]  Hello, my name is Axis Maxlife Insurance and I am calling you.\n",
      "[00:05.840 --> 00:06.400]  Yes, tell me.\n",
      "[00:06.900 --> 00:08.180]  My name is Thala Kumar.\n",
      "[00:09.280 --> 00:10.740]  Yes, tell me.\n",
      "[00:10.920 --> 00:13.320]  Can you tell me the policy number of Axis Maxlife Insurance?\n",
      "[00:14.720 --> 00:15.420]  Yes, tell me.\n",
      "[00:16.160 --> 00:21.720]  The policy number of Axis Maxlife Insurance is Rs.690,000.\n",
      "[00:21.720 --> 00:23.520]  The price is Rs.6178,000.\n",
      "[00:23.700 --> 00:25.740]  The due date is June 6, 2024.\n",
      "[00:26.960 --> 00:27.440]  Yes, it is.\n",
      "[00:27.440 --> 00:28.740]  The total amount is Rs. 3.1 lakhs.\n",
      "[00:29.220 --> 00:30.760]  It used to be Rs. 6 lakhs in 2017.\n",
      "[00:30.760 --> 00:31.660]  Now it is Rs. 2 lakhs.\n",
      "[00:33.040 --> 00:33.700]  Yes, yes.\n",
      "[00:34.080 --> 00:36.160]  When are you going to pay for this?\n",
      "[00:37.660 --> 00:39.080]  I will see if I can pay for it.\n",
      "[00:39.360 --> 00:40.440]  I am not sure if I will be able to pay for it.\n",
      "[00:41.480 --> 00:43.860]  I will see if I can pay for it.\n",
      "[00:43.940 --> 00:46.440]  I am not sure if I will be able to pay for it.\n",
      "[00:46.560 --> 00:47.140]  I am not sure if I will be able to pay for it.\n",
      "[00:47.160 --> 00:47.160]  I will see if I can pay for it.\n",
      "[00:47.740 --> 00:49.000]  I will see if I can pay for it.\n",
      "[00:49.780 --> 00:52.820]  You are planning to pay for this for 5 years, right?\n",
      "[00:53.880 --> 00:54.680]  Yes, yes.\n",
      "[00:54.680 --> 00:54.820]  Yes.\n",
      "[00:54.820 --> 00:55.760]  So, you have already paid for two years.\n",
      "[00:56.920 --> 00:57.420]  Yes.\n",
      "[00:57.420 --> 00:58.020]  Now, you have paid for two years.\n",
      "[00:58.560 --> 00:59.340]  Now, if you pay for these two years,\n",
      "[01:01.100 --> 01:01.600]  Yes.\n",
      "[01:01.840 --> 01:03.680]  Then, next year, you will have only one view.\n",
      "[01:05.320 --> 01:05.820]  Yes.\n",
      "[01:06.240 --> 01:08.240]  So, it will be over in five years.\n",
      "[01:08.660 --> 01:11.380]  So, if you look at the amount you have already paid so far,\n",
      "[01:12.900 --> 01:14.280]  Rs. 1,23,000.\n",
      "[01:15.340 --> 01:15.840]  Yes.\n",
      "[01:16.320 --> 01:17.980]  So, if you look at your present fund value,\n",
      "[01:19.180 --> 01:22.020]  Rs. 2,10,333.\n",
      "[01:22.020 --> 01:23.780]  Sir, CRS is in a very high growth.\n",
      "[01:25.240 --> 01:25.800]  Yes, yes.\n",
      "[01:26.220 --> 01:29.540]  So, if you don't pay it now, we will pay it at the end of the year.\n",
      "[01:29.620 --> 01:35.820]  But, if you pay it now, you will get a return of around Rs.1 lakh without interest.\n",
      "[01:37.240 --> 01:37.800]  Yes, yes.\n",
      "[01:38.020 --> 01:42.360]  So, if you pay it now, you will get a return of Rs.1 lakh without interest.\n",
      "[01:43.200 --> 01:44.660]  Yes, yes.\n",
      "[01:45.040 --> 01:47.700]  But, if you pay it now, you will get a discounting fund.\n",
      "[01:47.700 --> 01:50.440]  What will happen is, you will only get a discounted fund.\n",
      "[01:53.080 --> 01:57.140]  So, you won't get that much returns if you get a discounted fund. Plus, you won't get any risk average.\n",
      "[01:59.040 --> 01:59.860]  Ok, ok.\n",
      "[02:00.680 --> 02:02.060]  Sir, when will you pay the deposit?\n",
      "[02:03.200 --> 02:06.080]  Sir, I will talk to the VP and then call you.\n",
      "[02:07.340 --> 02:11.240]  Ok, talk to the VP and then call me. Your health declaration form is here.\n",
      "[02:11.240 --> 02:13.400]  I will call you when you are done with your assignment.\n",
      "[02:14.420 --> 02:15.260]  Who is calling?\n",
      "[02:17.680 --> 02:18.720]  I am calling.\n",
      "[02:20.240 --> 02:21.740]  I am calling.\n",
      "[02:22.040 --> 02:22.600]  I am calling.\n",
      "[02:23.480 --> 02:24.380]  I am calling.\n",
      "[02:24.380 --> 02:24.420]  I am calling.\n",
      "[02:24.420 --> 02:24.460]  I am calling.\n",
      "[02:24.460 --> 02:24.960]  I am calling.\n",
      "[02:25.240 --> 02:25.740]  I am calling.\n",
      "[02:26.100 --> 02:26.620]  I am calling.\n",
      "[02:27.700 --> 02:30.480]  I am calling.\n",
      "[02:33.900 --> 02:34.780]  I am calling.\n",
      "[02:34.780 --> 02:35.480]  Thank you for your time, sir.\n",
      "[02:35.940 --> 02:37.240]  Thank you, sir.\n",
      "✅ Transcription completed\n",
      "🔍 Starting Repetition Detection\n",
      "📊 Removed 13 repetitive segments\n",
      "\n",
      "--- Speaker Diarization ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9dfd214214f4cdb8bf838a354c2e5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/469 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c093ec380fd24c66b6186cca0819f238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d965de5fa2f4bad82c240ff27fe8d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0884a4d12f804c649be52be6de718431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/26.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5604f5a6f442949379d647282e5657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/221 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Diarization completed\n",
      "\n",
      "--- Generating Dialogue ---\n",
      "\n",
      "🎭 FINAL DIALOGUE OUTPUT\n",
      "========================================\n",
      "AGENT [2.1s-5.8s]:\n",
      "  Hello, my name is Axis Max Life Insurance and I am calling you.\n",
      "\n",
      "CUSTOMER [5.8s-6.9s]:\n",
      "  Yes, tell me.\n",
      "\n",
      "AGENT [6.9s-10.9s]:\n",
      "  My name is Thala Kumar. Yes, tell me.\n",
      "\n",
      "AGENT [10.9s-14.7s]:\n",
      "  Can you tell me the policy number of Axis Max Life Insurance?\n",
      "\n",
      "CUSTOMER [14.7s-16.2s]:\n",
      "  Yes, tell me.\n",
      "\n",
      "AGENT [16.2s-21.7s]:\n",
      "  The policy number of Axis Max Life Insurance is ₹.690,000.\n",
      "\n",
      "AGENT [21.7s-27.0s]:\n",
      "  The price is ₹.6178,000. The due date is June 6, 2024.\n",
      "\n",
      "AGENT [27.0s-30.8s]:\n",
      "  Yes, it is. The total amount is ₹. 3.₹1,00,000. It used to be ₹. ₹6,00,000 in 2017.\n",
      "\n",
      "AGENT [30.8s-34.1s]:\n",
      "  Now it is ₹. ₹2,00,000.\n",
      "\n",
      "AGENT [34.1s-37.7s]:\n",
      "  When are you going to pay for this?\n",
      "\n",
      "CUSTOMER [37.7s-41.5s]:\n",
      "  I will see if I can pay for it. I am not sure if I will be able to pay for it.\n",
      "\n",
      "CUSTOMER [41.5s-46.6s]:\n",
      "  I will see if I can pay for it. I am not sure if I will be able to pay for it.\n",
      "\n",
      "CUSTOMER [46.6s-49.8s]:\n",
      "  I am not sure if I will be able to pay for it. I will see if I can pay for it.\n",
      "\n",
      "AGENT [49.8s-54.8s]:\n",
      "  You are planning to pay for this for 5 years, right?\n",
      "\n",
      "AGENT [54.8s-58.6s]:\n",
      "  So, you have already paid for two years. Now, you have paid for two years.\n",
      "\n",
      "AGENT [58.6s-61.8s]:\n",
      "  Now, if you pay for these two years,\n",
      "\n",
      "AGENT [61.8s-66.2s]:\n",
      "  Then, next year, you will have only one view.\n",
      "\n",
      "AGENT [66.2s-72.9s]:\n",
      "  So, it will be over in five years. So, if you look at the amount you have already paid so far,\n",
      "\n",
      "AGENT [72.9s-76.3s]:\n",
      "  ₹. 1,23,000.\n",
      "\n",
      "AGENT [76.3s-82.0s]:\n",
      "  So, if you look at your present fund value, ₹. 2,10,333.\n",
      "\n",
      "AGENT [82.0s-86.2s]:\n",
      "  Sir, CRS is in a very high growth.\n",
      "\n",
      "AGENT [86.2s-89.6s]:\n",
      "  So, if you don't pay it now, we will pay it at the end of the year.\n",
      "\n",
      "AGENT [89.6s-98.0s]:\n",
      "  But, if you pay it now, you will get a return of around ₹.₹1,00,000 without interest.\n",
      "\n",
      "AGENT [98.0s-105.0s]:\n",
      "  So, if you pay it now, you will get a return of ₹.₹1,00,000 without interest.\n",
      "\n",
      "AGENT [105.0s-113.1s]:\n",
      "  But, if you pay it now, you will get a discounting fund. What will happen is, you will only get a discounted fund.\n",
      "\n",
      "AGENT [113.1s-120.7s]:\n",
      "  So, you won't get that much returns if you get a discounted fund. Plus, you won't get any risk average.\n",
      "\n",
      "AGENT [120.7s-123.2s]:\n",
      "  Sir, when will you pay the deposit?\n",
      "\n",
      "CUSTOMER [123.2s-127.3s]:\n",
      "  Sir, I will talk to the VP and then call you.\n",
      "\n",
      "AGENT [127.3s-131.2s]:\n",
      "  Ok, talk to the VP and then call me. Your health declaration form is here.\n",
      "\n",
      "AGENT [131.2s-134.4s]:\n",
      "  I will call you when you are done with your assignment.\n",
      "\n",
      "AGENT [134.4s-137.7s]:\n",
      "  Who is calling?\n",
      "\n",
      "AGENT [137.7s-140.2s]:\n",
      "  I am calling.\n",
      "\n",
      "CUSTOMER [140.2s-142.0s]:\n",
      "  I am calling.\n",
      "\n",
      "AGENT [142.0s-145.2s]:\n",
      "  I am calling. I am calling. I am calling. I am calling. I am calling.\n",
      "\n",
      "AGENT [145.2s-153.9s]:\n",
      "  I am calling. I am calling. I am calling.\n",
      "\n",
      "AGENT [153.9s-157.2s]:\n",
      "  I am calling. Thank you for your time, Sir. Thank you, Sir.\n",
      "\n",
      "💾 Results saved to enhanced_results.json\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"🎯 Starting Enhanced Audio Processing Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Step 1: Audio Analysis and Preprocessing\n",
    "    audio_info = analyze_audio_quality(INPUT_AUDIO_PATH)\n",
    "    if not smart_audio_preprocessing(INPUT_AUDIO_PATH, CLEAN_AUDIO_PATH):\n",
    "        print(\"❌ Audio preprocessing failed\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Optimized Transcription\n",
    "    try:\n",
    "        whisper_result = enhanced_whisper_transcription(\n",
    "            CLEAN_AUDIO_PATH,\n",
    "            is_callcenter=audio_info[\"is_callcenter\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Transcription failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Advanced Processing\n",
    "    final_output, processed_segments = process_insurance_call(\n",
    "        whisper_result[\"segments\"],\n",
    "        audio_info[\"is_callcenter\"]\n",
    "    )\n",
    "    whisper_result[\"segments\"] = processed_segments\n",
    "\n",
    "    # Step 4: Speaker Diarization\n",
    "    print(\"\\n--- Speaker Diarization ---\")\n",
    "    try:\n",
    "        pipeline = Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-diarization-3.1\",\n",
    "            use_auth_token=HUGGING_FACE_ACCESS_TOKEN\n",
    "        )\n",
    "        if torch.cuda.is_available():\n",
    "            pipeline.to(torch.device(\"cuda\"))\n",
    "        diarization = pipeline(CLEAN_AUDIO_PATH)\n",
    "        print(\"✅ Diarization completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Diarization failed: {e}\")\n",
    "        diarization = None\n",
    "\n",
    "    # Step 5: Generate Dialogue\n",
    "    print(\"\\n--- Generating Dialogue ---\")\n",
    "    dialogue = []\n",
    "    current_speaker = None\n",
    "    current_text = []\n",
    "    current_start = 0\n",
    "\n",
    "    for segment in processed_segments:\n",
    "        speaker = \"AGENT\"  # Default to AGENT if diarization fails\n",
    "        if diarization:\n",
    "            # Calculate speaker overlap durations\n",
    "            speaker_overlaps = []\n",
    "            for seg, _, speaker_label in diarization.itertracks(yield_label=True):\n",
    "                overlap_start = max(segment['start'], seg.start)\n",
    "                overlap_end = min(segment['end'], seg.end)\n",
    "                overlap_duration = max(0, overlap_end - overlap_start)\n",
    "                if overlap_duration > 0:\n",
    "                    speaker_overlaps.append((speaker_label, overlap_duration))\n",
    "\n",
    "            # Get speaker with maximum overlap\n",
    "            if speaker_overlaps:\n",
    "                speaker_label = max(speaker_overlaps, key=lambda x: x[1])[0]\n",
    "                speaker = \"AGENT\" if speaker_label.endswith(\"0\") else \"CUSTOMER\"\n",
    "\n",
    "        if speaker == current_speaker and segment['start'] - current_start < 3.0:\n",
    "            current_text.append(segment['text'])\n",
    "        else:\n",
    "            if current_speaker and current_text:\n",
    "                dialogue.append({\n",
    "                    'speaker': current_speaker,\n",
    "                    'text': ' '.join(current_text),\n",
    "                    'start': current_start,\n",
    "                    'end': segment['start']\n",
    "                })\n",
    "            current_speaker = speaker\n",
    "            current_text = [segment['text']]\n",
    "            current_start = segment['start']\n",
    "\n",
    "    if current_speaker and current_text:\n",
    "        dialogue.append({\n",
    "            'speaker': current_speaker,\n",
    "            'text': ' '.join(current_text),\n",
    "            'start': current_start,\n",
    "            'end': processed_segments[-1]['end']\n",
    "        })\n",
    "\n",
    "    # Step 6: Output Results\n",
    "    print(\"\\n🎭 FINAL DIALOGUE OUTPUT\")\n",
    "    print(\"=\" * 40)\n",
    "    print(format_final_output(dialogue))\n",
    "\n",
    "    output_data = {\n",
    "        'metadata': {\n",
    "            'audio_type': 'callcenter' if audio_info['is_callcenter'] else 'clean',\n",
    "            'duration': audio_info['duration'],\n",
    "            'speakers': len(set(d['speaker'] for d in dialogue)),\n",
    "            'model': 'whisper-large-v3'\n",
    "        },\n",
    "        'dialogue': [{\n",
    "            'speaker': d['speaker'],\n",
    "            'text': d['text'],\n",
    "            'start_time': d['start'],\n",
    "            'end_time': d['end']\n",
    "        } for d in dialogue]\n",
    "    }\n",
    "\n",
    "    with open('enhanced_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "    print(\"\\n💾 Results saved to enhanced_results.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuEcY0DJ7iys"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yS-h6SUO7qZq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpGPwyDX7qcd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1753939434601,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "C0ecKDCK7tFo"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_AUDIO_PATH = \"call6.wav\"\n",
    "CLEAN_AUDIO_PATH = \"cleaned_audio_call-6.wav\"\n",
    "HUGGING_FACE_ACCESS_TOKEN = \"hf_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59480,
     "status": "ok",
     "timestamp": 1753939494087,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "VsdD-nyz7tFr",
    "outputId": "abb5e625-c235-4de9-9018-6b030c47bf21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Starting Enhanced Audio Processing Pipeline\n",
      "============================================================\n",
      "Audio Duration: 172.48s | Call Center: False\n",
      "--- Applying Clean Audio Processing ---\n",
      "--- Starting Enhanced Transcription ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:182: UserWarning: Word-level timestamps on translations may not be reliable.\n",
      "  warnings.warn(\"Word-level timestamps on translations may not be reliable.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01.980 --> 00:10.000]  Discussion includes policy numbers, due dates, fund values, and payment methods like Google Pay, PhonePe.\n",
      "[00:19.800 --> 00:25.880]  Discussion includes policy numbers, due dates, fund values, and payment methods like Google Pay, PhonePe.\n",
      "[00:25.880 --> 00:27.140]  Do you know who is Maheshwari Vinodkumari Arun?\n",
      "[00:29.100 --> 00:30.960]  She is my madam.\n",
      "[00:31.880 --> 00:33.580]  She has a policy in her name.\n",
      "[00:33.660 --> 00:34.620]  We have called her to talk about it.\n",
      "[00:36.860 --> 00:39.160]  You spoke to her once that day.\n",
      "[00:39.480 --> 00:41.760]  She even told my staff about it.\n",
      "[00:44.060 --> 00:46.040]  What have you updated?\n",
      "[00:48.620 --> 00:49.640]  One minute.\n",
      "[00:50.220 --> 00:51.600]  I will talk to my staff.\n",
      "[00:51.600 --> 00:56.720]  Yes, but till last month they have said that they will be paying for it.\n",
      "[01:23.000 --> 01:23.960]  Hello ma'am.\n",
      "[01:23.960 --> 01:24.620]  Hello ma'am.\n",
      "[01:25.400 --> 01:27.160]  Ma'am, they are saying that they will pay you on Monday.\n",
      "[01:30.480 --> 01:35.680]  Monday? Okay ma'am. They have already said that they will pay you. That's why we are calling you.\n",
      "[01:37.320 --> 01:39.580]  Okay ma'am. They are saying that they will pay you on Monday.\n",
      "[01:40.960 --> 01:42.640]  Are they sure that they will pay you on Monday?\n",
      "[01:43.320 --> 01:44.520]  Yes ma'am.\n",
      "[01:44.700 --> 01:46.540]  Okay ma'am. Will they do it in the branch or online?\n",
      "[01:48.900 --> 01:50.160]  Online only ma'am.\n",
      "[01:51.140 --> 01:56.740]  If you have a health declaration form, it is pending. Once you submit it, your apology will be active.\n",
      "[01:58.400 --> 01:59.480]  Ok Madam.\n",
      "[02:00.460 --> 02:01.320]  Ok Madam.\n",
      "[02:01.340 --> 02:03.160]  Please inform me.\n",
      "[02:03.160 --> 02:04.760]  Do you have an alternative phone number or email id?\n",
      "[02:08.780 --> 02:11.440]  I don't have a number already. Do you have this number?\n",
      "[02:11.440 --> 02:11.440]  What is this number?\n",
      "[02:13.760 --> 02:14.780]  This is the number.\n",
      "[02:15.240 --> 02:20.520]  It is 949940090809\n",
      "[02:21.440 --> 02:24.440]  That is madam's number.\n",
      "[02:25.580 --> 02:26.980]  You can take that too.\n",
      "[02:27.300 --> 02:28.320]  Okay ma'am.\n",
      "[02:28.420 --> 02:29.640]  Thank you for giving me time.\n",
      "[02:31.040 --> 02:32.500]  Okay ma'am.\n",
      "[02:41.440 --> 02:46.340]  Now cut the call from the customer side\n",
      "[02:46.340 --> 02:50.740]  The call disconnects because there is no response from the customer side\n",
      "✅ Transcription completed\n",
      "🔍 Starting Repetition Detection\n",
      "📊 Removed 1 repetitive segments\n",
      "\n",
      "--- Speaker Diarization ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Diarization completed\n",
      "\n",
      "--- Generating Dialogue ---\n",
      "\n",
      "🎭 FINAL DIALOGUE OUTPUT\n",
      "========================================\n",
      "CUSTOMER [2.0s-19.8s]:\n",
      "  Discussion includes policy numbers, due dates, fund values, and payment methods like Google Pay, PhonePe.\n",
      "\n",
      "CUSTOMER [19.8s-25.9s]:\n",
      "  Discussion includes policy numbers, due dates, fund values, and payment methods like Google Pay, PhonePe.\n",
      "\n",
      "CUSTOMER [25.9s-29.1s]:\n",
      "  Do you know who is Maheshwari Vinodkumari Arun?\n",
      "\n",
      "AGENT [29.1s-31.9s]:\n",
      "  She is my madam.\n",
      "\n",
      "CUSTOMER [31.9s-36.9s]:\n",
      "  She has a policy in her name. We have called her to talk about it.\n",
      "\n",
      "AGENT [36.9s-44.1s]:\n",
      "  You spoke to her once that day. She even told my staff about it.\n",
      "\n",
      "CUSTOMER [44.1s-48.6s]:\n",
      "  What have you updated?\n",
      "\n",
      "AGENT [48.6s-51.6s]:\n",
      "  One minute. I will talk to my staff.\n",
      "\n",
      "CUSTOMER [51.6s-83.0s]:\n",
      "  Yes, but till last month they have said that they will be paying for it.\n",
      "\n",
      "AGENT [83.0s-90.5s]:\n",
      "  Hello ma'am. Hello ma'am. Ma'am, they are saying that they will pay you on Monday.\n",
      "\n",
      "CUSTOMER [90.5s-97.3s]:\n",
      "  Monday? Okay ma'am. They have already said that they will pay you. That's why we are calling you.\n",
      "\n",
      "AGENT [97.3s-101.0s]:\n",
      "  Okay ma'am. They are saying that they will pay you on Monday.\n",
      "\n",
      "CUSTOMER [101.0s-103.3s]:\n",
      "  Are they sure that they will pay you on Monday?\n",
      "\n",
      "AGENT [103.3s-104.7s]:\n",
      "  Yes ma'am.\n",
      "\n",
      "CUSTOMER [104.7s-108.9s]:\n",
      "  Okay ma'am. Will they do it in the branch or online?\n",
      "\n",
      "AGENT [108.9s-111.1s]:\n",
      "  Online only ma'am.\n",
      "\n",
      "CUSTOMER [111.1s-118.4s]:\n",
      "  If you have a health declaration form, it is pending. Once you submit it, your apology will be active.\n",
      "\n",
      "AGENT [118.4s-120.5s]:\n",
      "  Ok Madam.\n",
      "\n",
      "CUSTOMER [120.5s-128.8s]:\n",
      "  Ok Madam. Please inform me. Do you have an alternative phone number or email id?\n",
      "\n",
      "AGENT [128.8s-133.8s]:\n",
      "  I don't have a number already. Do you have this number?\n",
      "\n",
      "CUSTOMER [133.8s-141.4s]:\n",
      "  This is the number. It is 949940090809\n",
      "\n",
      "AGENT [141.4s-145.6s]:\n",
      "  That is madam's number.\n",
      "\n",
      "AGENT [145.6s-147.3s]:\n",
      "  You can take that too.\n",
      "\n",
      "CUSTOMER [147.3s-151.0s]:\n",
      "  Okay ma'am. Thank you for giving me time.\n",
      "\n",
      "CUSTOMER [151.0s-161.4s]:\n",
      "  Okay ma'am.\n",
      "\n",
      "CUSTOMER [161.4s-166.3s]:\n",
      "  Now cut the call from the customer side\n",
      "\n",
      "CUSTOMER [166.3s-170.7s]:\n",
      "  The call disconnects because there is no response from the customer side\n",
      "\n",
      "💾 Results saved to enhanced_results-call6.json\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"🎯 Starting Enhanced Audio Processing Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Step 1: Audio Analysis and Preprocessing\n",
    "    audio_info = analyze_audio_quality(INPUT_AUDIO_PATH)\n",
    "    if not smart_audio_preprocessing(INPUT_AUDIO_PATH, CLEAN_AUDIO_PATH):\n",
    "        print(\"❌ Audio preprocessing failed\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Optimized Transcription\n",
    "    try:\n",
    "        whisper_result = enhanced_whisper_transcription(\n",
    "            CLEAN_AUDIO_PATH,\n",
    "            is_callcenter=audio_info[\"is_callcenter\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Transcription failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Advanced Processing\n",
    "    final_output, processed_segments = process_insurance_call(\n",
    "        whisper_result[\"segments\"],\n",
    "        audio_info[\"is_callcenter\"]\n",
    "    )\n",
    "    whisper_result[\"segments\"] = processed_segments\n",
    "\n",
    "    # Step 4: Speaker Diarization\n",
    "    print(\"\\n--- Speaker Diarization ---\")\n",
    "    try:\n",
    "        pipeline = Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-diarization-3.1\",\n",
    "            use_auth_token=HUGGING_FACE_ACCESS_TOKEN\n",
    "        )\n",
    "        if torch.cuda.is_available():\n",
    "            pipeline.to(torch.device(\"cuda\"))\n",
    "        diarization = pipeline(CLEAN_AUDIO_PATH)\n",
    "        print(\"✅ Diarization completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Diarization failed: {e}\")\n",
    "        diarization = None\n",
    "\n",
    "    # Step 5: Generate Dialogue\n",
    "    print(\"\\n--- Generating Dialogue ---\")\n",
    "    dialogue = []\n",
    "    current_speaker = None\n",
    "    current_text = []\n",
    "    current_start = 0\n",
    "\n",
    "    for segment in processed_segments:\n",
    "        speaker = \"AGENT\"  # Default to AGENT if diarization fails\n",
    "        if diarization:\n",
    "            # Calculate speaker overlap durations\n",
    "            speaker_overlaps = []\n",
    "            for seg, _, speaker_label in diarization.itertracks(yield_label=True):\n",
    "                overlap_start = max(segment['start'], seg.start)\n",
    "                overlap_end = min(segment['end'], seg.end)\n",
    "                overlap_duration = max(0, overlap_end - overlap_start)\n",
    "                if overlap_duration > 0:\n",
    "                    speaker_overlaps.append((speaker_label, overlap_duration))\n",
    "\n",
    "            # Get speaker with maximum overlap\n",
    "            if speaker_overlaps:\n",
    "                speaker_label = max(speaker_overlaps, key=lambda x: x[1])[0]\n",
    "                speaker = \"AGENT\" if speaker_label.endswith(\"0\") else \"CUSTOMER\"\n",
    "\n",
    "        if speaker == current_speaker and segment['start'] - current_start < 3.0:\n",
    "            current_text.append(segment['text'])\n",
    "        else:\n",
    "            if current_speaker and current_text:\n",
    "                dialogue.append({\n",
    "                    'speaker': current_speaker,\n",
    "                    'text': ' '.join(current_text),\n",
    "                    'start': current_start,\n",
    "                    'end': segment['start']\n",
    "                })\n",
    "            current_speaker = speaker\n",
    "            current_text = [segment['text']]\n",
    "            current_start = segment['start']\n",
    "\n",
    "    if current_speaker and current_text:\n",
    "        dialogue.append({\n",
    "            'speaker': current_speaker,\n",
    "            'text': ' '.join(current_text),\n",
    "            'start': current_start,\n",
    "            'end': processed_segments[-1]['end']\n",
    "        })\n",
    "\n",
    "    # Step 6: Output Results\n",
    "    print(\"\\n🎭 FINAL DIALOGUE OUTPUT\")\n",
    "    print(\"=\" * 40)\n",
    "    print(format_final_output(dialogue))\n",
    "\n",
    "    output_data = {\n",
    "        'metadata': {\n",
    "            'audio_type': 'callcenter' if audio_info['is_callcenter'] else 'clean',\n",
    "            'duration': audio_info['duration'],\n",
    "            'speakers': len(set(d['speaker'] for d in dialogue)),\n",
    "            'model': 'whisper-large-v3'\n",
    "        },\n",
    "        'dialogue': [{\n",
    "            'speaker': d['speaker'],\n",
    "            'text': d['text'],\n",
    "            'start_time': d['start'],\n",
    "            'end_time': d['end']\n",
    "        } for d in dialogue]\n",
    "    }\n",
    "\n",
    "    with open('enhanced_results-call6.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "    print(\"\\n💾 Results saved to enhanced_results-call6.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIor5nbL9tbY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1753939967567,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "kCYloEG89twX",
    "outputId": "63406f7c-c3c9-43e6-db6d-9e6f09cd5134"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_8adca724-3d75-4b52-80ba-b8a245279d86\", \"cleaned_audio_for_asr_and_diarization.wav\", 5150670)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"cleaned_audio_for_asr_and_diarization.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NJP3QxN9_0F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNxugESJGpqrMrW+8ERcKdr",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04c02505e6b34118a94c8ed337c56493": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0884a4d12f804c649be52be6de718431": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e458f14273a1483a9cbc46c10c1e9ba4",
       "IPY_MODEL_43b8bd36ff9a4bcabcef6574cfb0ed4a",
       "IPY_MODEL_d937dbcf08364007801d9dba92289fcf"
      ],
      "layout": "IPY_MODEL_04c02505e6b34118a94c8ed337c56493"
     }
    },
    "09d9d7c4407b49ec85e85dd063c80302": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b5604f5a6f442949379d647282e5657": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bedacf9466974cdca355e639a3720f82",
       "IPY_MODEL_9a4af23043224c05b97d68918217a583",
       "IPY_MODEL_4c17d509334b44d3a44db86d1d8634bd"
      ],
      "layout": "IPY_MODEL_69542258bdb349c0aad188c9c34c61f8"
     }
    },
    "12164907e405497489144f0021538d96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1223099c48ec46e2943a21866889235c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2387e52bf66b4153b807f28e3e18fe6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2be0c61df6284750ababaf5b30edac22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f3dd8e2653744639ade8c17e8b2a94a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7565254234740cda17c9a10c541c967",
      "max": 5905440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fe19ede88dcd4d658c8f1f18c554ef44",
      "value": 5905440
     }
    },
    "3292aaea97eb4f1dbd4aec140bc690fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3469bb28154c405bbe0d3bf0016343c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "369f0deee2aa4d3f9b725135e04b9cf4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "375b3c3b0502442d9f5a9997ae5ee312": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa1dd595f2884e199c7776203209fd91",
      "max": 399,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f857544f37944ddb6ef363b558a10e6",
      "value": 399
     }
    },
    "37f610385b754a618770b65e4a0d10ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84dd00cd23bc42c7bcf6ef1cd9656a56",
      "placeholder": "​",
      "style": "IPY_MODEL_94cdf9ccb43e4e61aa4f1723728d6350",
      "value": " 469/469 [00:00&lt;00:00, 47.2kB/s]"
     }
    },
    "3f857544f37944ddb6ef363b558a10e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43b8bd36ff9a4bcabcef6574cfb0ed4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91b64d87487844f9941c6ba44ac14d58",
      "max": 26645418,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afafe0ffb1414b789e4286a8dc88e134",
      "value": 26645418
     }
    },
    "4c17d509334b44d3a44db86d1d8634bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_369f0deee2aa4d3f9b725135e04b9cf4",
      "placeholder": "​",
      "style": "IPY_MODEL_b0374de50c1e4875899a9bb83f84514e",
      "value": " 221/221 [00:00&lt;00:00, 25.1kB/s]"
     }
    },
    "4fe9c25a5ab34e97b1f975147387fa85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c0459d2ebf34af8b4217c2934d00f8a",
      "placeholder": "​",
      "style": "IPY_MODEL_9eb5f3455ce442828f4b054142d5b1a0",
      "value": "config.yaml: 100%"
     }
    },
    "56b6cc3e2516452694c9a2f90aba0fe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1223099c48ec46e2943a21866889235c",
      "placeholder": "​",
      "style": "IPY_MODEL_63b8615f3c794ce78380e732bda45d91",
      "value": " 5.91M/5.91M [00:00&lt;00:00, 9.74MB/s]"
     }
    },
    "579a17c3fcb34df3a90c4f160123d789": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b1e85638da54f55872bc66d62608fb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e5b1b08064f484c8824debc170f5032": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "628601caf77c48d1a107ce84bba158b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63b8615f3c794ce78380e732bda45d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69542258bdb349c0aad188c9c34c61f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69e20f68cae44cc79287aff68c852a58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c0459d2ebf34af8b4217c2934d00f8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d965de5fa2f4bad82c240ff27fe8d68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4fe9c25a5ab34e97b1f975147387fa85",
       "IPY_MODEL_375b3c3b0502442d9f5a9997ae5ee312",
       "IPY_MODEL_df4cd56fc19143a29247ce545b5c5de9"
      ],
      "layout": "IPY_MODEL_5e5b1b08064f484c8824debc170f5032"
     }
    },
    "79b461cdcba7432aa963c9f62a7cdefd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69e20f68cae44cc79287aff68c852a58",
      "placeholder": "​",
      "style": "IPY_MODEL_12164907e405497489144f0021538d96",
      "value": "config.yaml: 100%"
     }
    },
    "81a67928599a412d949ee42821e0a875": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84dd00cd23bc42c7bcf6ef1cd9656a56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90da1e31152041d18bfb61a85b8ef32c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebd036f741e04fd8b67fe08879977b45",
      "placeholder": "​",
      "style": "IPY_MODEL_f62b1fc1337b48398f5a8477822b4325",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "91b64d87487844f9941c6ba44ac14d58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94cdf9ccb43e4e61aa4f1723728d6350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a4af23043224c05b97d68918217a583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b1e85638da54f55872bc66d62608fb8",
      "max": 221,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3469bb28154c405bbe0d3bf0016343c6",
      "value": 221
     }
    },
    "9aac8260067f45d68f1d964677b3041f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eb5f3455ce442828f4b054142d5b1a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a01c5b85b5054be5ba4ffe22b78947ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2387e52bf66b4153b807f28e3e18fe6b",
      "max": 469,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a14e23e5648842279e486b23b2d1cb78",
      "value": 469
     }
    },
    "a14e23e5648842279e486b23b2d1cb78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "afafe0ffb1414b789e4286a8dc88e134": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b0374de50c1e4875899a9bb83f84514e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7565254234740cda17c9a10c541c967": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bedacf9466974cdca355e639a3720f82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_579a17c3fcb34df3a90c4f160123d789",
      "placeholder": "​",
      "style": "IPY_MODEL_d4c01906f6f3433e80327cd8aa2f92ec",
      "value": "config.yaml: 100%"
     }
    },
    "c093ec380fd24c66b6186cca0819f238": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90da1e31152041d18bfb61a85b8ef32c",
       "IPY_MODEL_2f3dd8e2653744639ade8c17e8b2a94a",
       "IPY_MODEL_56b6cc3e2516452694c9a2f90aba0fe7"
      ],
      "layout": "IPY_MODEL_81a67928599a412d949ee42821e0a875"
     }
    },
    "d4c01906f6f3433e80327cd8aa2f92ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d937dbcf08364007801d9dba92289fcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee26b2d5a17241d4a229f0b3419585be",
      "placeholder": "​",
      "style": "IPY_MODEL_2be0c61df6284750ababaf5b30edac22",
      "value": " 26.6M/26.6M [00:00&lt;00:00, 44.6MB/s]"
     }
    },
    "d9dfd214214f4cdb8bf838a354c2e5ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79b461cdcba7432aa963c9f62a7cdefd",
       "IPY_MODEL_a01c5b85b5054be5ba4ffe22b78947ba",
       "IPY_MODEL_37f610385b754a618770b65e4a0d10ff"
      ],
      "layout": "IPY_MODEL_09d9d7c4407b49ec85e85dd063c80302"
     }
    },
    "df4cd56fc19143a29247ce545b5c5de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3c04cc66be54bf1bde7ef3accc8d245",
      "placeholder": "​",
      "style": "IPY_MODEL_628601caf77c48d1a107ce84bba158b5",
      "value": " 399/399 [00:00&lt;00:00, 38.7kB/s]"
     }
    },
    "e3c04cc66be54bf1bde7ef3accc8d245": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e458f14273a1483a9cbc46c10c1e9ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9aac8260067f45d68f1d964677b3041f",
      "placeholder": "​",
      "style": "IPY_MODEL_3292aaea97eb4f1dbd4aec140bc690fa",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "ebd036f741e04fd8b67fe08879977b45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee26b2d5a17241d4a229f0b3419585be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f62b1fc1337b48398f5a8477822b4325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa1dd595f2884e199c7776203209fd91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe19ede88dcd4d658c8f1f18c554ef44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
