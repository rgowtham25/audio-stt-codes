{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 23483,
     "status": "ok",
     "timestamp": 1756969741088,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "FIMY9NjgijxZ",
    "outputId": "1825fb5d-e5d7-4fd6-c54f-ae53442e27aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faster-whisper\n",
      "  Downloading faster_whisper-1.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting ctranslate2<5,>=4.0 (from faster-whisper)\n",
      "  Downloading ctranslate2-4.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.34.4)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.21.4)\n",
      "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
      "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting av>=11 (from faster-whisper)\n",
      "  Downloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.67.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (2.0.2)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (25.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (1.1.8)\n",
      "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
      "Downloading faster_whisper-1.2.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ctranslate2-4.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster-whisper\n",
      "Successfully installed av-15.1.0 coloredlogs-15.0.1 ctranslate2-4.6.0 faster-whisper-1.2.0 humanfriendly-10.0 onnxruntime-1.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --break-system-packages faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 25212,
     "status": "ok",
     "timestamp": 1756969782247,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "pQaHJTp-jowK",
    "outputId": "5bd3153c-8b92-4119-bb34-b3c4d9cb8d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyannote.audio\n",
      "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio)\n",
      "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from pyannote.audio) (0.34.4)\n",
      "Collecting lightning>=2.0.1 (from pyannote.audio)\n",
      "  Downloading lightning-2.5.4-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.audio) (2.3.0)\n",
      "Collecting pyannote.core>=5.0.0 (from pyannote.audio)\n",
      "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyannote.database>=5.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyannote.metrics>=3.2 (from pyannote.audio)\n",
      "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
      "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio)\n",
      "  Downloading pytorch_metric_learning-2.9.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote.audio) (13.9.4)\n",
      "Collecting semver>=3.0.0 (from pyannote.audio)\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.audio) (0.13.1)\n",
      "Collecting speechbrain>=1.0.0 (from pyannote.audio)\n",
      "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tensorboardX>=2.6 (from pyannote.audio)\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote.audio) (2.8.0+cu126)\n",
      "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting torchmetrics>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->pyannote.audio) (3.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (1.1.8)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading pytorch_lightning-2.5.4-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.16.1)\n",
      "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.12/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.16.1)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.1)\n",
      "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.0)\n",
      "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->pyannote.audio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->pyannote.audio) (2.19.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
      "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.5.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.5)\n",
      "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.12.15)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.43)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->pyannote.audio) (1.3.0)\n",
      "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading ruamel.yaml-0.18.15-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.8.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.20.1)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.2.4)\n",
      "Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
      "Downloading lightning-2.5.4-py3-none-any.whl (825 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.2/825.2 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading pytorch_metric_learning-2.9.0-py3-none-any.whl (127 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
      "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading pytorch_lightning-2.5.4-py3-none-any.whl (829 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.4/247.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
      "Downloading ruamel.yaml-0.18.15-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (754 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.1/754.1 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt, julius\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=905807b7a42f42dd87c878672e5d172b2744e5b80aaac6fc246cd5ebe05baccb\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=63f91b04c2bb9f5ee078dfd10949e4f3274314d14f09d8e669880a01f6135f81\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/c1/ca/544dafe48401e8e2e17064dfe465a390fca9e8720ffa12e744\n",
      "Successfully built docopt julius\n",
      "Installing collected packages: primePy, docopt, tensorboardX, semver, ruamel.yaml.clib, lightning-utilities, colorlog, ruamel.yaml, pyannote.core, alembic, optuna, hyperpyyaml, torchmetrics, pytorch-metric-learning, pyannote.database, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch-audiomentations, lightning, pyannote.audio\n",
      "Successfully installed alembic-1.16.5 asteroid-filterbanks-0.4.0 colorlog-6.9.0 docopt-0.6.2 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.5.4 lightning-utilities-0.15.2 optuna-4.5.0 primePy-1.3 pyannote.audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.5.4 pytorch-metric-learning-2.9.0 ruamel.yaml-0.18.15 ruamel.yaml.clib-0.2.12 semver-3.0.4 speechbrain-1.0.3 tensorboardX-2.6.4 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --break-system-packages pyannote.audio torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15968,
     "status": "ok",
     "timestamp": 1756969806116,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "jV3PhN5witZG",
    "outputId": "8a698f9c-f4bd-4977-8771-169e1aff5bb0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from pyannote.audio import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1756969824149,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "2UbLa1tviwtA"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_AUDIO_PATH = \"call2.wav\"\n",
    "CLEAN_AUDIO_PATH = \"cleaned_audio_for_asr_and_diarization.wav\"\n",
    "HUGGING_FACE_ACCESS_TOKEN = \"hf_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 23888,
     "status": "ok",
     "timestamp": 1756970581614,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "vJ_X9NsBjEKA"
   },
   "outputs": [],
   "source": [
    "# Load faster-whisper model\n",
    "# model = WhisperModel(\"large-v3\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\", compute_type=\"float16\")\n",
    "model = WhisperModel(\"large-v3\", device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1756970581655,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "yzgMmX9PjEmA",
    "outputId": "d2c354c7-ae03-40fb-f24b-a942e5b5b198"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faster_whisper.transcribe.WhisperModel at 0x7c27bcf94680>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1756970581665,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "9XecuZI1O5xs"
   },
   "outputs": [],
   "source": [
    "def get_audio_duration(audio_path):\n",
    "    \"\"\"Get audio duration using ffprobe\"\"\"\n",
    "    try:\n",
    "        cmd = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
    "               \"-of\", \"default=noprint_wrappers=1:nokey=1\", audio_path]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "        return float(result.stdout.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Could not get duration: {e}\")\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1756970722156,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "chymACVjO50S"
   },
   "outputs": [],
   "source": [
    "def audio_preprocessing_v1(input_path, output_path):\n",
    "    \"\"\"Advanced audio preprocessing with better parameters\"\"\"\n",
    "    print(\"--- Trying Advanced Audio Preprocessing ---\")\n",
    "\n",
    "    # Improved ffmpeg command - less aggressive filtering to preserve speech\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ac\", \"1\",  # Mono\n",
    "        \"-ar\", \"16000\",  # 16kHz sample rate\n",
    "        \"-af\", \"loudnorm=I=-23:TP=-2:LRA=7,highpass=f=80,lowpass=f=8000,afftdn=nr=10\",\n",
    "        \"-y\", output_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "        print(\"Advanced preprocessing successful\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Advanced preprocessing failed: {e.returncode}\")\n",
    "        return False\n",
    "\n",
    "def audio_preprocessing_v2(input_path, output_path):\n",
    "    \"\"\"Simplified but effective preprocessing\"\"\"\n",
    "    print(\"--- Trying Simplified Audio Preprocessing ---\")\n",
    "\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ac\", \"1\",\n",
    "        \"-ar\", \"16000\",\n",
    "        \"-af\", \"loudnorm=I=-23:TP=-2,highpass=f=100\",\n",
    "        \"-y\", output_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "        print(\"Simplified preprocessing successful\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Simplified preprocessing failed: {e.returncode}\")\n",
    "        return False\n",
    "\n",
    "def audio_preprocessing_v3(input_path, output_path):\n",
    "    \"\"\"Basic but reliable preprocessing\"\"\"\n",
    "    print(\"--- Trying Basic Audio Preprocessing ---\")\n",
    "\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ac\", \"1\",\n",
    "        \"-ar\", \"16000\",\n",
    "        \"-af\", \"loudnorm\",\n",
    "        \"-y\", output_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "        print(\"Basic preprocessing successful\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Basic preprocessing failed: {e.returncode}\")\n",
    "        return False\n",
    "\n",
    "def audio_preprocessing_v4(input_path, output_path):\n",
    "    \"\"\"Minimal processing - just format conversion\"\"\"\n",
    "    print(\"--- Trying Minimal Audio Processing ---\")\n",
    "\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ac\", \"1\",\n",
    "        \"-ar\", \"16000\",\n",
    "        \"-y\", output_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "        print(\"Minimal processing successful\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Minimal processing failed: {e.returncode}\")\n",
    "        return False\n",
    "\n",
    "def smart_audio_preprocessing(input_path, output_path):\n",
    "    \"\"\"Try different preprocessing methods in order of preference\"\"\"\n",
    "    original_duration = get_audio_duration(input_path)\n",
    "    print(f\"Original audio duration: {original_duration:.2f} seconds\")\n",
    "\n",
    "    methods = [\n",
    "        audio_preprocessing_v1,\n",
    "        audio_preprocessing_v2,\n",
    "        audio_preprocessing_v3,\n",
    "        audio_preprocessing_v4\n",
    "    ]\n",
    "\n",
    "    for i, method in enumerate(methods, 1):\n",
    "        if method(input_path, output_path):\n",
    "            if os.path.exists(output_path):\n",
    "                processed_duration = get_audio_duration(output_path)\n",
    "                print(f\"Processed audio duration: {processed_duration:.2f} seconds\")\n",
    "\n",
    "                if abs(original_duration - processed_duration) < 1.0:\n",
    "                    print(f\"✅ Audio preprocessing successful with method {i}\")\n",
    "                    return True\n",
    "                else:\n",
    "                    print(f\"⚠️  Duration mismatch with method {i}, trying next...\")\n",
    "                    continue\n",
    "\n",
    "    print(\"❌ All preprocessing methods failed!\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1756970725443,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "GbVWoFpWi6J5"
   },
   "outputs": [],
   "source": [
    "def post_process_text(text):\n",
    "    \"\"\"Clean up transcribed text from Whisper output for call center insurance context.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # === 1. Remove excessive immediate repetitions ===\n",
    "    words = text.split()\n",
    "    cleaned_words = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        current_word = words[i].lower()\n",
    "        repetition_count = 1\n",
    "        j = i + 1\n",
    "        while j < len(words) and words[j].lower() == current_word:\n",
    "            repetition_count += 1\n",
    "            j += 1\n",
    "\n",
    "        keep_count = min(repetition_count, 2) if repetition_count <= 3 else 1\n",
    "        for _ in range(keep_count):\n",
    "            cleaned_words.append(words[i])\n",
    "        i += repetition_count\n",
    "\n",
    "    text = ' '.join(cleaned_words)\n",
    "\n",
    "    # === 2. Remove filler sounds (non-verbal, repetitive) ===\n",
    "    filler_sounds = [\"uh\", \"um\", \"mm\", \"hmm\", \"ah\", \"oh\", \"huh\", \"ha ha\"]\n",
    "    soft_fillers = [\"okay okay\", \"yes yes\", \"yes yes yes\", \"i mean\", \"you know\", \"like like\", \"ok ok\"]\n",
    "\n",
    "    for filler in filler_sounds + soft_fillers:\n",
    "        text = re.sub(rf'\\b{re.escape(filler)}\\b', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # === 3. Insurance domain term normalization ===\n",
    "    corrections = {\n",
    "        'access max life': 'Axis Max Life',\n",
    "        'axis max life': 'Axis Max Life',\n",
    "        'g pay': 'GPay',\n",
    "        'google pay': 'Google Pay',\n",
    "        'phone pay': 'PhonePe',\n",
    "        'phone pe': 'PhonePe',\n",
    "        'pay tm': 'Paytm',\n",
    "        'net banking': 'netbanking',\n",
    "        'some assured': 'sum assured',\n",
    "        'premium do': 'premium due',\n",
    "        'do date': 'due date',\n",
    "        'okay sir': 'Okay sir',\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for wrong, correct in corrections.items():\n",
    "        text_lower = text_lower.replace(wrong, correct)\n",
    "\n",
    "    # === 3.5 Replace 'Rs.', 'Rs' → '₹' with optional space cleanup ===\n",
    "    text_lower = re.sub(r'\\brs[.]?\\s*', '₹', text_lower)\n",
    "\n",
    "    # === 4. Punctuation cleanup ===\n",
    "    text_lower = re.sub(r'\\s{2,}', ' ', text_lower)          # Extra spaces\n",
    "    text_lower = re.sub(r'[,]{2,}', ',', text_lower)         # Repeated commas\n",
    "    text_lower = re.sub(r'\\s+,', ',', text_lower)            # Space before comma\n",
    "    text_lower = re.sub(r'\\s+\\.', '.', text_lower)           # Space before period\n",
    "    text_lower = re.sub(r'\\s+[!?]', lambda m: m.group(0).strip(), text_lower)\n",
    "\n",
    "    # === 5. Capitalize sentences ===\n",
    "    text_lower = re.sub(r'(^|[.!?]\\s+)([a-z])',\n",
    "                        lambda m: m.group(1) + m.group(2).upper(),\n",
    "                        text_lower)\n",
    "\n",
    "    return text_lower.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1756970727441,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "v0XkKXWYjBbx"
   },
   "outputs": [],
   "source": [
    "def enhanced_whisper_transcription(audio_path):\n",
    "    \"\"\"\n",
    "    Enhanced Whisper transcription with faster-whisper\n",
    "    \"\"\"\n",
    "    print(\"--- Enhanced Faster-Whisper Transcription (Optimal Single Strategy) ---\")\n",
    "\n",
    "    prompt = (\n",
    "        \"This is a customer support call for Axis Maxlife Insurance. \"\n",
    "        \"We will discuss policy numbers, due date, fund value, sum assured, late fee, \"\n",
    "        \"and payment methods such as Google Pay, PhonePe, Paytm and net banking.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        segments, info = model.transcribe(\n",
    "            audio_path,\n",
    "            language=\"ta\",\n",
    "            task=\"translate\",\n",
    "            beam_size=5,\n",
    "            temperature=0.0,\n",
    "            initial_prompt=prompt,\n",
    "            vad_filter=True,\n",
    "            vad_parameters=dict(min_silence_duration_ms=500),\n",
    "            condition_on_previous_text=False,\n",
    "            word_timestamps=False\n",
    "        )\n",
    "\n",
    "        whisper_result = {\n",
    "            \"segments\": [\n",
    "                {\n",
    "                    \"text\": segment.text,\n",
    "                    \"start\": segment.start,\n",
    "                    \"end\": segment.end\n",
    "                } for segment in segments\n",
    "            ],\n",
    "            \"duration\": info.duration,\n",
    "            \"language\": info.language\n",
    "        }\n",
    "\n",
    "        print(\"✅ Faster-Whisper transcription completed with optimal parameters\")\n",
    "        return whisper_result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Faster-Whisper transcription failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1756970728644,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "DuiJN2pSjJ8H"
   },
   "outputs": [],
   "source": [
    "def calculate_repetition_score(segments):\n",
    "    \"\"\"\n",
    "    Calculate a repetition score for transcription segments\n",
    "    Lower score = less repetition = better\n",
    "    \"\"\"\n",
    "    if not segments:\n",
    "        return 0.0\n",
    "\n",
    "    total_repetition = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for segment in segments:\n",
    "        text = segment.get('text', '').strip().lower()\n",
    "        words = text.split()\n",
    "\n",
    "        if len(words) < 2:\n",
    "            continue\n",
    "\n",
    "        total_words += len(words)\n",
    "\n",
    "        # Count immediate word repetitions\n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i] == words[i + 1]:\n",
    "                total_repetition += 1\n",
    "\n",
    "        # Count phrase repetitions within segment\n",
    "        for phrase_len in range(2, min(len(words)//2 + 1, 6)):\n",
    "            for start in range(len(words) - phrase_len * 2 + 1):\n",
    "                phrase1 = ' '.join(words[start:start + phrase_len])\n",
    "                phrase2 = ' '.join(words[start + phrase_len:start + phrase_len * 2])\n",
    "                if phrase1 == phrase2:\n",
    "                    total_repetition += phrase_len * 2  # Heavy penalty\n",
    "\n",
    "    return total_repetition / max(total_words, 1)\n",
    "\n",
    "def detect_and_remove_repetitions(segments, max_repetition_ratio=0.3):\n",
    "    \"\"\"\n",
    "    AGGRESSIVE post-processing function to detect and remove repetitive segments\n",
    "    \"\"\"\n",
    "    print(\"🔍 Starting aggressive repetition detection...\")\n",
    "    cleaned_segments = []\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        text = segment['text'].strip()\n",
    "        words = text.split()\n",
    "\n",
    "        # Skip very short segments\n",
    "        if len(words) < 2:\n",
    "            continue\n",
    "\n",
    "        # AGGRESSIVE: Check for excessive word repetition\n",
    "        is_repetitive = False\n",
    "\n",
    "        # Count word frequencies\n",
    "        word_counts = {}\n",
    "        for word in words:\n",
    "            word_lower = word.lower().strip('.,!?')\n",
    "            word_counts[word_lower] = word_counts.get(word_lower, 0) + 1\n",
    "\n",
    "        # Check if any single word dominates the segment\n",
    "        max_word_count = max(word_counts.values()) if word_counts else 0\n",
    "        word_dominance = max_word_count / len(words) if words else 0\n",
    "\n",
    "        if word_dominance > 0.4:  # If any word is >40% of the segment\n",
    "            print(f\"🚫 Rejecting word-dominated segment: {text[:50]}... (dominance: {word_dominance:.2f})\")\n",
    "            continue\n",
    "\n",
    "        # Check for immediate repetitions (same word repeated consecutively)\n",
    "        consecutive_repeats = 0\n",
    "        max_consecutive = 0\n",
    "\n",
    "        for j in range(1, len(words)):\n",
    "            if words[j].lower().strip('.,!?') == words[j-1].lower().strip('.,!?'):\n",
    "                consecutive_repeats += 1\n",
    "                max_consecutive = max(max_consecutive, consecutive_repeats + 1)\n",
    "            else:\n",
    "                consecutive_repeats = 0\n",
    "\n",
    "        if max_consecutive > 3:  # More than 3 consecutive identical words\n",
    "            print(f\"🚫 Rejecting consecutive repeat segment: {text[:50]}... (max consecutive: {max_consecutive})\")\n",
    "            continue\n",
    "\n",
    "        # Check for pattern repetitions within segment\n",
    "        for phrase_len in range(2, min(len(words)//3 + 1, 8)):\n",
    "            for start in range(len(words) - phrase_len * 2 + 1):\n",
    "                phrase1 = ' '.join(words[start:start + phrase_len]).lower()\n",
    "                phrase2 = ' '.join(words[start + phrase_len:start + phrase_len * 2]).lower()\n",
    "\n",
    "                if phrase1 == phrase2:\n",
    "                    repetition_coverage = (phrase_len * 2) / len(words)\n",
    "                    if repetition_coverage > max_repetition_ratio:\n",
    "                        print(f\"🚫 Rejecting pattern repeat segment: {text[:50]}... (coverage: {repetition_coverage:.2f})\")\n",
    "                        is_repetitive = True\n",
    "                        break\n",
    "            if is_repetitive:\n",
    "                break\n",
    "\n",
    "        if is_repetitive:\n",
    "            continue\n",
    "\n",
    "        # Check for similarity with recent segments (avoid near-duplicates)\n",
    "        is_near_duplicate = False\n",
    "        for prev_segment in cleaned_segments[-5:]:  # Check last 5 segments\n",
    "            prev_words = prev_segment['text'].lower().split()\n",
    "            current_words = [w.lower() for w in words]\n",
    "\n",
    "            if prev_words and current_words:\n",
    "                # Calculate Jaccard similarity\n",
    "                prev_set = set(prev_words)\n",
    "                current_set = set(current_words)\n",
    "                intersection = len(prev_set.intersection(current_set))\n",
    "                union = len(prev_set.union(current_set))\n",
    "\n",
    "                similarity = intersection / union if union > 0 else 0\n",
    "\n",
    "                if similarity > 0.7 and abs(len(prev_words) - len(current_words)) < 5:\n",
    "                    print(f\"🚫 Rejecting near-duplicate: {text[:30]}... (similarity: {similarity:.2f})\")\n",
    "                    is_near_duplicate = True\n",
    "                    break\n",
    "\n",
    "        if is_near_duplicate:\n",
    "            continue\n",
    "\n",
    "        # If we reach here, the segment passed all checks\n",
    "        cleaned_segments.append(segment)\n",
    "\n",
    "    removed_count = len(segments) - len(cleaned_segments)\n",
    "    print(f\"📊 Aggressive cleaning: {len(segments)} → {len(cleaned_segments)} segments\")\n",
    "    print(f\"🗑️  Removed {removed_count} repetitive/problematic segments\")\n",
    "\n",
    "    return cleaned_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8e967bc68d5944f3b73c28a19b397c03",
      "b494fdbb0d774a16825e2b5be2b6dd8d",
      "e10cc552d00748cda67ac86e65881d08",
      "9a3ec81d4707418da7a96ba1a6d08544",
      "d96d53caf8c04192a48428c77d5c6f51",
      "6facaaa95e51453b920484fea659ffbb",
      "23d7d08e2e6e42ef9a59c7fa5664dcaa",
      "7109c2b3c1cf4410a26160e63d60e13e",
      "a194d8da736e44139718aa57e6b05a64",
      "cacad721680e4ffa8cb331f36744164c",
      "40c8899597a5439583dc518c5b591210",
      "69de98906b1b4a9e9954f7bf87d7dfac",
      "1e49d620b63c4838a2fc1c919cb6dadd",
      "eb8a34d504ee4ac082e331429e323439",
      "2095aa67c5b74c50841e9dd43a747b17",
      "60a03e7e593b4eb5bdf2a6dc7dd65994",
      "5aaabfa8af1f49f8b563a1dcaa65cbb7",
      "37442e80866e4fd1bfb90ff6c9f78c31",
      "2dbd36db05164e0fbcb0aa37ae95febb",
      "3971334141ea4ca9b93975e8c1e036ed",
      "f8c397cc2a834c98b8663f5070784ae7",
      "a387a8403ee748ea98c5fcd7364ff48b",
      "5527817c12424e65a7d1ea34fa7133e4",
      "fc1bfc0b10384701a56b1744dfffeec0",
      "19d18062d7aa49d6ae498802c52f4784",
      "a4e3b6d8f2c54f0884bf758b1738eac3",
      "14d2d6ea0b3a4c1dbf4b0152e69a60c9",
      "67c8cb6b4665484184d1567c8cf48692",
      "d490301e3f8a42f2b93f0290dd51c312",
      "379f855b4d554eb78ffcb194c56a72d5",
      "9ae3348ead144258965e97f350f8cd8c",
      "0fea8253c3564af5ace6ac355b1e05f0",
      "b196a956a2c649ebbda398ef00c80279",
      "f411b3c2209444029b78518ac7ff3b33",
      "80439e7a10424771be12b60ec0b1cc42",
      "c87c3e90e01548f986c4942247266f53",
      "0429b6b1097b4a5aa233e22748bec479",
      "4d5c0eff05a34009adb5255a6e109fb6",
      "1ae2f9eb3d0744dcaaec15b7d5336bea",
      "3a50c0d74aea4f74a93bcba94c5372b5",
      "f16f7c708a0e46dab2a045ca0f31225d",
      "daeb2d02dc6c45ffa3d117f687c03bcf",
      "fc4422d35987447eba281474a6d80375",
      "69e3965a32ce41a4bc3b9670ebfb4651",
      "1e992417b697408192ce02332021f29d",
      "33a2390f9933446ba156a34555f5b8f2",
      "a5e04c3dd4d44ca98c3bbf372ca201ba",
      "7df353728dc348cdbea34f571e786a3f",
      "6e3712da68bc444e95299f2900425a8c",
      "e59f00c53fb64f679407b369e36e367c",
      "bbc467888027468f9eef9487c6335394",
      "481b97307bb1468f9f3d526b7de5464e",
      "7e51625924e44f54b98da5a103da6744",
      "984d8d5473ab4ed182683ce98fccf031",
      "4d7cd11feb9e4818a299b4400d8d3eeb"
     ]
    },
    "executionInfo": {
     "elapsed": 1314223,
     "status": "ok",
     "timestamp": 1756972045411,
     "user": {
      "displayName": "VBS Analytics",
      "userId": "12942825704271409009"
     },
     "user_tz": -330
    },
    "id": "0u4QZiotjPPr",
    "outputId": "ba9cd2b7-d60a-46b5-abbb-6548a6d1969f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Starting Enhanced Audio Processing Pipeline (Anti-Repetition)\n",
      "============================================================\n",
      "Original audio duration: 190.76 seconds\n",
      "--- Trying Advanced Audio Preprocessing ---\n",
      "Advanced preprocessing successful\n",
      "Processed audio duration: 190.74 seconds\n",
      "✅ Audio preprocessing successful with method 1\n",
      "--- Enhanced Faster-Whisper Transcription (Optimal Single Strategy) ---\n",
      "✅ Faster-Whisper transcription completed with optimal parameters\n",
      "✅ Whisper transcription completed\n",
      "\n",
      "--- Removing Repetitive Segments ---\n",
      "🔍 Starting aggressive repetition detection...\n",
      "🚫 Rejecting near-duplicate: But don't be tensed when you s... (similarity: 0.92)\n",
      "🚫 Rejecting near-duplicate: No, I don't have any.... (similarity: 1.00)\n",
      "🚫 Rejecting word-dominated segment: Thank you.... (dominance: 0.50)\n",
      "📊 Aggressive cleaning: 54 → 44 segments\n",
      "🗑️  Removed 10 repetitive/problematic segments\n",
      "\n",
      "--- Speaker Diarization ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e967bc68d5944f3b73c28a19b397c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/469 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/speechbrain/utils/torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
      "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69de98906b1b4a9e9954f7bf87d7dfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5527817c12424e65a7d1ea34fa7133e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f411b3c2209444029b78518ac7ff3b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/26.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e992417b697408192ce02332021f29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/221 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:85: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  info = torchaudio.info(file[\"audio\"], backend=backend)\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/soundfile_backend.py:120: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  return AudioMetaData(\n",
      "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Speaker diarization completed\n",
      "\n",
      "--- Generating Dialogue ---\n",
      "\n",
      "🎭 DIALOGUE OUTPUT========================================\n",
      "\n",
      "SPEAKER_00 [1.1s - 12.3s]:\n",
      "  📝 Hello! Greetings! My name is sumathi. We have called from licensure. This is an email call. You have taken a policy from axis maxlife insurance. Can you speak for 2 minutes? Yes, madam. Quick call.\n",
      "\n",
      "SPEAKER_01 [12.3s - 17.3s]:\n",
      "  📝 I can't get the call. If i cancel the policy, will it be refunded?\n",
      "\n",
      "SPEAKER_00 [17.3s - 33.5s]:\n",
      "  📝 Okay. It will be refunded in 30 seconds. Your policy is being re-researched. I will inform you. Okay. Can you speak in tamil only? Okay. Can you tell me what reason you are not connecting?\n",
      "\n",
      "SPEAKER_01 [33.5s - 35.5s]:\n",
      "  📝 It is not possible.\n",
      "\n",
      "SPEAKER_00 [39.7s - 56.7s]:\n",
      "  📝 I hope you understand the situation. You have already paid for 1 year. Don't be tensed when you surrender after paying for the first time. Because you should have paid for at least 3 years to generate cash surrender value. Usually, if you surrender after paying for at least 3 years, they will give you the surrender value accordingly.\n",
      "\n",
      "SPEAKER_00 [60.7s - 73.4s]:\n",
      "  📝 Can you please take some time to continue? How much will it cost if i do this now? When you pay the first day and surrender, won't there be any interest?\n",
      "\n",
      "SPEAKER_01 [73.4s - 76.6s]:\n",
      "  📝 You mean the amount will go away?\n",
      "\n",
      "SPEAKER_00 [76.6s - 156.3s]:\n",
      "  📝 Yes, because if you pay for at least 3 years and surrender, then only the cash will be generated. So, when you surrender, they will give you the amount of the surrender amount. Do you have any interest when you surrender the first payment? Shall we continue after some time? I am thinking about it. Okay. Tell me what you are thinking about. Already there is a lapse in the policy status and there is a hole in the summaries. If there is a lapse, there will not be any benefit. In case if you surrender and there is no policy, there will not be any benefit for you. They have given late payment charges. If you delay, there will be a lot of chances to get high. Payment will be made soon. Only then you will have full benefit. Your policy number is 149.607.129 max price smart wealth advantage growth per person income fixed income policy You have to pay ₹66,537 for the cross-examination at avanada 102024 We will give you a special revival scheme for all of our valuable customers. You have a one-year pay period. We will give you a six-month pay period. You can pay a six-month pay period. This will shift your maturity rate by 6 months, paying term by 6 months, and policy benefit by 6 months. If you are able to do that by 6 months, you will be able to get policy merit aptitude.\n",
      "\n",
      "SPEAKER_01 [156.3s - 164.4s]:\n",
      "  📝 I will check it and let. I will contact you once i get the information.\n",
      "\n",
      "SPEAKER_00 [165.7s - 180.8s]:\n",
      "  📝 In this case, if you want to get special services, you will have to go to the branch. So, submit your health declaration form. I will arrange a call back in a week's time. So, just inform us what you want to know. Do you have any other questions?\n",
      "\n",
      "SPEAKER_01 [180.8s - 181.9s]:\n",
      "  📝 No, i don't have any.\n",
      "\n",
      "SPEAKER_00 [181.9s - 184.9s]:\n",
      "  📝 Do you want to update any mail from alternate mobile?\n",
      "\n",
      "💾 Results saved to: enhanced_transcription_results.json\n",
      "✅ Processing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main processing pipeline with repetition prevention\"\"\"\n",
    "    print(\"🎯 Starting Enhanced Audio Processing Pipeline (Anti-Repetition)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Step 1: Smart Audio Preprocessing\n",
    "    if not smart_audio_preprocessing(INPUT_AUDIO_PATH, CLEAN_AUDIO_PATH):\n",
    "        print(\"❌ Audio preprocessing failed completely. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # model = whisper.load_model(\"large\")\n",
    "\n",
    "    # Step 2: Enhanced Whisper Transcription with anti-repetition\n",
    "    try:\n",
    "        whisper_result = enhanced_whisper_transcription(CLEAN_AUDIO_PATH)\n",
    "        print(\"✅ Whisper transcription completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Whisper transcription failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Remove repetitive segments BEFORE post-processing\n",
    "    print(\"\\n--- Removing Repetitive Segments ---\")\n",
    "    cleaned_segments = detect_and_remove_repetitions(whisper_result[\"segments\"])\n",
    "\n",
    "    # Step 4: Post-process remaining transcription\n",
    "    processed_segments = []\n",
    "    for segment in cleaned_segments:\n",
    "        processed_text = post_process_text(segment['text'])\n",
    "        if processed_text.strip() and len(processed_text.strip()) > 5:  # Only keep meaningful segments\n",
    "            segment_copy = segment.copy()\n",
    "            segment_copy['text'] = processed_text\n",
    "            processed_segments.append(segment_copy)\n",
    "\n",
    "    whisper_result[\"segments\"] = processed_segments\n",
    "\n",
    "    # Step 5: Speaker Diarization\n",
    "    print(\"\\n--- Speaker Diarization ---\")\n",
    "    try:\n",
    "        pipeline = Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-diarization-3.1\",\n",
    "            use_auth_token=HUGGING_FACE_ACCESS_TOKEN\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            pipeline.to(torch.device(\"cuda\"))\n",
    "            print(\"✅ Using GPU for diarization\")\n",
    "\n",
    "        diarization = pipeline(CLEAN_AUDIO_PATH)\n",
    "        print(\"✅ Speaker diarization completed\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Speaker diarization failed: {e}\")\n",
    "        diarization = None\n",
    "\n",
    "    # Step 6: Generate Enhanced Dialogue\n",
    "    print(\"\\n--- Generating Dialogue ---\")\n",
    "\n",
    "    def get_dominant_speaker(start_time, end_time, diarization_result):\n",
    "        if not diarization_result:\n",
    "            return \"Speaker_Unknown\"\n",
    "\n",
    "        speakers = {}\n",
    "        for segment, _, speaker in diarization_result.itertracks(yield_label=True):\n",
    "            overlap_start = max(start_time, segment.start)\n",
    "            overlap_end = min(end_time, segment.end)\n",
    "            overlap_duration = max(0, overlap_end - overlap_start)\n",
    "\n",
    "            if overlap_duration > 0:\n",
    "                speakers[speaker] = speakers.get(speaker, 0) + overlap_duration\n",
    "\n",
    "        return max(speakers, key=speakers.get) if speakers else \"Speaker_Unknown\"\n",
    "\n",
    "    # Combine segments by speaker\n",
    "    dialogue = []\n",
    "    current_speaker = None\n",
    "    current_texts = []\n",
    "    current_start = 0\n",
    "    current_end = 0\n",
    "\n",
    "    for segment in processed_segments:\n",
    "        start = segment['start']\n",
    "        end = segment['end']\n",
    "        text = segment['text'].strip()\n",
    "\n",
    "        speaker = get_dominant_speaker(start, end, diarization)\n",
    "\n",
    "        # Merge consecutive segments from same speaker (within 3 seconds)\n",
    "        if (speaker == current_speaker and\n",
    "            current_speaker and\n",
    "            (start - current_end) < 3.0):\n",
    "            current_texts.append(text)\n",
    "            current_end = end\n",
    "        else:\n",
    "            # Save previous speaker's dialogue\n",
    "            if current_speaker and current_texts:\n",
    "                combined_text = ' '.join(current_texts)\n",
    "                # Final check for repetition in combined text\n",
    "                if len(combined_text.strip()) > 10:  # Only keep substantial dialogue\n",
    "                    dialogue.append({\n",
    "                        'speaker': current_speaker,\n",
    "                        'text': combined_text,\n",
    "                        'start_time': current_start,\n",
    "                        'end_time': current_end\n",
    "                    })\n",
    "\n",
    "            # Start new speaker segment\n",
    "            current_speaker = speaker\n",
    "            current_texts = [text]\n",
    "            current_start = start\n",
    "            current_end = end\n",
    "\n",
    "    # Add final segment\n",
    "    if current_speaker and current_texts:\n",
    "        combined_text = ' '.join(current_texts)\n",
    "        if len(combined_text.strip()) > 10:\n",
    "            dialogue.append({\n",
    "                'speaker': current_speaker,\n",
    "                'text': combined_text,\n",
    "                'start_time': current_start,\n",
    "                'end_time': current_end\n",
    "            })\n",
    "\n",
    "    # Step 7: Display Results\n",
    "    print(\"\\n\" + \"🎭 DIALOGUE OUTPUT\" + \"=\" * 40)\n",
    "\n",
    "    for entry in dialogue:\n",
    "        timestamp = f\"[{entry['start_time']:.1f}s - {entry['end_time']:.1f}s]\"\n",
    "        print(f\"\\n{entry['speaker']} {timestamp}:\")\n",
    "        print(f\"  📝 {entry['text']}\")\n",
    "\n",
    "    # Step 8: Save Results\n",
    "    output_data = {\n",
    "        'metadata': {\n",
    "            'total_duration': whisper_result.get('duration', 0),\n",
    "            'total_speakers': len(set(d['speaker'] for d in dialogue)),\n",
    "            'total_segments': len(dialogue),\n",
    "            'model_used': 'whisper-large',\n",
    "            'processing_successful': True,\n",
    "            'anti_repetition_applied': True\n",
    "        },\n",
    "        'dialogue': dialogue,\n",
    "        'raw_transcription': whisper_result\n",
    "    }\n",
    "\n",
    "    with open('enhanced_transcription_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\n💾 Results saved to: enhanced_transcription_results.json\")\n",
    "    print(\"✅ Processing completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNnWLOhsPj/L37x45hpUtdF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0429b6b1097b4a5aa233e22748bec479": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc4422d35987447eba281474a6d80375",
      "placeholder": "​",
      "style": "IPY_MODEL_69e3965a32ce41a4bc3b9670ebfb4651",
      "value": " 26.6M/26.6M [00:00&lt;00:00, 83.5MB/s]"
     }
    },
    "0fea8253c3564af5ace6ac355b1e05f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14d2d6ea0b3a4c1dbf4b0152e69a60c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19d18062d7aa49d6ae498802c52f4784": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_379f855b4d554eb78ffcb194c56a72d5",
      "max": 399,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ae3348ead144258965e97f350f8cd8c",
      "value": 399
     }
    },
    "1ae2f9eb3d0744dcaaec15b7d5336bea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e49d620b63c4838a2fc1c919cb6dadd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5aaabfa8af1f49f8b563a1dcaa65cbb7",
      "placeholder": "​",
      "style": "IPY_MODEL_37442e80866e4fd1bfb90ff6c9f78c31",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "1e992417b697408192ce02332021f29d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_33a2390f9933446ba156a34555f5b8f2",
       "IPY_MODEL_a5e04c3dd4d44ca98c3bbf372ca201ba",
       "IPY_MODEL_7df353728dc348cdbea34f571e786a3f"
      ],
      "layout": "IPY_MODEL_6e3712da68bc444e95299f2900425a8c"
     }
    },
    "2095aa67c5b74c50841e9dd43a747b17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8c397cc2a834c98b8663f5070784ae7",
      "placeholder": "​",
      "style": "IPY_MODEL_a387a8403ee748ea98c5fcd7364ff48b",
      "value": " 5.91M/5.91M [00:00&lt;00:00, 12.7MB/s]"
     }
    },
    "23d7d08e2e6e42ef9a59c7fa5664dcaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2dbd36db05164e0fbcb0aa37ae95febb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33a2390f9933446ba156a34555f5b8f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e59f00c53fb64f679407b369e36e367c",
      "placeholder": "​",
      "style": "IPY_MODEL_bbc467888027468f9eef9487c6335394",
      "value": "config.yaml: 100%"
     }
    },
    "37442e80866e4fd1bfb90ff6c9f78c31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "379f855b4d554eb78ffcb194c56a72d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3971334141ea4ca9b93975e8c1e036ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a50c0d74aea4f74a93bcba94c5372b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40c8899597a5439583dc518c5b591210": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "481b97307bb1468f9f3d526b7de5464e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d5c0eff05a34009adb5255a6e109fb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d7cd11feb9e4818a299b4400d8d3eeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5527817c12424e65a7d1ea34fa7133e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc1bfc0b10384701a56b1744dfffeec0",
       "IPY_MODEL_19d18062d7aa49d6ae498802c52f4784",
       "IPY_MODEL_a4e3b6d8f2c54f0884bf758b1738eac3"
      ],
      "layout": "IPY_MODEL_14d2d6ea0b3a4c1dbf4b0152e69a60c9"
     }
    },
    "5aaabfa8af1f49f8b563a1dcaa65cbb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60a03e7e593b4eb5bdf2a6dc7dd65994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67c8cb6b4665484184d1567c8cf48692": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69de98906b1b4a9e9954f7bf87d7dfac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e49d620b63c4838a2fc1c919cb6dadd",
       "IPY_MODEL_eb8a34d504ee4ac082e331429e323439",
       "IPY_MODEL_2095aa67c5b74c50841e9dd43a747b17"
      ],
      "layout": "IPY_MODEL_60a03e7e593b4eb5bdf2a6dc7dd65994"
     }
    },
    "69e3965a32ce41a4bc3b9670ebfb4651": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e3712da68bc444e95299f2900425a8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6facaaa95e51453b920484fea659ffbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7109c2b3c1cf4410a26160e63d60e13e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7df353728dc348cdbea34f571e786a3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_984d8d5473ab4ed182683ce98fccf031",
      "placeholder": "​",
      "style": "IPY_MODEL_4d7cd11feb9e4818a299b4400d8d3eeb",
      "value": " 221/221 [00:00&lt;00:00, 14.2kB/s]"
     }
    },
    "7e51625924e44f54b98da5a103da6744": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "80439e7a10424771be12b60ec0b1cc42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ae2f9eb3d0744dcaaec15b7d5336bea",
      "placeholder": "​",
      "style": "IPY_MODEL_3a50c0d74aea4f74a93bcba94c5372b5",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "8e967bc68d5944f3b73c28a19b397c03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b494fdbb0d774a16825e2b5be2b6dd8d",
       "IPY_MODEL_e10cc552d00748cda67ac86e65881d08",
       "IPY_MODEL_9a3ec81d4707418da7a96ba1a6d08544"
      ],
      "layout": "IPY_MODEL_d96d53caf8c04192a48428c77d5c6f51"
     }
    },
    "984d8d5473ab4ed182683ce98fccf031": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a3ec81d4707418da7a96ba1a6d08544": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cacad721680e4ffa8cb331f36744164c",
      "placeholder": "​",
      "style": "IPY_MODEL_40c8899597a5439583dc518c5b591210",
      "value": " 469/469 [00:00&lt;00:00, 37.7kB/s]"
     }
    },
    "9ae3348ead144258965e97f350f8cd8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a194d8da736e44139718aa57e6b05a64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a387a8403ee748ea98c5fcd7364ff48b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4e3b6d8f2c54f0884bf758b1738eac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fea8253c3564af5ace6ac355b1e05f0",
      "placeholder": "​",
      "style": "IPY_MODEL_b196a956a2c649ebbda398ef00c80279",
      "value": " 399/399 [00:00&lt;00:00, 22.7kB/s]"
     }
    },
    "a5e04c3dd4d44ca98c3bbf372ca201ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_481b97307bb1468f9f3d526b7de5464e",
      "max": 221,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e51625924e44f54b98da5a103da6744",
      "value": 221
     }
    },
    "b196a956a2c649ebbda398ef00c80279": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b494fdbb0d774a16825e2b5be2b6dd8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6facaaa95e51453b920484fea659ffbb",
      "placeholder": "​",
      "style": "IPY_MODEL_23d7d08e2e6e42ef9a59c7fa5664dcaa",
      "value": "config.yaml: 100%"
     }
    },
    "bbc467888027468f9eef9487c6335394": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c87c3e90e01548f986c4942247266f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f16f7c708a0e46dab2a045ca0f31225d",
      "max": 26645418,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_daeb2d02dc6c45ffa3d117f687c03bcf",
      "value": 26645418
     }
    },
    "cacad721680e4ffa8cb331f36744164c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d490301e3f8a42f2b93f0290dd51c312": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d96d53caf8c04192a48428c77d5c6f51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daeb2d02dc6c45ffa3d117f687c03bcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e10cc552d00748cda67ac86e65881d08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7109c2b3c1cf4410a26160e63d60e13e",
      "max": 469,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a194d8da736e44139718aa57e6b05a64",
      "value": 469
     }
    },
    "e59f00c53fb64f679407b369e36e367c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb8a34d504ee4ac082e331429e323439": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dbd36db05164e0fbcb0aa37ae95febb",
      "max": 5905440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3971334141ea4ca9b93975e8c1e036ed",
      "value": 5905440
     }
    },
    "f16f7c708a0e46dab2a045ca0f31225d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f411b3c2209444029b78518ac7ff3b33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80439e7a10424771be12b60ec0b1cc42",
       "IPY_MODEL_c87c3e90e01548f986c4942247266f53",
       "IPY_MODEL_0429b6b1097b4a5aa233e22748bec479"
      ],
      "layout": "IPY_MODEL_4d5c0eff05a34009adb5255a6e109fb6"
     }
    },
    "f8c397cc2a834c98b8663f5070784ae7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc1bfc0b10384701a56b1744dfffeec0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67c8cb6b4665484184d1567c8cf48692",
      "placeholder": "​",
      "style": "IPY_MODEL_d490301e3f8a42f2b93f0290dd51c312",
      "value": "config.yaml: 100%"
     }
    },
    "fc4422d35987447eba281474a6d80375": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
