{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPzKze1kzokMeH4DuVcybwv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install --break-system-packages git+https://github.com/openai/whisper.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9I7l6RGXIazV","executionInfo":{"status":"ok","timestamp":1752316600804,"user_tz":-330,"elapsed":16240,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"c0bbc70a-d6f6-4952-c9c0-1421590713be"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-hm1ihwtk\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-hm1ihwtk\n","  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (10.7.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.0.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.9.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.6.0+cu124)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (4.67.1)\n","Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (3.2.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20250625) (1.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.7.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n"]}]},{"cell_type":"code","source":["!pip install --break-system-packages pyannote.audio torchaudio # pydub not strictly needed if only ffmpeg is used for audio proc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9uSYZheIa2J","executionInfo":{"status":"ok","timestamp":1752316617741,"user_tz":-330,"elapsed":16918,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"80dd694a-9255-420b-894c-b12eb75e1cc1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyannote.audio in /usr/local/lib/python3.11/dist-packages (3.3.2)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.4.0)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.8.1)\n","Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.33.2)\n","Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.5.2)\n","Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.3.0)\n","Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (5.0.0)\n","Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (5.1.3)\n","Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (3.2.1)\n","Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (3.0.1)\n","Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.8.1)\n","Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (13.9.4)\n","Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (3.0.4)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.13.1)\n","Requirement already satisfied: speechbrain>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (1.0.3)\n","Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.4)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n","Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.12.0)\n","Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (1.7.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->pyannote.audio) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (2.0.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (1.1.5)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.1->pyannote.audio) (0.14.3)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.1->pyannote.audio) (2.5.2)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n","Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n","Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.15.3)\n","Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n","Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.16.0)\n","Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.1)\n","Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.0)\n","Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (4.4.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (2.19.2)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n","Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.5.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.5)\n","Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n","Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.5)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (75.2.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.58.5)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.16.4)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.9.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.41)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n","Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.11/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n","Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.7.9)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.20.1)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.1.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n","Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.12)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.2.3)\n"]}]},{"cell_type":"code","source":["import whisper\n","from pyannote.audio import Pipeline\n","import torch\n","import re\n","import os\n","import subprocess"],"metadata":{"id":"rK_5F2dRIa4p","executionInfo":{"status":"ok","timestamp":1752316641832,"user_tz":-330,"elapsed":24088,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["input_audio_path = \"/content/s1.wav\"\n","clean_audio_path = \"cleaned_audio_for_asr_and_diarization.wav\""],"metadata":{"id":"57E26QGLIa9d","executionInfo":{"status":"ok","timestamp":1752316641851,"user_tz":-330,"elapsed":15,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["HUGGING_FACE_ACCESS_TOKEN = \"hf_\" # <-- REPLACE THIS!"],"metadata":{"id":"50MSpRpPIa_p","executionInfo":{"status":"ok","timestamp":1752316641857,"user_tz":-330,"elapsed":18,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# --- Step 1: Enhanced Audio Preprocessing with ffmpeg and Duration Verification ---\n","print(\"--- Starting Audio Preprocessing ---\")\n","\n","# First, get the duration of the original input file for comparison\n","print(f\"--- Verifying Original Input Audio Duration ({input_audio_path}) ---\")\n","ffprobe_command_input = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", input_audio_path]\n","try:\n","    input_duration_output = subprocess.run(ffprobe_command_input, check=True, capture_output=True, text=True).stdout.strip()\n","    original_input_duration_seconds = float(input_duration_output)\n","    print(f\"Original input audio duration: {original_input_duration_seconds:.2f} seconds\")\n","except Exception as e:\n","    print(f\"Error getting original input audio duration: {e}. Please ensure the input WAV file exists and is valid.\")\n","    # Exit or raise error if input audio duration cannot be determined\n","    raise\n","\n","# FFmpeg command using the original successful filters\n","ffmpeg_command = [\n","    \"ffmpeg\",\n","    \"-i\", input_audio_path,\n","    \"-acodec\", \"pcm_s16le\",\n","    \"-ac\", \"1\",\n","    \"-ar\", \"16000\",\n","    # Reverted to the original working filters: loudnorm, highpass, lowpass\n","    \"-af\", \"loudnorm=I=-16:TP=-1.5:LRA=11, highpass=f=200, lowpass=f=3000\",\n","    \"-y\", clean_audio_path # -y to overwrite output file without asking\n","]\n","\n","try:\n","    result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n","    if result.stdout:\n","        print(\"FFmpeg stdout:\")\n","        print(result.stdout)\n","    if result.stderr:\n","        print(\"FFmpeg stderr (might contain warnings/info):\")\n","        print(result.stderr)\n","    print(f\"--- Audio Preprocessing Complete. Cleaned audio saved to {clean_audio_path} ---\")\n","\n","    # Verify duration of the cleaned audio file\n","    print(f\"--- Verifying Cleaned Audio Duration ({clean_audio_path}) ---\")\n","    ffprobe_command_output = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", clean_audio_path]\n","    duration_output = subprocess.run(ffprobe_command_output, check=True, capture_output=True, text=True).stdout.strip()\n","    try:\n","        cleaned_audio_duration_seconds = float(duration_output)\n","        print(f\"Cleaned audio duration: {cleaned_audio_duration_seconds:.2f} seconds\")\n","        if abs(original_input_duration_seconds - cleaned_audio_duration_seconds) > 0.1: # Allow for small floating point differences\n","            print(f\"WARNING: Cleaned audio duration ({cleaned_audio_duration_seconds:.2f}s) significantly differs from input ({original_input_duration_seconds:.2f}s). This might indicate a truncation problem during FFmpeg processing.\")\n","        else:\n","            print(\"Cleaned audio duration matches input audio duration.\")\n","    except ValueError:\n","        print(f\"Could not parse duration from ffprobe for cleaned audio: {duration_output}\")\n","\n","except subprocess.CalledProcessError as e:\n","    print(f\"--- FFmpeg Error ---\")\n","    print(f\"Command: {' '.join(e.cmd)}\")\n","    print(f\"Return Code: {e.returncode}\")\n","    print(f\"STDOUT:\\n{e.stdout}\")\n","    print(f\"STDERR:\\n{e.stderr}\")\n","    print(f\"--- Audio Preprocessing Failed. Cannot proceed. ---\")\n","    raise e\n","except FileNotFoundError:\n","    print(\"--- FFmpeg/FFprobe not found ---\")\n","    print(\"Please ensure FFmpeg and FFprobe are installed and accessible in your environment's PATH.\")\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"5v7XH1IrIbCG","executionInfo":{"status":"ok","timestamp":1752316657894,"user_tz":-330,"elapsed":16034,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"d69ed00f-54e0-48f8-d74d-56e72f09dcfd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Audio Preprocessing ---\n","--- Verifying Original Input Audio Duration (/content/s1.wav) ---\n","Original input audio duration: 178.13 seconds\n","FFmpeg stderr (might contain warnings/info):\n","ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","Guessed Channel Layout for Input Stream #0.0 : stereo\n","Input #0, wav, from '/content/s1.wav':\n","  Duration: 00:02:58.13, bitrate: 512 kb/s\n","  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, stereo, s16, 512 kb/s\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n","Press [q] to stop, [?] for help\n","Output #0, wav, to 'cleaned_audio_for_asr_and_diarization.wav':\n","  Metadata:\n","    ISFT            : Lavf58.76.100\n","  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n","    Metadata:\n","      encoder         : Lavc58.134.100 pcm_s16le\n","size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \n","size=      91kB time=00:00:02.79 bitrate= 265.4kbits/s speed=5.58x    \n","size=     256kB time=00:00:10.99 bitrate= 190.7kbits/s speed=  11x    \n","size=     512kB time=00:00:18.29 bitrate= 229.2kbits/s speed=12.1x    \n","size=     768kB time=00:00:24.89 bitrate= 252.7kbits/s speed=12.3x    \n","size=     768kB time=00:00:29.99 bitrate= 209.7kbits/s speed=11.9x    \n","size=    1024kB time=00:00:34.99 bitrate= 239.7kbits/s speed=11.6x    \n","size=    1280kB time=00:00:40.89 bitrate= 256.4kbits/s speed=11.6x    \n","size=    1280kB time=00:00:48.29 bitrate= 217.1kbits/s speed=  12x    \n","size=    1536kB time=00:00:52.09 bitrate= 241.5kbits/s speed=11.5x    \n","size=    1536kB time=00:00:56.49 bitrate= 222.7kbits/s speed=11.2x    \n","size=    1792kB time=00:01:01.69 bitrate= 237.9kbits/s speed=11.1x    \n","size=    2048kB time=00:01:06.49 bitrate= 252.3kbits/s speed=  11x    \n","size=    2048kB time=00:01:11.99 bitrate= 233.0kbits/s speed=  11x    \n","size=    2304kB time=00:01:17.29 bitrate= 244.2kbits/s speed=10.9x    \n","size=    2560kB time=00:01:22.29 bitrate= 254.8kbits/s speed=10.8x    \n","size=    2560kB time=00:01:28.09 bitrate= 238.0kbits/s speed=10.9x    \n","size=    2816kB time=00:01:30.29 bitrate= 255.5kbits/s speed=10.5x    \n","size=    2816kB time=00:01:33.99 bitrate= 245.4kbits/s speed=10.3x    \n","size=    2816kB time=00:01:38.09 bitrate= 235.2kbits/s speed=10.2x    \n","size=    3072kB time=00:01:41.49 bitrate= 247.9kbits/s speed=  10x    \n","size=    3072kB time=00:01:43.99 bitrate= 242.0kbits/s speed=9.75x    \n","size=    3328kB time=00:01:46.99 bitrate= 254.8kbits/s speed=9.58x    \n","size=    3328kB time=00:01:52.89 bitrate= 241.5kbits/s speed=9.67x    \n","size=    3584kB time=00:02:02.29 bitrate= 240.1kbits/s speed=  10x    \n","size=    4096kB time=00:02:11.19 bitrate= 255.8kbits/s speed=10.3x    \n","size=    4352kB time=00:02:20.59 bitrate= 253.6kbits/s speed=10.7x    \n","size=    4608kB time=00:02:29.99 bitrate= 251.7kbits/s speed=  11x    \n","size=    4864kB time=00:02:39.29 bitrate= 250.1kbits/s speed=11.2x    \n","size=    5120kB time=00:02:48.09 bitrate= 249.5kbits/s speed=11.4x    \n","size=    5376kB time=00:02:55.22 bitrate= 251.3kbits/s speed=11.5x    \n","size=    5567kB time=00:02:58.12 bitrate= 256.0kbits/s speed=11.6x    \n","video:0kB audio:5566kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.001368%\n","\n","--- Audio Preprocessing Complete. Cleaned audio saved to cleaned_audio_for_asr_and_diarization.wav ---\n","--- Verifying Cleaned Audio Duration (cleaned_audio_for_asr_and_diarization.wav) ---\n","Cleaned audio duration: 178.13 seconds\n","Cleaned audio duration matches input audio duration.\n"]}]},{"cell_type":"code","source":["# --- Step 2: Whisper Transcription ---\n","print(\"--- Starting Whisper Transcription ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kKBklyOIlhJ","executionInfo":{"status":"ok","timestamp":1752316657940,"user_tz":-330,"elapsed":11,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"c580e97b-9e68-4380-af10-64fe4f3d8a7a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Whisper Transcription ---\n"]}]},{"cell_type":"code","source":["model = whisper.load_model(\"large\")"],"metadata":{"id":"jbLYCRy2Ilji","executionInfo":{"status":"ok","timestamp":1752316705483,"user_tz":-330,"elapsed":47540,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# model"],"metadata":{"id":"KNHxrbmBNKuM","executionInfo":{"status":"ok","timestamp":1752316705529,"user_tz":-330,"elapsed":16,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["initial_prompt_text = (\n","    \"Axis Maxlife Insurance, Policy number, fund value, risk term, Premium Due, Due date, Sum Assured, Policy Status, \"\n","    \"Late Fee, Google pay, gpay, phone pay, paytm, netbacking, risk coverage, policy benefits\"\n",")"],"metadata":{"id":"841i7hIQIll5","executionInfo":{"status":"ok","timestamp":1752316705556,"user_tz":-330,"elapsed":10,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["whisper_result = model.transcribe(\n","    clean_audio_path,\n","    language=\"ta\",       # Explicitly set source language as Tamil\n","    task=\"translate\",     # Translate from Tamil to English\n","    verbose=True,\n","    initial_prompt=initial_prompt_text\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdZyd6etNDR6","executionInfo":{"status":"ok","timestamp":1752317675423,"user_tz":-330,"elapsed":969871,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"1598b086-9446-4124-ae3f-c198b586845e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]},{"output_type":"stream","name":"stdout","text":["[00:00.000 --> 00:02.000]  Hello!\n","[00:02.000 --> 00:06.000]  Hello! My name is Swathi. We have called from License.\n","[00:06.000 --> 00:08.000]  Are you Ganeshwari mam?\n","[00:08.000 --> 00:10.000]  No, I am Nyaneshwari mam.\n","[00:10.000 --> 00:13.000]  Sorry, Nyaneshwari mam. Are you Nyaneshwari mam?\n","[00:13.000 --> 00:14.000]  Yes mam.\n","[00:14.000 --> 00:19.000]  You have taken policy in Maxlife Insurance. I will call you back. Please talk.\n","[00:19.000 --> 00:21.000]  Yes mam.\n","[00:21.000 --> 00:29.000]  Thank you. Your policy number is 831-801-543. Maxlife Home Life Participating Plan Policy.\n","[00:29.000 --> 00:35.000]  The duration of 10-12-2024 is Rs.5352.\n","[00:35.000 --> 00:39.000]  What are the reasons for your payment? When are you going to pay?\n","[00:39.000 --> 00:45.000]  We are going to pay in the evening. Normally, I go to the office for one session.\n","[00:45.000 --> 00:47.000]  After Monday, we pay.\n","[00:47.000 --> 00:49.000]  After Monday, we pay.\n","[00:49.000 --> 00:51.000]  You pay between Monday and Tuesday.\n","[00:51.000 --> 00:52.000]  Yes.\n","[00:52.000 --> 00:56.000]  Okay. Are you doing payment in branch or online?\n","[00:56.000 --> 00:58.000]  Online.\n","[00:58.000 --> 00:59.000]  Online.\n","[00:59.000 --> 01:00.000]  Online.\n","[01:00.000 --> 01:01.000]  Can you do online?\n","[01:01.000 --> 01:02.000]  Yes.\n","[01:02.000 --> 01:05.000]  Okay. Its health declaration form is also in pending.\n","[01:05.000 --> 01:08.000]  You submit it together. Then only we will start the policy.\n","[01:08.000 --> 01:11.000]  Already, the policy status is paid up.\n","[01:11.000 --> 01:15.000]  If you have paid up, you will get the benefits that you get.\n","[01:15.000 --> 01:20.000]  In case of uncertainty, the policy is available. So, we will get the benefit.\n","[01:20.000 --> 01:22.000]  They have also given late permit charges.\n","[01:22.000 --> 01:25.000]  If you delay it, there are many chances that it gets high.\n","[01:25.000 --> 01:26.000]  It will be done soon.\n","[01:26.000 --> 01:28.000]  Will it get done soon?\n","[01:28.000 --> 01:31.580]  They have given Rs.230\n","[01:31.580 --> 01:37.380]  So, you can pay on Monday or next week\n","[01:37.380 --> 01:40.020]  If you want to adjust the late payment, we will give you a waived off\n","[01:40.020 --> 01:46.520]  If you don't pay next week, they will do the tender\n","[01:46.520 --> 01:48.520]  Are you doing the tender?\n","[01:48.520 --> 01:49.520]  Yes\n","[01:49.520 --> 01:51.860]  Okay, you can do it till the end\n","[01:51.860 --> 01:55.660]  Whenever you do, submit the health declaration form\n","[01:55.660 --> 01:56.860]  Then only we will activate the policy\n","[01:56.860 --> 01:59.860]  You can do it online, it is a gift form\n","[01:59.860 --> 02:00.860]  Okay\n","[02:00.860 --> 02:06.860]  If the schedule is reduced, you will get the results\n","[02:06.860 --> 02:11.860]  In case of an uncertainty policy, you can try till the end\n","[02:11.860 --> 02:16.860]  Why do you need to do it online?\n","[02:16.860 --> 02:18.860]  No, you can do it online, the form will come\n","[02:18.860 --> 02:20.860]  There will be only 4 questions\n","[02:20.860 --> 02:23.860]  You can submit the answer and submit\n","[02:23.860 --> 02:25.860]  There are no charges for that\n","[02:25.860 --> 02:26.860]  Okay\n","[02:26.860 --> 02:30.860]  Even if you don't have the money, we will submit the form\n","[02:30.860 --> 02:35.860]  We will submit the form even if you ask questions\n","[02:35.860 --> 02:36.860]  Okay\n","[02:36.860 --> 02:39.860]  We will arrange a call back next week\n","[02:39.860 --> 02:41.860]  You can do the online payment till the end\n","[02:41.860 --> 02:42.860]  Okay\n","[02:42.860 --> 02:44.860]  Any other information?\n","[02:44.860 --> 02:45.860]  No\n","[02:45.860 --> 02:48.860]  Do you have any alternate mobile number or email address?\n","[02:48.860 --> 02:51.860]  No\n","[02:51.860 --> 02:55.860]  Okay, thank you for your time for Access Smart Staff Insurance\n","[02:55.860 --> 02:56.860]  Thank you\n","[02:56.860 --> 02:57.860]  Thank you\n","[02:57.860 --> 02:58.860]  Thank you\n"]}]},{"cell_type":"code","source":["print(\"--- Whisper Transcription Complete ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1yx7n7HIloR","executionInfo":{"status":"ok","timestamp":1752317675434,"user_tz":-330,"elapsed":28,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"4c63412e-6265-444e-dd5e-4f93de6e2c80"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Whisper Transcription Complete ---\n"]}]},{"cell_type":"code","source":["# --- Step 3: Speaker Diarization with pyannote.audio ---\n","print(\"\\n--- Starting Speaker Diarization ---\")\n","try:\n","    pipeline = Pipeline.from_pretrained(\n","        \"pyannote/speaker-diarization-3.1\",\n","        use_auth_token=HUGGING_FACE_ACCESS_TOKEN\n","    )\n","\n","    # Send pipeline to GPU (if available)\n","    if torch.cuda.is_available():\n","        pipeline.to(torch.device(\"cuda\"))\n","        print(\"Pyannote.audio moved to GPU.\")\n","    else:\n","        print(\"CUDA not available, running pyannote.audio on CPU. This might be slow.\")\n","\n","    diarization = pipeline(clean_audio_path)\n","    print(\"--- Speaker Diarization Complete ---\")\n","\n","except Exception as e:\n","    print(f\"--- Speaker Diarization Failed ---\")\n","    print(f\"Error: {e}\")\n","    print(\"Please ensure your Hugging Face Access Token is correct and has access to pyannote/speaker-diarization-3.1.\")\n","    # If diarization fails, we can still proceed with transcription but without speaker labels\n","    diarization = None # Set diarization to None if it failed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQhe8AvzIlrx","executionInfo":{"status":"ok","timestamp":1752318233267,"user_tz":-330,"elapsed":557829,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"6c3b3be9-76f7-4a49-961c-70b3355ee363"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Starting Speaker Diarization ---\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n"]},{"output_type":"stream","name":"stdout","text":["CUDA not available, running pyannote.audio on CPU. This might be slow.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n","  std = sequences.std(dim=-1, correction=1)\n"]},{"output_type":"stream","name":"stdout","text":["--- Speaker Diarization Complete ---\n"]}]},{"cell_type":"code","source":["# --- Step 4: Combine and Format Output ---\n","print(\"\\n--- Generating Dialogue Output ---\")\n","dialogue_output = []\n","\n","# Helper function to find the dominant speaker for a given time segment\n","def get_dominant_speaker_for_segment(start_time, end_time, diarization_result):\n","    if not diarization_result: # If diarization failed\n","        return \"Unknown\"\n","\n","    speakers_in_segment = {}\n","    for segment, _, speaker_label in diarization_result.itertracks(yield_label=True):\n","        # Calculate overlap between transcription segment and diarization segment\n","        overlap_start = max(start_time, segment.start)\n","        overlap_end = min(end_time, segment.end)\n","        overlap_duration = max(0, overlap_end - overlap_start)\n","\n","        if overlap_duration > 0:\n","            speakers_in_segment[speaker_label] = speakers_in_segment.get(speaker_label, 0) + overlap_duration\n","\n","    if not speakers_in_segment:\n","        return \"Unknown\"\n","\n","    # Return the speaker with the most overlap\n","    return max(speakers_in_segment, key=speakers_in_segment.get)\n","\n","# Group segments by speaker for better dialogue flow (experimental, can be adjusted)\n","current_speaker = None\n","current_text = []\n","current_start = -1\n","current_end = -1\n","\n","for i, segment in enumerate(whisper_result[\"segments\"]):\n","    start = segment['start']\n","    end = segment['end']\n","    text = segment['text'].strip()\n","\n","    speaker = get_dominant_speaker_for_segment(start, end, diarization)\n","\n","    if speaker == current_speaker and current_speaker is not None and (start - current_end) < 2.0: # Merge if same speaker and short pause\n","        current_text.append(text)\n","        current_end = end\n","    else:\n","        if current_speaker is not None:\n","            dialogue_output.append(f\"Speaker {current_speaker}: {' '.join(current_text)}\")\n","        current_speaker = speaker\n","        current_text = [text]\n","        current_start = start\n","        current_end = end\n","\n","# Add the last accumulated segment\n","if current_speaker is not None:\n","    dialogue_output.append(f\"Speaker {current_speaker}: {' '.join(current_text)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnY0e6UGI0HR","executionInfo":{"status":"ok","timestamp":1752318233270,"user_tz":-330,"elapsed":40,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"d200428e-7daa-4131-c8ba-91e4c93c7963"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Generating Dialogue Output ---\n"]}]},{"cell_type":"code","source":["# --- Step 5: Print the final dialogue ---\n","for line in dialogue_output:\n","    print(line)\n","\n","print(\"\\n--- Processing Complete ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDbIiOtCI0J2","executionInfo":{"status":"ok","timestamp":1752318233272,"user_tz":-330,"elapsed":25,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"0c7f2489-ef44-460c-d0dd-5197281ab164"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Speaker SPEAKER_00: Hello! Hello! My name is Swathi. We have called from License. Are you Ganeshwari mam? No, I am Nyaneshwari mam. Sorry, Nyaneshwari mam. Are you Nyaneshwari mam?\n","Speaker SPEAKER_02: Yes mam.\n","Speaker SPEAKER_00: You have taken policy in Maxlife Insurance. I will call you back. Please talk.\n","Speaker SPEAKER_01: Yes mam.\n","Speaker SPEAKER_00: Thank you. Your policy number is 831-801-543. Maxlife Home Life Participating Plan Policy. The duration of 10-12-2024 is Rs.5352. What are the reasons for your payment? When are you going to pay?\n","Speaker SPEAKER_01: We are going to pay in the evening. Normally, I go to the office for one session. After Monday, we pay. After Monday, we pay.\n","Speaker SPEAKER_00: You pay between Monday and Tuesday.\n","Speaker SPEAKER_01: Yes.\n","Speaker SPEAKER_00: Okay. Are you doing payment in branch or online?\n","Speaker SPEAKER_01: Online. Online. Online.\n","Speaker SPEAKER_00: Can you do online? Yes. Okay. Its health declaration form is also in pending. You submit it together. Then only we will start the policy. Already, the policy status is paid up. If you have paid up, you will get the benefits that you get. In case of uncertainty, the policy is available. So, we will get the benefit. They have also given late permit charges. If you delay it, there are many chances that it gets high. It will be done soon. Will it get done soon? They have given Rs.230 So, you can pay on Monday or next week If you want to adjust the late payment, we will give you a waived off\n","Speaker SPEAKER_01: If you don't pay next week, they will do the tender\n","Speaker SPEAKER_00: Are you doing the tender?\n","Speaker SPEAKER_01: Yes\n","Speaker SPEAKER_00: Okay, you can do it till the end Whenever you do, submit the health declaration form Then only we will activate the policy You can do it online, it is a gift form\n","Speaker SPEAKER_02: Okay\n","Speaker SPEAKER_00: If the schedule is reduced, you will get the results In case of an uncertainty policy, you can try till the end\n","Speaker SPEAKER_01: Why do you need to do it online?\n","Speaker SPEAKER_00: No, you can do it online, the form will come There will be only 4 questions You can submit the answer and submit There are no charges for that Okay Even if you don't have the money, we will submit the form We will submit the form even if you ask questions Okay We will arrange a call back next week You can do the online payment till the end\n","Speaker SPEAKER_02: Okay\n","Speaker SPEAKER_00: Any other information?\n","Speaker SPEAKER_02: No\n","Speaker SPEAKER_00: Do you have any alternate mobile number or email address?\n","Speaker SPEAKER_01: No\n","Speaker SPEAKER_00: Okay, thank you for your time for Access Smart Staff Insurance\n","Speaker SPEAKER_01: Thank you\n","Speaker SPEAKER_00: Thank you Thank you\n","\n","--- Processing Complete ---\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6jB8PZgSat_C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vaM33A0xauH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Second call"],"metadata":{"id":"b1meWYlWavT6","executionInfo":{"status":"ok","timestamp":1752320117802,"user_tz":-330,"elapsed":5,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["input_audio_path = \"/content/s2.wav\"\n","clean_audio_path = \"cleaned_audio_for_asr_and_diarization.wav\""],"metadata":{"id":"eAV7ESDZa3Oi","executionInfo":{"status":"ok","timestamp":1752320191038,"user_tz":-330,"elapsed":9,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# --- Step 1: Enhanced Audio Preprocessing with ffmpeg and Duration Verification ---\n","print(\"--- Starting Audio Preprocessing ---\")\n","\n","# First, get the duration of the original input file for comparison\n","print(f\"--- Verifying Original Input Audio Duration ({input_audio_path}) ---\")\n","ffprobe_command_input = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", input_audio_path]\n","try:\n","    input_duration_output = subprocess.run(ffprobe_command_input, check=True, capture_output=True, text=True).stdout.strip()\n","    original_input_duration_seconds = float(input_duration_output)\n","    print(f\"Original input audio duration: {original_input_duration_seconds:.2f} seconds\")\n","except Exception as e:\n","    print(f\"Error getting original input audio duration: {e}. Please ensure the input WAV file exists and is valid.\")\n","    # Exit or raise error if input audio duration cannot be determined\n","    raise\n","\n","# FFmpeg command using the original successful filters\n","ffmpeg_command = [\n","    \"ffmpeg\",\n","    \"-i\", input_audio_path,\n","    \"-acodec\", \"pcm_s16le\",\n","    \"-ac\", \"1\",\n","    \"-ar\", \"16000\",\n","    # Reverted to the original working filters: loudnorm, highpass, lowpass\n","    \"-af\", \"loudnorm=I=-16:TP=-1.5:LRA=11, highpass=f=200, lowpass=f=3000\",\n","    \"-y\", clean_audio_path # -y to overwrite output file without asking\n","]\n","\n","try:\n","    result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n","    if result.stdout:\n","        print(\"FFmpeg stdout:\")\n","        print(result.stdout)\n","    if result.stderr:\n","        print(\"FFmpeg stderr (might contain warnings/info):\")\n","        print(result.stderr)\n","    print(f\"--- Audio Preprocessing Complete. Cleaned audio saved to {clean_audio_path} ---\")\n","\n","    # Verify duration of the cleaned audio file\n","    print(f\"--- Verifying Cleaned Audio Duration ({clean_audio_path}) ---\")\n","    ffprobe_command_output = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", clean_audio_path]\n","    duration_output = subprocess.run(ffprobe_command_output, check=True, capture_output=True, text=True).stdout.strip()\n","    try:\n","        cleaned_audio_duration_seconds = float(duration_output)\n","        print(f\"Cleaned audio duration: {cleaned_audio_duration_seconds:.2f} seconds\")\n","        if abs(original_input_duration_seconds - cleaned_audio_duration_seconds) > 0.1: # Allow for small floating point differences\n","            print(f\"WARNING: Cleaned audio duration ({cleaned_audio_duration_seconds:.2f}s) significantly differs from input ({original_input_duration_seconds:.2f}s). This might indicate a truncation problem during FFmpeg processing.\")\n","        else:\n","            print(\"Cleaned audio duration matches input audio duration.\")\n","    except ValueError:\n","        print(f\"Could not parse duration from ffprobe for cleaned audio: {duration_output}\")\n","\n","except subprocess.CalledProcessError as e:\n","    print(f\"--- FFmpeg Error ---\")\n","    print(f\"Command: {' '.join(e.cmd)}\")\n","    print(f\"Return Code: {e.returncode}\")\n","    print(f\"STDOUT:\\n{e.stdout}\")\n","    print(f\"STDERR:\\n{e.stderr}\")\n","    print(f\"--- Audio Preprocessing Failed. Cannot proceed. ---\")\n","    raise e\n","except FileNotFoundError:\n","    print(\"--- FFmpeg/FFprobe not found ---\")\n","    print(\"Please ensure FFmpeg and FFprobe are installed and accessible in your environment's PATH.\")\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Ci-UT5CdawrE","executionInfo":{"status":"ok","timestamp":1752320207125,"user_tz":-330,"elapsed":13960,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"f17c160c-a132-4601-b23e-7a8b96c852ed"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Audio Preprocessing ---\n","--- Verifying Original Input Audio Duration (/content/s2.wav) ---\n","Original input audio duration: 231.34 seconds\n","FFmpeg stderr (might contain warnings/info):\n","ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","Guessed Channel Layout for Input Stream #0.0 : stereo\n","Input #0, wav, from '/content/s2.wav':\n","  Duration: 00:03:51.34, bitrate: 512 kb/s\n","  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, stereo, s16, 512 kb/s\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n","Press [q] to stop, [?] for help\n","Output #0, wav, to 'cleaned_audio_for_asr_and_diarization.wav':\n","  Metadata:\n","    ISFT            : Lavf58.76.100\n","  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n","    Metadata:\n","      encoder         : Lavc58.134.100 pcm_s16le\n","size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \n","size=     213kB time=00:00:06.69 bitrate= 259.9kbits/s speed=13.3x    \n","size=     256kB time=00:00:15.39 bitrate= 136.2kbits/s speed=15.3x    \n","size=     512kB time=00:00:24.29 bitrate= 172.6kbits/s speed=16.1x    \n","size=    1024kB time=00:00:32.89 bitrate= 255.0kbits/s speed=16.3x    \n","size=    1280kB time=00:00:42.09 bitrate= 249.1kbits/s speed=16.7x    \n","size=    1536kB time=00:00:50.99 bitrate= 246.7kbits/s speed=16.9x    \n","size=    1792kB time=00:00:59.89 bitrate= 245.1kbits/s speed=  17x    \n","size=    2048kB time=00:01:08.69 bitrate= 244.2kbits/s speed=17.1x    \n","size=    2304kB time=00:01:17.69 bitrate= 242.9kbits/s speed=17.2x    \n","size=    2560kB time=00:01:26.49 bitrate= 242.4kbits/s speed=17.2x    \n","size=    2816kB time=00:01:35.99 bitrate= 240.3kbits/s speed=17.3x    \n","size=    3072kB time=00:01:44.99 bitrate= 239.7kbits/s speed=17.4x    \n","size=    3328kB time=00:01:54.09 bitrate= 238.9kbits/s speed=17.5x    \n","size=    3840kB time=00:02:02.99 bitrate= 255.8kbits/s speed=17.5x    \n","size=    4096kB time=00:02:12.09 bitrate= 254.0kbits/s speed=17.5x    \n","size=    4352kB time=00:02:21.29 bitrate= 252.3kbits/s speed=17.6x    \n","size=    4608kB time=00:02:30.69 bitrate= 250.5kbits/s speed=17.6x    \n","size=    4864kB time=00:02:39.69 bitrate= 249.5kbits/s speed=17.7x    \n","size=    5120kB time=00:02:48.69 bitrate= 248.6kbits/s speed=17.7x    \n","size=    5376kB time=00:02:55.99 bitrate= 250.2kbits/s speed=17.5x    \n","size=    5632kB time=00:03:03.79 bitrate= 251.0kbits/s speed=17.4x    \n","size=    5888kB time=00:03:11.29 bitrate= 252.1kbits/s speed=17.3x    \n","size=    6144kB time=00:03:18.89 bitrate= 253.1kbits/s speed=17.2x    \n","size=    6400kB time=00:03:25.99 bitrate= 254.5kbits/s speed=17.1x    \n","size=    6656kB time=00:03:34.49 bitrate= 254.2kbits/s speed=17.1x    \n","size=    6912kB time=00:03:43.79 bitrate= 253.0kbits/s speed=17.1x    \n","size=    7229kB time=00:03:51.33 bitrate= 256.0kbits/s speed=17.1x    \n","video:0kB audio:7229kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.001054%\n","\n","--- Audio Preprocessing Complete. Cleaned audio saved to cleaned_audio_for_asr_and_diarization.wav ---\n","--- Verifying Cleaned Audio Duration (cleaned_audio_for_asr_and_diarization.wav) ---\n","Cleaned audio duration: 231.34 seconds\n","Cleaned audio duration matches input audio duration.\n"]}]},{"cell_type":"code","source":["print(\"--- Starting Whisper Transcription ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cEQTr5AbbPLC","executionInfo":{"status":"ok","timestamp":1752320252498,"user_tz":-330,"elapsed":21,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"d0c85cf6-cb07-4a43-ff51-0e0e5012a1e2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Whisper Transcription ---\n"]}]},{"cell_type":"code","source":["whisper_result = model.transcribe(\n","    clean_audio_path,\n","    language=\"ta\",       # Explicitly set source language as Tamil\n","    task=\"translate\",     # Translate from Tamil to English\n","    verbose=True,\n","    initial_prompt=initial_prompt_text\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdBdIo7XbPNS","executionInfo":{"status":"ok","timestamp":1752322727011,"user_tz":-330,"elapsed":2463089,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"b5e62643-dddd-4314-d74e-b5db6b219f5e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]},{"output_type":"stream","name":"stdout","text":["[00:00.000 --> 00:04.000]  Hello, My name is Smati, We are calling from Life Insurance,\n","[00:04.000 --> 00:05.000]  Hello,\n","[00:05.000 --> 00:07.000]  Do you know Maheshwari Maa?\n","[00:07.000 --> 00:08.000]  Yes, I know, Tell me Maa\n","[00:08.000 --> 00:13.000]  Ok, Do you have policy in Access Maxlife Insurance? Can we talk about Renewal Pearl for 2 minutes?\n","[00:13.000 --> 00:15.000]  Yes, Tell me Maa\n","[00:15.000 --> 00:27.000]  Thank you, Your policy number is 326166147, Maxlife Holders Superfund Policy, 2772024, 34640 Rs.\n","[00:27.000 --> 00:36.000]  We have talked with you for last month, you have informed us about payment in this month, but still not received, do you know when and why you are getting delayed?\n","[00:36.000 --> 00:40.000]  I have paid it, I have paid it 4 days before\n","[00:40.000 --> 00:42.000]  You have paid it 4 days before?\n","[00:42.000 --> 00:43.000]  Yes, I have paid it\n","[00:43.000 --> 00:44.000]  When did you pay it?\n","[00:44.000 --> 00:47.000]  I have paid it for 1 year\n","[00:47.000 --> 00:49.000]  For 1 year, you have paid it for 1.5-3 months\n","[00:49.000 --> 00:54.000]  Yes, I have paid it for 1.5-3 months\n","[00:54.000 --> 00:56.000]  Ok, When did you pay it?\n","[00:56.000 --> 00:57.000]  There, I have paid it for 1 month\n","[00:57.000 --> 00:58.000]  I have paid it for 1 month\n","[00:58.000 --> 01:01.000]  Ok, After that, we have taken the agent's account, and have paid it to them, they will pay the entire amount\n","[01:01.000 --> 01:02.000]  Ok\n","[01:02.000 --> 01:05.000]  I have paid it for 1 month\n","[01:05.000 --> 01:08.000]  Have you paid it to the agent?\n","[01:08.000 --> 01:09.000]  Yes, Maa\n","[01:09.000 --> 01:12.000]  Did you pay it in cash or money or by any other means?\n","[01:12.000 --> 01:15.000]  No, I have sent it through the phone\n","[01:15.000 --> 01:19.000]  Did you send it to their account or you have provided it directly for the policy?\n","[01:19.000 --> 01:22.000]  No, I have sent it directly to that woman\n","[01:22.000 --> 01:25.000]  Ok\n","[01:25.000 --> 01:26.000]  Should I tell her about the case?\n","[01:26.000 --> 01:30.000]  Ma'am, I haven't received any payment yet.\n","[01:30.000 --> 01:33.000]  I'll tell you when I get the money.\n","[01:33.000 --> 01:36.000]  You can pay them later. We can pay them later.\n","[01:36.000 --> 01:39.000]  But we'll get the money only when you pay the full amount.\n","[01:39.000 --> 01:42.000]  We'll maintain the payment only when you pay the full amount.\n","[01:42.000 --> 01:44.000]  We'll pay you when you get the payment.\n","[01:44.000 --> 01:46.000]  We told you that day itself.\n","[01:46.000 --> 01:50.000]  We couldn't pay the amount because of the health problem.\n","[01:50.000 --> 01:51.000]  Okay.\n","[01:51.000 --> 01:57.000]  So, she said that she'll pay half of the amount and the rest in 2-3 months.\n","[01:57.000 --> 01:58.000]  Okay.\n","[01:58.000 --> 02:03.000]  I paid the amount half of the amount 3-4 days ago.\n","[02:03.000 --> 02:04.000]  I don't know the exact date.\n","[02:04.000 --> 02:06.000]  So, you asked me to pay the amount.\n","[02:06.000 --> 02:10.000]  If you had paid the amount 4 days ago, you would have received the payment.\n","[02:10.000 --> 02:12.000]  But, you didn't receive the payment.\n","[02:12.000 --> 02:13.000]  So, ask your agent.\n","[02:13.000 --> 02:17.000]  You can't go directly to the branch and pay the amount.\n","[02:17.000 --> 02:20.000]  You don't have the capacity to pay the amount.\n","[02:20.000 --> 02:21.000]  Okay.\n","[02:21.000 --> 02:22.000]  I don't know that.\n","[02:22.000 --> 02:26.000]  So, I'm paying the amount in the same way.\n","[02:26.000 --> 02:29.000]  So, I'm getting a call that you haven't been updated yet.\n","[02:29.000 --> 02:31.000]  Ask them what it is.\n","[02:31.000 --> 02:32.000]  Okay.\n","[02:32.000 --> 02:33.000]  I'll call them.\n","[02:33.000 --> 02:34.000]  I'll give them the number.\n","[02:34.000 --> 02:35.000]  Can I call them?\n","[02:35.000 --> 02:36.000]  No.\n","[02:36.000 --> 02:38.000]  It won't land if you call the system call.\n","[02:38.000 --> 02:40.000]  We'll arrange for your call back.\n","[02:40.000 --> 02:42.000]  You talk to them and inform me.\n","[02:42.000 --> 02:43.000]  Okay?\n","[02:43.000 --> 02:44.000]  Okay.\n","[02:44.000 --> 02:45.000]  Okay.\n","[02:45.000 --> 02:46.000]  Any other problems?\n","[02:46.000 --> 02:47.000]  No.\n","[02:47.000 --> 02:48.000]  I'll take care of it.\n","[02:48.000 --> 02:50.000]  I'll tell you what to do after I see it.\n","[02:50.000 --> 02:51.000]  Okay.\n","[02:51.000 --> 02:54.000]  Can you update your alternate mobile number and email address?\n","[02:54.000 --> 02:56.000]  I don't know any of those.\n","[02:56.000 --> 02:58.000]  I'm not that educated.\n","[02:58.000 --> 02:59.000]  Okay.\n","[02:59.000 --> 03:00.000]  I'll send it to the access nurse.\n","[03:00.000 --> 03:04.000]  The person who is the customer of the business is the one who will write it and give it to you.\n","[03:04.000 --> 03:05.000]  Okay.\n","[03:05.000 --> 03:08.000]  I'll call them once in a while.\n","[03:08.000 --> 03:09.000]  Okay.\n","[03:09.000 --> 03:12.000]  They'll tell you that they'll call you directly.\n","[03:12.000 --> 03:13.000]  Okay.\n","[03:13.000 --> 03:16.000]  That's why I've given this call to them.\n","[03:16.000 --> 03:17.000]  Okay.\n","[03:17.000 --> 03:19.000]  But, when you gave it to them, they said that you haven't been updated yet.\n","[03:19.000 --> 03:20.000]  So, check it once.\n","[03:20.000 --> 03:22.000]  Because you haven't given the money yet.\n","[03:22.000 --> 03:23.000]  So, check it once.\n","[03:23.000 --> 03:24.000]  I'll give the money.\n","[03:24.000 --> 03:25.000]  I'll give it.\n","[03:25.000 --> 03:27.000]  I'll give it when you call next time.\n","[03:27.000 --> 03:28.000]  Okay.\n","[03:28.000 --> 03:31.000]  Thank you for taking time for the access nurse insurance.\n","[03:31.000 --> 03:32.000]  Thank you.\n","[03:32.000 --> 03:33.000]  You're welcome.\n","[03:33.000 --> 03:34.000]  Thank you.\n","[03:34.000 --> 03:35.000]  Okay.\n","[03:35.000 --> 03:36.000]  Okay.\n","[03:36.000 --> 03:37.000]  Okay.\n","[03:37.000 --> 03:38.000]  Okay.\n","[03:38.000 --> 03:39.000]  Okay.\n","[03:39.000 --> 03:40.000]  Okay.\n","[03:40.000 --> 03:41.000]  Okay.\n","[03:41.000 --> 03:42.000]  Okay.\n","[03:42.000 --> 03:43.000]  Okay.\n","[03:43.000 --> 03:44.000]  Okay.\n","[03:44.000 --> 03:45.000]  Okay.\n","[03:45.000 --> 03:46.000]  Okay.\n","[03:46.000 --> 03:47.000]  Okay.\n","[03:47.000 --> 03:48.000]  Okay.\n","[03:48.000 --> 03:49.000]  Okay.\n","[03:49.000 --> 03:50.000]  Okay.\n","[03:50.000 --> 03:51.000]  Okay.\n","[03:51.000 --> 03:52.000]  Okay.\n","[03:52.000 --> 03:53.000]  Okay.\n","[03:53.000 --> 03:54.000]  Maybe she'll take that for you to take care with.\n","[03:54.000 --> 03:55.000]  Okay.\n","[03:55.000 --> 03:56.000]  Yes.\n","[03:56.000 --> 03:57.000]  I'll call you again tonight.\n","[03:57.000 --> 03:58.000]  In alone?\n","[03:58.000 --> 03:59.000]  Yes.\n","[03:59.000 --> 04:00.000]  Okay.\n","[04:00.000 --> 04:01.000]  Bye.\n","[04:01.000 --> 04:02.000]  Bye.\n","[04:02.000 --> 04:03.000]  Bye.\n","[04:03.000 --> 04:04.000]  See you tomorrow, we'll call you.\n","[04:04.000 --> 04:05.000]  Bye.\n","[04:05.000 --> 04:06.000]  Okay.\n","[04:06.000 --> 04:07.000]  Bye.\n","[04:07.000 --> 04:08.000]  Okay.\n","[04:08.000 --> 04:09.000]  Bye.\n","[04:09.000 --> 04:10.000]  Bye.\n","[04:10.000 --> 04:11.000]  Bye.\n","[04:11.000 --> 04:12.000]  Bye.\n","[04:12.000 --> 04:13.000]  See you tomorrow.\n","[04:13.000 --> 04:14.000]  Bye.\n","[04:14.000 --> 04:15.000]  Why not call me?\n","[04:15.000 --> 04:16.000]  Thank you, patient.\n","[04:16.000 --> 04:17.000]  Bye..\n","[04:17.000 --> 04:18.000]  Thank you.\n","[04:18.000 --> 04:19.000]  Bye.\n"]}]},{"cell_type":"code","source":["print(\"--- Whisper Transcription Complete ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrkTAQ8hbPPs","executionInfo":{"status":"ok","timestamp":1752322727232,"user_tz":-330,"elapsed":36,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"0a2c9422-d320-436d-9014-d6b4c3a90275"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Whisper Transcription Complete ---\n"]}]},{"cell_type":"code","source":["# --- Step 3: Speaker Diarization with pyannote.audio ---\n","print(\"\\n--- Starting Speaker Diarization ---\")\n","try:\n","    pipeline = Pipeline.from_pretrained(\n","        \"pyannote/speaker-diarization-3.1\",\n","        use_auth_token=HUGGING_FACE_ACCESS_TOKEN\n","    )\n","\n","    # Send pipeline to GPU (if available)\n","    if torch.cuda.is_available():\n","        pipeline.to(torch.device(\"cuda\"))\n","        print(\"Pyannote.audio moved to GPU.\")\n","    else:\n","        print(\"CUDA not available, running pyannote.audio on CPU. This might be slow.\")\n","\n","    diarization = pipeline(clean_audio_path)\n","    print(\"--- Speaker Diarization Complete ---\")\n","\n","except Exception as e:\n","    print(f\"--- Speaker Diarization Failed ---\")\n","    print(f\"Error: {e}\")\n","    print(\"Please ensure your Hugging Face Access Token is correct and has access to pyannote/speaker-diarization-3.1.\")\n","    # If diarization fails, we can still proceed with transcription but without speaker labels\n","    diarization = None # Set diarization to None if it failed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rCVxSnmsbPRz","executionInfo":{"status":"ok","timestamp":1752323620904,"user_tz":-330,"elapsed":739131,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"86cde4d4-f6fb-4b4b-ca2d-41cddb684769"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Starting Speaker Diarization ---\n","CUDA not available, running pyannote.audio on CPU. This might be slow.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n","  std = sequences.std(dim=-1, correction=1)\n"]},{"output_type":"stream","name":"stdout","text":["--- Speaker Diarization Complete ---\n"]}]},{"cell_type":"code","source":["# --- Step 4: Combine and Format Output ---\n","print(\"\\n--- Generating Dialogue Output ---\")\n","dialogue_output = []\n","\n","# Helper function to find the dominant speaker for a given time segment\n","def get_dominant_speaker_for_segment(start_time, end_time, diarization_result):\n","    if not diarization_result: # If diarization failed\n","        return \"Unknown\"\n","\n","    speakers_in_segment = {}\n","    for segment, _, speaker_label in diarization_result.itertracks(yield_label=True):\n","        # Calculate overlap between transcription segment and diarization segment\n","        overlap_start = max(start_time, segment.start)\n","        overlap_end = min(end_time, segment.end)\n","        overlap_duration = max(0, overlap_end - overlap_start)\n","\n","        if overlap_duration > 0:\n","            speakers_in_segment[speaker_label] = speakers_in_segment.get(speaker_label, 0) + overlap_duration\n","\n","    if not speakers_in_segment:\n","        return \"Unknown\"\n","\n","    # Return the speaker with the most overlap\n","    return max(speakers_in_segment, key=speakers_in_segment.get)\n","\n","# Group segments by speaker for better dialogue flow (experimental, can be adjusted)\n","current_speaker = None\n","current_text = []\n","current_start = -1\n","current_end = -1\n","\n","for i, segment in enumerate(whisper_result[\"segments\"]):\n","    start = segment['start']\n","    end = segment['end']\n","    text = segment['text'].strip()\n","\n","    speaker = get_dominant_speaker_for_segment(start, end, diarization)\n","\n","    if speaker == current_speaker and current_speaker is not None and (start - current_end) < 2.0: # Merge if same speaker and short pause\n","        current_text.append(text)\n","        current_end = end\n","    else:\n","        if current_speaker is not None:\n","            dialogue_output.append(f\"Speaker {current_speaker}: {' '.join(current_text)}\")\n","        current_speaker = speaker\n","        current_text = [text]\n","        current_start = start\n","        current_end = end\n","\n","# Add the last accumulated segment\n","if current_speaker is not None:\n","    dialogue_output.append(f\"Speaker {current_speaker}: {' '.join(current_text)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aa4JoXobbPWI","executionInfo":{"status":"ok","timestamp":1752323620919,"user_tz":-330,"elapsed":48,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"86c9a853-75c4-4197-8d46-155145b77d58"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Generating Dialogue Output ---\n"]}]},{"cell_type":"code","source":["# --- Step 5: Print the final dialogue ---\n","for line in dialogue_output:\n","    print(line)\n","\n","print(\"\\n--- Processing Complete ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocTEcJbXbPYt","executionInfo":{"status":"ok","timestamp":1752323620932,"user_tz":-330,"elapsed":10,"user":{"displayName":"VBS Analytics","userId":"12942825704271409009"}},"outputId":"1960e8cc-e650-44fd-8c16-e3b68e6cf5f8"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Speaker SPEAKER_01: Hello, My name is Smati, We are calling from Life Insurance, Hello, Do you know Maheshwari Maa?\n","Speaker SPEAKER_00: Yes, I know, Tell me Maa\n","Speaker SPEAKER_01: Ok, Do you have policy in Access Maxlife Insurance? Can we talk about Renewal Pearl for 2 minutes?\n","Speaker SPEAKER_00: Yes, Tell me Maa\n","Speaker SPEAKER_01: Thank you, Your policy number is 326166147, Maxlife Holders Superfund Policy, 2772024, 34640 Rs. We have talked with you for last month, you have informed us about payment in this month, but still not received, do you know when and why you are getting delayed?\n","Speaker SPEAKER_00: I have paid it, I have paid it 4 days before\n","Speaker SPEAKER_01: You have paid it 4 days before?\n","Speaker SPEAKER_00: Yes, I have paid it\n","Speaker SPEAKER_01: When did you pay it?\n","Speaker SPEAKER_00: I have paid it for 1 year\n","Speaker SPEAKER_01: For 1 year, you have paid it for 1.5-3 months\n","Speaker SPEAKER_00: Yes, I have paid it for 1.5-3 months\n","Speaker SPEAKER_01: Ok, When did you pay it?\n","Speaker SPEAKER_00: There, I have paid it for 1 month I have paid it for 1 month Ok, After that, we have taken the agent's account, and have paid it to them, they will pay the entire amount\n","Speaker SPEAKER_01: Ok\n","Speaker SPEAKER_00: I have paid it for 1 month\n","Speaker SPEAKER_01: Have you paid it to the agent?\n","Speaker SPEAKER_00: Yes, Maa\n","Speaker SPEAKER_01: Did you pay it in cash or money or by any other means?\n","Speaker SPEAKER_00: No, I have sent it through the phone\n","Speaker SPEAKER_01: Did you send it to their account or you have provided it directly for the policy?\n","Speaker SPEAKER_00: No, I have sent it directly to that woman\n","Speaker SPEAKER_01: Ok\n","Speaker SPEAKER_00: Should I tell her about the case?\n","Speaker SPEAKER_01: Ma'am, I haven't received any payment yet.\n","Speaker SPEAKER_00: I'll tell you when I get the money.\n","Speaker SPEAKER_01: You can pay them later. We can pay them later. But we'll get the money only when you pay the full amount. We'll maintain the payment only when you pay the full amount. We'll pay you when you get the payment.\n","Speaker SPEAKER_00: We told you that day itself. We couldn't pay the amount because of the health problem. Okay. So, she said that she'll pay half of the amount and the rest in 2-3 months. Okay. I paid the amount half of the amount 3-4 days ago. I don't know the exact date. So, you asked me to pay the amount.\n","Speaker SPEAKER_01: If you had paid the amount 4 days ago, you would have received the payment. But, you didn't receive the payment. So, ask your agent. You can't go directly to the branch and pay the amount. You don't have the capacity to pay the amount. Okay.\n","Speaker SPEAKER_00: I don't know that. So, I'm paying the amount in the same way.\n","Speaker SPEAKER_01: So, I'm getting a call that you haven't been updated yet. Ask them what it is.\n","Speaker SPEAKER_00: Okay. I'll call them. I'll give them the number. Can I call them?\n","Speaker SPEAKER_01: No. It won't land if you call the system call. We'll arrange for your call back. You talk to them and inform me.\n","Speaker SPEAKER_00: Okay? Okay.\n","Speaker SPEAKER_01: Okay. Any other problems?\n","Speaker SPEAKER_00: No. I'll take care of it. I'll tell you what to do after I see it.\n","Speaker SPEAKER_01: Okay. Can you update your alternate mobile number and email address?\n","Speaker SPEAKER_00: I don't know any of those. I'm not that educated.\n","Speaker SPEAKER_01: Okay. I'll send it to the access nurse.\n","Speaker SPEAKER_00: The person who is the customer of the business is the one who will write it and give it to you.\n","Speaker SPEAKER_01: Okay.\n","Speaker SPEAKER_00: I'll call them once in a while. Okay. They'll tell you that they'll call you directly. Okay. That's why I've given this call to them.\n","Speaker SPEAKER_01: Okay. But, when you gave it to them, they said that you haven't been updated yet. So, check it once. Because you haven't given the money yet. So, check it once.\n","Speaker SPEAKER_00: I'll give the money. I'll give it. I'll give it when you call next time.\n","Speaker SPEAKER_01: Okay. Thank you for taking time for the access nurse insurance. Thank you.\n","Speaker SPEAKER_00: You're welcome. Thank you.\n","Speaker SPEAKER_01: Okay.\n","Speaker SPEAKER_00: Okay. Okay. Okay.\n","Speaker Unknown: Okay.\n","Speaker SPEAKER_01: Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay.\n","Speaker Unknown: Okay.\n","Speaker SPEAKER_01: Okay. Okay. Okay.\n","Speaker Unknown: Okay. Maybe she'll take that for you to take care with. Okay. Yes. I'll call you again tonight. In alone? Yes. Okay. Bye. Bye. Bye. See you tomorrow, we'll call you. Bye. Okay. Bye. Okay. Bye. Bye. Bye. Bye. See you tomorrow. Bye. Why not call me? Thank you, patient. Bye.. Thank you. Bye.\n","\n","--- Processing Complete ---\n"]}]}]}